---
title: Линейная алгебра
---

# Решение задач


## Векторные подпространства


### Способы задания: фундаментальная система решений


Пусть задана система $m$ линейных однородных ^[То есть с нулем в правой части.] уравнений с $n$ неизвестными. Тогда множество ее решений -- векторное подпространство в пространстве строк длины $n$. ^[Это понятно, так как сумма решений и решение, умноженное на константу, -- решения и $0$ является решением, то есть множество решений замкнуто относительно операций векторного пространства и содержит $0$]

### Способы задания: линейная оболочка


Пусть $V$ -- векторное пространство и $u_1, \ldots, u_n \in V$. Тогда наименьшее по мощности векторное подпространство, содержащее $u_1, \ldots, u_n$ -- это *линейная оболочка* векторов $u_1, \ldots, u_n$.

### Как перейти от фундаментальной системы решений к линейной оболочке и обратно?


Рассмотрим на примере. Пусть $U = \langle (1, 1, 1, 1, 1), (0, 1, 0, 1, 1), (1, 1, 0, 0, 0), (2, 3, 1, 2, 2)\rangle$. Хотим представить $U$ в виде системы линейных уравнений, для которых векторы $(1, 1, 1, 1, 1), (0, 1, 0, 1, 1), (1, 1, 0, 0, 0), (2, 3, 1, 2, 2)$ являются решениями, то есть выполнено $$\begin{cases}
x_1 + x_2 + x_3 + x_4 + x_5 = 0\\
x_2 + x_4 + x_5 = 0\\
x_1 + x_2 = 0\\
2 \cdot x_1 + 3\cdot x_2 + x_3 + 2 \cdot x_4 + 2 \cdot x_5 = 0
\end{cases}$$

Решим полученную систему методом Гаусса:

$$\left(\begin{array}{ccccc}
1 & 1 & 1 & 1 & 1\\
0 & 1 & 0 & 1 & 1\\
1 & 1 & 0 & 0 & 0\\
2 & 3 & 1 & 2 & 2\\
\end{array}\right) \sim \left(\begin{array}{ccccc}
1 & 1 & 1 & 1 & 1\\
0 & 1 & 0 & 1 & 1\\
0 & 1 & -1 & 0 & 0\\
0 & 0 & -1 & -1 & -1\\
\end{array}\right) \sim \left(\begin{array}{ccccc}
1 & 1 & 1 & 1 & 1\\
0 & 1 & 0 & 1 & 1\\
0 & 0 & 1 & 1 & 1\\
0 & 0 & 0 & 0 & 0\\
\end{array}\right) \sim \left(\begin{array}{ccccc}
1 & 0 & 0 & -1 & -1\\
0 & 1 & 0 & 1 & 1\\
0 & 0 & 1 & 1 & 1\\
0 & 0 & 0 & 0 & 0\\
\end{array}\right)$$

Значит решение -- это линейная комбинация векторов $\left(\begin{array}{c}
1\\
-1\\
-1\\
1\\
0\\
\end{array}\right)$ и $\left(\begin{array}{c}
1\\
-1\\
-1\\
0\\
1\\
\end{array}\right)$ ^[Что бы их получить надо подставлять в качестве значений в столбцах, не входящих в единичную матрицу улучшенного ступенчатого вида, стандартные базисные векторы и вычислять оставшиеся значения.]

То есть $U = \begin{cases}
x_1 - x_2 - x_3 + x_4 = 0\\
x_1 - x_2 - x_3 + x_5 = 0
\end{cases}$.

### Нахождение суммы и пересечения подпространств


Сумма и пересечение подпространств -- это подпространства.

Чтобы найти сумму надо объединить векторы подпространств, заданных линейными оболочками.

Чтобы найти пересечение надо пересечь системы уравнений, задающих подпространства.

Как себя проверять? Должно выполняться $\dim(U + W) + \dim(U \cap W) = \dim U + \dim W$.

## Прямая сумма подпространств


## Нахождение линейного оператора, который переводит заданный набор векторов в другой заданный набор


## Образ и ядро линейного оператора


**критерий инъективности** Отображение инъективно $\iff$ его ядро тривиально.

Пусть $U$ и $W$ векторные пространства и $f: U \to W$ линейное отображение с матрицей $A$. Ядро и образ $f$ -- это подпространства в $U$ и $W$ соответственно.

Чтобы найти ядро оператора, заданного матрицей, нужно посчитать ее фундаментальную систему решений.

## Собственные значения и характеристический многочлен


$v$ -- (*собственный*) вектор оператора $f$ с *собственным значением* $\lambda \iff f(v) = \lambda v$.

Пусть матрица линейного отображения $f$ -- это $A$. $\det(A - t E)$ -- *характеристический многочлен*. $\det(A - t E) = 0$ -- *характеристическое уравнение*.

**критерий собственного значения** $\lambda$ -- собственное значение оператора $f\iff \lambda$ -- корень характеристического уравнения.

**факт** все вектора с собственным значением $\lambda$ образуют подпространство.

### Как найти базис подпространства, отвечающего собственному значению?


Найти ядро оператора $\lambda \operatorname{id} - f$, где $f$ -- линейный оператор, $\lambda$ его собственное значение, а $\operatorname{id}$ -- тождественный оператор.

### Диагонализируемость линейного оператора


Линейный оператор диагонализируем $\iff$ его характеристический многочлен раскладывается на линейные множители над полем векторного пространства $\iff$ векторное пространство раскладывается в прямую сумму собственных подпространств

*алгебраическая кратность* собственного значения $\lambda$ -- это его кратность, как корня характеристического уравнения.

*геометрическая кратность* собственного значения $\lambda$ -- это размерность векторного подпространства, отвечающего этому значению, а это в свою очередь размерность ядра $\lambda \operatorname{id} - f$, которая равна рангу матрицы $\lambda E - A_f$, где $A_f$ -- матрица оператора $f$.

## Жорданова форма


### Свойства жордановых клеток


- Сумма размерностей жордановых клеток с $\lambda$ на диагонали равна алгебраической кратности $\lambda$
- Количество клеток с $\lambda$ на диагонали равно геометрической кратности $\lambda$, то есть $\dim V_{\lambda}$
- Количество клеток с $\lambda$ на диагонали размерности $k\times k$ равно $\operatorname{rk}(A - \lambda E)^{k - 1} + \operatorname{rk}(A - \lambda E)^{k + 1} - 2\operatorname{rk}(A- \lambda E)^k$ (Абсолютно бессмысленная формула, которую я никогда не знала :)

### Как найти жорданову нормальную форму?


Пусть дана матрица $\left(\begin{array}{ccc}
3 & 0 & 8 \\
3 & -1 & 6 \\
-2 & 0 & -5
\end{array}\right)$.

Ищем ее характеристический многочлен $\det(A - tE) = \left|\begin{array}{ccc}
3 - t & 0 & 8 \\
3 & -1 - t & 6 \\
-2 & 0 & -5 - t
\end{array}\right| = (x + 1)^3$.

Далее найдем размерности клеток, пользуясь свойством $1$ и ...

## Минимальный многочлен


Это аннулирующий многочлен минимальной степени со старшим коэффицентом $1$. Обозначается $\mu_{f}(x)$, где $f$ -- линейное отображение.

**теорема Гамильтона-Кэли** $\mu_f(x) = \displaystyle \prod_{\lambda: \,\, \chi_{f}(\lambda) = 0}(x - \lambda)^\beta, \,\,\,\, \beta$ -- максимальный размер клеток с $\lambda$ в жордановой нормальной форме.

## Как посчитать функции от матриц


Найти минимальный многочлен матрицы (см. теорему выше). Поделить ряд Тейлора функции ^[Хочется, конечно, чтобы он к ней равномерно сходился] с остатком на минимальный многочлен. Остаток -- это многочлен степени на один меньшей, чем степень минимального многочлена. Чтобы найти коэффиценты остатка, подставляем корни минимального многочлена, в производные от равенства $f(x) = q(x)\mu_A(x) + r(x)$.


# Векторное пространство


:::: {#definition-0}

**Определение:**  *Векторное пространство* $V$ над полем $F$ -- это множество с операциями сложения $+: \,\,\,\, V \times V \to V$ и умножения $\cdot: \,\,\,\, F \times V \to V$, удовлетворяющими аксиомам:

$\forall a, b, c \in V, \,\,\,\, \forall \lambda, \mu \in F$

1. $a + (b + c) = (a + b) + c$ (ассоциативность)
2. $a + b = b + a$ (коммутативность)
3. $\exists \vec{0}:\,\,\,\, a + \vec{0} = a$ (существование *нулевого вектора*)
4. $\exists (-a) \in V: \,\,\,\, a + (-a) = \vec{0}$

5. $\lambda (\mu \cdot a) = (\lambda \mu) \cdot a$
6. $(\lambda + \mu)\cdot a = \lambda\cdot a + \mu\cdot a$
7. $\lambda \cdot (a + b) = \lambda \cdot a + \lambda\cdot b$
8. $\exists 1 \in F: \,\,\,\, 1 \cdot a = a$

::::

:::: {#definition-1}

**Определение:** Элементы векторного пространства $V$ -- *векторы*.

::::

:::: {#definition-2}

**Определение:** Пусть $V$ -- векторное пространство над $F$ с операциями сложения $+$ и умножения $-$. *Векторное подпространство* $V$ -- это $U \subset V$, такое что:

1. $\vec{0} \in U$ (нулевой вектор $V$ принадлежит $U$)
2. $\forall u, v \in U \,\,\,\, u + v \in U$ (замкнуто относительно сложения $V$)
3. $\forall u \in U, \lambda \in F \,\,\,\, \lambda \cdot u \in U$ (замкнуто относительно умножения $V$)

::::

:::: {#statement-0}

**Утверждение:**  Пусть $V$ -- векторное пространство над $F$. Векторное подпространство $U$ пространства $V$ является векторным пространством над полем $F$ относительно операций сложения и умножения, определенных для $V$.

*Доказательство:* Проверить аксиомы $\,\,\,\,\blacksquare$

::::

## Линейная зависимость векторов


:::: {#definition-3}

**Определение:**  Пусть в векторном пространстве $V$ над полем $F$ заданa система векторов $U = (v_1, \ldots, v_n)$. Выражение $\lambda_1 \cdot v_1 + \ldots + \lambda_n \cdot v_n, \,\,\,\, \lambda_i \in F$ -- это *линейная комбинация* системы векторов $U$.

Если $\forall i \in \{1, \ldots, n\} \,\,\,\, \lambda_i = 0$, то линейная комбинация *тривиальная*, иначе *нетривиальная*.

::::

:::: {#definition-4}

**Определение:**  Пусть в векторном пространстве $V$ над полем $F$ заданa система векторов $U = (v_1, \ldots, v_n)$. Если $\exists$ их нетривиальная линейная комбинация равная $0$, то система векторов $U$ *линейно зависима*.

::::

:::: {#definition-5}

**Определение:**  Пусть в векторном пространстве $V$ над полем $F$ заданa система векторов $U = (v_1, \ldots, v_n)$. Если только тривиальная линейная комбинация векторов $U$ равна $0$, то система векторов $U$ *линейно независима*.

::::

:::: {#definition-6}

**Определение:**  Пусть задана система векторов $V = (v_1, \ldots, v_n)$. Множество всех линейных комбинаций векторов системы $V$ -- это *линейная оболочка* $V$. Обозначается: $\langle V \rangle = \langle v_1, \ldots, v_n\rangle$.

$V$ называется *порождающей (системой)* линейной оболочки $V$.

::::

:::: {#statement-1}

**Утверждение:**  Линейная оболочка $\langle U \rangle = \langle u_1, \ldots, u_n\rangle, \,\,\,\, u_i \in V$($V$ векторное пространство) -- это векторное подпространство $V$.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#lemma-0}

**Лемма:**  Система векторов линейно зависима $\Leftrightarrow$ существует вектор этой системы линейно выражающийся через остальные.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#lemma-1}

**Лемма:**  (*Основная лемма о линейной зависимости*) Пусть $\{v_1, \ldots, v_m\} \subset \langle u_1, \ldots, u_n\rangle, \,\,\,\, m > n$. Тогда векторы $v_1, \ldots, v_m$ линейно зависимы.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

## Базис


:::: {#definition-7}

**Определение:**  *Базис* векторного пространства $V$ -- это:

1. Максимальная по включению линейно независимая система векторов $V$.
2. Система векторов, такая что любой вектор $V$ линейно выражается через векторы этой системы единственным образом.
3. Линейно независимая система векторов, такая что любой вектор $V$ линейно выражается через векторы этой системы.

::::

:::: {#statement-2}

**Утверждение:**  Все определения базиса эквивалентны. 

*Доказательство:* 

::::

:::: {#definition-8}

**Определение:**  Векторное пространство, порождающее множество которого конечно, называется *конечномерным*, иначе векторное пространство *бесконечномерно*.

::::

:::: {#statement-3}

**Утверждение:** В любом конечномерном векторном пространстве существует базис.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#statement-4}

**Утверждение:**  Количество векторов в любом базисе конечномерного векторного пространства одинаково.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#theorem-0}

**Теорема:**  Любую линейно независимую систему векторов в векторном пространстве можно дополнить до базиса.

*Доказательство:* Будем добавлять векторы до тех пор пока система остается линейно независимой $\Rightarrow$ получим максимальную по включению линейно независимую систему $\,\,\,\,\blacksquare$

::::

:::: {#theorem-1}

**Теорема:**  В $n$-мерном векторном пространстве любые $n$ линейно независимых вектора образуют базис.

*Доказательство:* Любые $n + 1$ вектора в $n$-мерном пространстве линейно зависимы, так как размерность -- это количество векторов в базисе. То есть любые $n$ векторов -это максимальная по включению линейно независимая система. Осталось доказать, что любой вектор пространства представим линейной комбинацией этих векторов. Но если это не так, то линейно независимы $n + 1$ вектор $\,\,\,\,\blacksquare$

::::

:::: {#statement-5}

**Утверждение:**  Пусть $U$ подпространство векторного пространства $V$. Тогда $\dim U \le \dim V$, при этом $\dim U = \dim V \Leftrightarrow U = V$.

*Доказательство:* Основная лемма о линейной зависимости $\,\,\,\,\blacksquare$

::::

:::: {#definition-9}

**Определение:**  Векторное пространство $U$ над полем $F$ *изоморфно* векторному пространству $V$ над полем $F$, если существует биекция $\varphi: \,\,\,\, U \to V$, такая что:

1. $\forall u_1, u_2 \in U \,\,\,\, \varphi(u_1 + u_2) = \varphi(u_1) + \varphi(u_2)$
2. $\forall u \in U, \lambda \in F \,\,\,\, \varphi(\lambda u) = \lambda \varphi(u)$

$\varphi$ называется *изоморфизм*.
Обозначается $U \cong V$.

::::

:::: {#theorem-2}

**Теорема:**  Пусть $U$ и $V$ конечномерные векторные пространства над полем $F$.
Тогда $$U \cong V \Leftrightarrow \dim U = \dim V$$

*Доказательство:* Изоморфизм переводит вектор базиса одного пространства в соответствующий вектор базиса другого $\,\,\,\,\blacksquare$

::::


# Переход от одного базиса к другому


Это было слишком много раз, чтобы писать заново.

Матрица перехода от базиса $e$ к базису $e’$ обозначается $C_{e \to e’}$.

### Свойства матрицы перехода

:::: {#statement-6}

**Утверждение:**  (*свойства матрицы перехода*)

Пусть $e, e’, e’’$ -- базисы в некотором конечномерном векторном пространстве.

1. $C_{e \to e’}$ -- невырождена.
2. $C_{e \to e} = E$.
3. $C_{e’ \to e} = C_{e \to e’}^{-1}$.
4. $C_{e \to e’}\cdot C_{e’ \to e’’} = C_{e’ \to e’’}$.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

## Сумма и пересечение векторных подпространств


:::: {#statement-7}

**Утверждение:**  Пусть $U, \,\,\,\, W$ подпространства векторного пространства $V$. Тогда $U \cap W$ подпространство $V$.

*Доказательство:* Проверим по определению.

1. $0$ принадлежит и $U$, и $W \Rightarrow$ принадлежит и пересечению.
2. Пусть $x, y \in U \cap W$, тогда $x + y \in U \cap W$.
3. $\,\,\,\,\blacksquare$

::::

:::: {#definition-10}

**Определение:**  Пусть $U, \,\,\,\, W$ подпространства векторного пространства $V$. *сумма* $U + W$ подпространств $U$ и $W$ -- это $U + W = \{u + w: \,\,\,\, u \in U, \,\,\,\, w \in W\}$.

::::

:::: {#statement-8}

**Утверждение:**  Пусть $U, \,\,\,\, W$ подпространства векторного пространства $V$. Тогда $U + W$ -- подпространство в $V$.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#theorem-3}

**Теорема:** (*формула Грассмана*)
Пусть $U, \,\,\,\, W$ подпространства векторного пространства $V$.
$$\dim U + \dim W = \dim (U \cap W) + \dim (U + W)$$

*Доказательство:*

![](img/vectors.png)

Пусть $e_1, \ldots, e_k$ -- базис в $U \cap W$,<br>
$e_1, \ldots, e_m$ -- базис в $U$,<br>
$e_1, \ldots, e_k, e_{m + 1}, \ldots, e_{n}$ -- базис в $W$. ($\dim W = n - m + k$).

Докажем, что $e_1, \ldots, e_n$ -- базис в $U + W$.

1. Любой вектор $x \in U + W$ представим выражается через базисы $U$ и $W$, а следовательно через $e_1, \ldots, e_n$.
2. Докажем что эти векторы линейно независимы. Пусть $$\underbrace{\mu_1 e_1+\ldots+\mu_k e_k}_{\vec{a}} + \underbrace{\mu_{k + 1} e_{k + 1} + \ldots + \mu_m e_{m}}_{\vec{b}} + \underbrace{\mu_{m + 1} e_{m + 1} + \ldots + \mu_n e_n}_{\vec{c}} = 0$$ 
Поколдуем $\,\,\,\,\blacksquare$

::::

## Прямая сумма подпространств

:::: {#definition-11}

**Определение:**  Пусть $U, \,\,\,\, W$ подпространства векторного пространства $V$. Сумма $U + W$ *прямая*, если $\forall x \in U + W \,\,\,\, \exists! \,\,u \in U, w \in W: \,\,\,\, u + w = x$.

Обозначается прямая сумма так: $U \oplus W$.

::::

:::: {#statement-9}

**Утверждение:**  Пусть $U, \,\,\,\, W$ подпространства векторного пространства $V$. Тогда $U + W$ -- прямая $\Leftrightarrow U \cap W = \{0\}$.

*Доказательство:* $$\Rightarrow$$

Пусть $U \cap W \ne \{0\}$, тогда $\exists x \in U \cap W$. $x = x_{\in U} + 0_{\in W} = 0_{\in U} + x_{\in W}$, то есть существует два представления $x$. противоречие.

$$\Leftarrow$$
Пусть $U + W$ не прямая сумма, тогда $\exists x \in U + W: \,\,\,\, x = u’ + w’ = u + w, \,\,\,\, u’, u \in U, \,\,\,\, w’, w \in W$. Значит $u’ - u \in U = w - w’ \in W$, то есть $U \cap W \ne \{0\}$. Противоречие $\,\,\,\,\blacksquare$

::::

:::: {#statement-10}

**Утверждение:**  Сумма подпространств $U = U_1 + U_2 + \ldots + U_n$ -- прямая $\Leftrightarrow \,\,\,\, \forall i \in \{1, \ldots, n\} \,\,\,\, U_i \cap (U_{i + 1} + \ldots + U_n) = \{0\}$.

*Доказательство:*

$$\Rightarrow$$
см. доказательство выше.
$$\Leftarrow$$
Пусть сумма не является прямой, тогда $\exists u \in U: \,\,\,\, u = \Sigma u_i = \Sigma u_i’, \,\,\,\, u_i, u_i’ \in U$. Возьмем первую ненулевую разность $u_i - u_i’$ и остальное перенесем вправо: $u_i - u_i’ = -u_{i + 1} + u_{i + 1}’ + \ldots - u_{n} + u_{n}’$. Следовательно пересечение содержит не только нулевой вектор. Противоречие $\,\,\,\,\blacksquare$

::::

# Линейные функции

:::: {#definition-12}

**Определение:** *Линейная функция* на векторном пространстве $V$ -- это отображение $\varphi: \,\,\,\, V \to F$, где $V$ векторное пространство над полем $F$, такое что:

1. $\forall x, y \in V \,\,\,\, \varphi(x + y) = \varphi(x) + \varphi(y)$.
2. $\forall x \in V, \lambda \in F \,\,\,\, \varphi(\lambda x) = \lambda \varphi(x)$.

::::

:::: {#statement-11}

**Утверждение:**  Множество всех линейных функций $V^{*}$ на векторном пространстве $V$ над полем $F$ -- это векторное пространство относительно поточечного сложения ($\forall \varphi, \psi \in V^{*} \,\,\,\,\forall v \in V \,\,\,\, (\varphi + \psi)(v) = \varphi(v) + \psi(v)$) и умножения на элементы поля $F$.

*Доказательство:* аксиомы $\,\,\,\,\blacksquare$

::::

:::: {#definition-13}

**Определение:**  $V^{*}$ *сопряженное* к $V$ векторное пространство.

::::

:::: {#statement-12}

**Утверждение:**  

1. Линейная функция на векторном пространстве $V$ однозначно задается значениями на векторах некоторого базиса $V$.
2. Пусть $V$ векторное пространство над полем $F$ и $\dim V = n$. Тогда любые $n$ чисел из $F$ задают линейную функцию на $V$.
3. Пусть $\varphi$ и $\psi$ линейные функции на векторном пространстве $V$. Тогда $\varphi = \psi \Leftrightarrow$ $\varphi$ принимает на базисных векторах $V$ те же значения, что и $\psi$ (совпадают значения на каждом векторе).
4. какое-то там отображение.

*Доказательство:* Пусть $\varphi$ линейная функция на $V$, а $e_1, \ldots, e_n$ базис в $V$. Тогда $\forall v \in V \,\,\,\, v = \lambda_1 e_1 + \ldots + \lambda_n e_n$ и такое представление единственно.
$\varphi(v) = \varphi(\lambda_1 e_1 + \ldots + \lambda_n e_n) = \lambda_1\varphi(e_1) + \ldots + \lambda_n \varphi(e_n)$. Обозначим $\varphi(e_i) = a_i$. Честно говоря, я не понимаю, что значит задает, а поэтому не знаю, что тут доказывать $\,\,\,\,\blacksquare$ 

::::

## Сопряженные базисы


:::: {#statement-13}

**Утверждение:**  Пусть $V$ векторное пространство над полем $F$, $e_1, \ldots, e_n$ базис в $V$. Тогда множество $\{\varepsilon^1, \ldots, \varepsilon^n\}$, где $\varepsilon^j(e_i) = \begin{cases}
    0, i \ne j\\
    1, i = j
\end{cases}$ -- базис в $V^{*}$.

*Доказательство:* Докажем, что векторы(линейные функции) $\varepsilon^1, \ldots, \varepsilon^n$ линейно независимы. Рассмотрим их линейную комбинацию равную $0$: $\lambda_1\varepsilon^1+ \ldots + \lambda_n\varepsilon^n = 0$. Чтобы функции (в данном случае тождественный ноль и $\lambda_1\varepsilon^1+ \ldots + \lambda_n\varepsilon^n$) были равны, необходимо совпадение значений на базисных векторах. Значение $\lambda_1\varepsilon^1+ \ldots + \lambda_n\varepsilon^n$ на $e_i$ равно $\lambda_i$, а следовательно $\lambda_i = 0 \,\,\,\,\forall i$. 

Осталось доказать, что любая линейная функция на $V$ задается (😉) через $\varepsilon_i$-е, ну, делается это так: $\varphi = \varphi(e_1)\varepsilon^1 +\ldots + \varphi(e_n)\varepsilon^n \,\,\,\,\blacksquare$

::::

:::: {#corollary-0}

**Следствие:**  $\dim V = \dim V^{*}$ и $V \cong V^{*}$

*Доказательство:*

::::

:::: {#definition-14}

**Определение:**  Базис $\{\varepsilon^1, \ldots, \varepsilon^n\}$ в $V^{*}$ *сопряженный* к базису $e_1, \ldots, e_n$ в $V$.

::::

## Второе сопряженное пространство


:::: {#definition-15}

**Определение:**  $V^{**}$ -- это $(V^{*})^{*}$, то есть сопряженное к $V^{*}$ и *второе сопряженное к* $V$ векторное пространство ($V^{*}$ сопряжено векторному пространству $V$ 🙄).

::::

:::: {#statement-14}

**Утверждение:** Пусть $V$ векторное пространство. Каждому вектору $x \in V$ сопоставим отображение $f_x: \,\,\,\, V^{*} \to F$, такое что $f_x(\varphi) = \varphi(x)$. Тогда $f_x \in V^{**}$.

*Доказательство:* 

1. $f_x(\varphi + \psi) = (\varphi + \psi)(x) = \varphi(x) + \psi(x) = f_x(\varphi) + f_x(\psi)$.
2. $f_x(\lambda \varphi) = \lambda \varphi(x) = \lambda f_x(\varphi) \,\,\,\,\blacksquare$

::::

:::: {#theorem-4}

**Теорема:**  (*Канонический изоморфизм* $V$ и $V^{**}$)
Отображение $\Phi: \,\,\,\, v \mapsto f_v$ -- изоморфизм $V$ и $V^{**}$.

*Доказательство:* 

1. Линейность очевидна.
2. Биективность

a. Проверим инъективность. Пусть $\exists x, y \in V: \,\,\,\, x \ne y$ и $\Phi(x) = \Phi(y)$. Пусть $\varepsilon^1, \ldots, \varepsilon^n$ базис в $V^{*}$ сопряженный базису $e_1, \ldots, e_n$ в $V$. Тогда $\Phi(x) = f_x$ на $i$-ом векторе $V^{*} \,\,\,\, f_x(\varepsilon^i) = \varepsilon^i(x) = x_i$, где $x_i$ $i$-я координата вектора $x$ в базисе $e_1, \ldots, e_n$. Аналогично $y_i$ $i$-я координата вектора $y$ в базисе $e_1, \ldots, e_n$, так как $\Phi(x) = \Phi(y)$ эти координаты совпадают, а следовательно $x = y$. Противоречие.
b. Проверим сюрьективность. Пусть $e_1, \ldots, e_n$ -- базис в $V$.<br>$\varepsilon_1, \ldots, \varepsilon_n$ -- базис в $V^{*}$.<br>$f_{e_1}, \ldots, f_{e_n}$ -- базис в $V^{**}$.<br>$f_{e_i}(\varepsilon^j) = \varepsilon^j(e_i) = \begin{cases} 0, \,\,\,\, i \ne j \\ 1, \,\,\,\, i = j \end{cases}$(зачем это?)<br>$\forall v \in V \,\,\,\,\Phi(v) = \Phi(\lambda_1 e_1 + \ldots + \lambda_n e_n) = \lambda_1\Phi(e_1) + \ldots + \lambda_n \Phi(e_n) = \lambda_1 f_{e_1} + \ldots \lambda_n f_{e_n} \,\,\,\,\blacksquare$
(Непонятно)

::::

# Матрица перехода сопряженного базиса

:::: {#theorem-5}

**Теорема:**  Пусть $V$ -- векторное пространство, $B = \{e_1, \ldots, e_n\}$ и $\tilde{B} = \{\tilde{e}_1, \ldots, \tilde{e}_n\}$ -- базисы $V$. $B^{*} = \{\varepsilon^1, \ldots, \varepsilon^n\}$ и $\tilde{B}^{*} = \{\tilde{\varepsilon}^1, \ldots, \tilde{\varepsilon}^n\}$ -- сопряженные к $B$ и $\tilde{B}$ базисы. Тогда $C_{B \to \tilde{B}}^T = C_{\tilde{B}^{*} \to B^{*}}$.

*Доказательство:*

$$\tilde{e}_1 = \lambda_{11}e_1 + \ldots + \lambda_{n1}e_n$$
$$\tilde{e}_2 = \lambda_{12}e_1 + \ldots + \lambda_{n2}e_n$$
$$\vdots$$
$$\tilde{e}_n = \lambda_{1n}e_1 + \ldots + \lambda_{nn}e_n$$
$$C_{B \to \tilde{B}} = \left(\begin{array}{ccc}
    \lambda_{11} & \dots & \lambda_{1n}\\
    \vdots & \ddots & \vdots\\
    \lambda_{n1} & \dots & \lambda_{nn}\\
\end{array}\right)$$

$$\tilde{\varepsilon}^1 = \mu_{11}\varepsilon^1 + \ldots + \mu_{n1}\varepsilon^n$$
$$\tilde{\varepsilon}^2 = \mu_{12}\varepsilon^1 + \ldots + \mu_{n2}\varepsilon^n$$
$$\vdots$$
$$\tilde{\varepsilon}^n = \mu_{1n}\varepsilon^1 + \ldots + \mu_{nn}\varepsilon^n$$
$$C_{B^{*} \to \tilde{B}^{*}} = \left(\begin{array}{ccc}
    \mu_{11} & \dots & \mu_{1n}\\
    \vdots & \ddots & \vdots\\
    \mu_{n1} & \dots & \mu_{nn}\\
\end{array}\right)$$

$$\delta_i^j = \tilde{\varepsilon}_i(\tilde{e}_j) = (\mu_{1i}\varepsilon^1 + \ldots + \mu_{ni}\varepsilon^n)(\lambda_{1j}e_1 + \ldots + \lambda_{nj}e_n) = \displaystyle \sum_{k = 1}^{n}\mu_{ki}\lambda_{kj} =$$
$$=\displaystyle \sum_{k = 1}^{n}\lambda_{kj}\mu_{ik}^T \Rightarrow C_{B \to \tilde{B}}\cdot C_{B^{*} \to \tilde{B}^{*}}^T = E \,\,\,\,\blacksquare$$

::::

## Ядро линейной функции(линейного функционала)

:::: {#definition-16}

**Определение:**  Пусть $\varphi$ -- линейная функция на векторном пространстве $V$. Тогда *ядро* $\varphi$ -- это $\ker \varphi = \{v \in V: \,\,\,\, \varphi(v) = 0\}$.

::::

:::: {#statement-15}

**Утверждение:**  Пусть $\varphi$ -- линейная функция на векторном пространстве $V$. Тогда $\ker \varphi$ -- подпространство $V$.

*Доказательство:* 

1. $0 \in \ker \varphi$, так как $\varphi(0) = \varphi(0 + 0) = \varphi(0) + \varphi(0) \Rightarrow \varphi(0) = 0$.
2. Пусть $u, v \in \ker \varphi \Rightarrow \varphi(u) + \varphi(v) = 0 + 0 = 0 = \varphi(u + v) \Rightarrow u + v \in \ker \varphi$.
3. $\,\,\,\,\blacksquare$

::::

:::: {#statement-16}

**Утверждение:**  Пусть $V$ векторное пространство, тогда любое его подпространство $U$ может быть представлено как конечное пересечение ядер некоторых линейных функций на $V$.

*Доказательство:* Пусть $B = \{e_1, \ldots, e_m\}$ -- базис в $U$. Дополним его до базиса $V$: $B’ = \{e_1, \ldots, e_m, e_{m + 1} \ldots, e_n\}$.

Пусть $v \in V$, разложим его по базису: $v = \lambda_1e_1 + \ldots + \lambda_n e_n$.

Рассмотрим значение $i$-ого вектора базиса сопряженного к $B’$: $\varepsilon^i(v) = \varepsilon^i(\lambda_1e_1 + \ldots + \lambda_n e_n) = \lambda_i$, то есть $v \in \ker \varepsilon^i \Rightarrow i$-я координата $v$ равна $0$($\lambda_i = 0$).

Пусть $u \in U, \,\,\,\, u = \mu_1e_1 + \ldots + \mu_m e_m \Rightarrow \mu_{m + 1}, \ldots, \mu_n = 0$, иначе векторы базиса будут линейно зависимы, следовательно $u \in \ker\varepsilon^{m + 1}, \ldots, \ker\varepsilon^n \Rightarrow \displaystyle\bigcap\limits_{i = m + 1}^{n}\ker \varepsilon^i = U \,\,\,\,\blacksquare$

::::

:::: {#statement-17}

**Утверждение:**  Пусть $V$ -- векторное пространство, $B = \{e_1, \ldots, e_m, e_{m + 1}, \ldots, e_n\}$ -- базис $V$, $U$ -- попространство $V$, $B’ = \{e_1, \ldots, e_m\}$ -- базис $U$. Тогда $U$ -- это множество решений некоторой однородной системы линейных уравнений.

*Доказательство:* Рассмотрим некоторой базис $\tilde{B} = \{\tilde{e}_1, \ldots, \tilde{e}_n\}$.

Тогда координаты вектора в базисе $B$ выражаются через координаты в базисе $\tilde{B}$ так: $\left(\begin{array}{c}
x_1\\
x_2\\
\vdots\\
x_n
\end{array}\right) = C_{B \to \tilde{B}}\left(\begin{array}{c}
\tilde{x}_1\\
\tilde{x}_2\\
\vdots\\
\tilde{x}_n
\end{array}\right)$.<br>
Пусть $C_{B \to \tilde{B}}^{*}$ -- это матрица, содержащая строки матрицы $C_{B \to \tilde{B}}$ c $m + 1$ до $n$.
$\forall u \in U \left(\begin{array}{c}
x_1\\
\vdots\\
x_{m + 1}\\
\vdots\\
x_n
\end{array}\right) = C_{B \to \tilde{B}}\left(\begin{array}{c}
\tilde{x}_1\\
\vdots\\
\tilde{x}_{m + 1}\\
\vdots\\
\tilde{x}_n
\end{array}\right)$, где $x_{m + 1}, \ldots, x_n = 0$. Значит $u \in U \Leftrightarrow C_{B \to \tilde{B}}^{*}\left(\begin{array}{c}
\tilde{x}_{m + 1}\\
\vdots\\
\tilde{x}_n
\end{array}\right) = 0 \,\,\,\,\blacksquare$

::::

## Линейные отображения


:::: {#definition-17}

**Определение:**  Пусть $U$ и $W$ -- векторные пространства над полем $F$. $\varphi: \,\,\,\, V \to W$ -- *линейное отображение*, если:

1. $\forall u_1, u_2 \in V \,\,\,\, \varphi(u_1 + u_2) = \varphi(u_1) + \varphi(u_2)$
2. $\forall u \in U, \,\,\,\, \lambda \in F \,\,\,\, \varphi(\lambda u) = \lambda \varphi(u)$

::::

### Матрицы линейных отображений


:::: {#definition-18}

**Определение:**  Пусть $U$ и $W$ -- векторные пространства над полем $F$, $\varphi: U \to W$ -- линейное отображение. Пусть $B = \{e_1, \ldots, e_n\}$ -- базис $U$, $B’ = \{f_1, \ldots, f_m\}$ -- базис $W$.

$$u \in U \,\,\,\, u = \lambda_1 e_1 + \ldots \lambda_n e_n$$
$$\varphi(u) = \lambda_1 \varphi(e_1) + \ldots + \lambda_n \varphi(e_n)$$
$$w_1 = \varphi(e_1), \ldots, w_n = \varphi(e_n)$$
$$w_1 = \mu_{11} f_1 + \ldots + \mu_{m1} f_m$$
$$\vdots$$
$$w_n = \mu_{1n} f_1 + \ldots + \mu_{mn} f_m$$
$$\Downarrow$$
$$\mathcal{A} = \left(\begin{array}{ccc}
\mu_{11} & \dots & \mu_{1n}\\
\vdots & \ddots & \vdots\\
\mu_{m1} & \dots & \mu_{mn}
\end{array}\right)$$ -- *матрица линейного отображения* $\varphi$ относительно базисов $B$ и $B’$.

::::

:::: {#statement-18}

**Утверждение:**  Пусть $U$ и $W$ -- векторные пространства над полем $F$, $\varphi: U \to W$ -- линейное отображение. Пусть $B, \tilde{B}$ -- базисы $U$, $B’, \tilde{B}’$ -- базисы $W$. $\mathcal{A}$ -- матрица $\varphi$ относительно $B$ и $B’$, $\mathcal{A}’$ -- матрица $\varphi$ относительно $\tilde{B}$ и $\tilde{B}’$. Тогда $$\mathcal{A}’ = C_{\tilde{B} \to \tilde{B}’}^{-1}\mathcal{A}C_{B \to B’}$$

*Доказательство:* записать все в матричном виде ($Y = \mathcal{A}X$, $Y$ -- координаты вектора в $W$, $X$ -- координаты вектора в $U$) $\,\,\,\,\blacksquare$

::::

## Ядро и образ линейного отображения


:::: {#definition-19}

**Определение:**  Пусть $U$ и $W$ -- векторные пространства над полем $F$, $\varphi: U \to W$ -- линейное отображение. *Ядро* $\varphi$ -- это $\ker \varphi = \{u \in U: \,\,\,\, \varphi(u) = 0\}$.

::::

:::: {#definition-20}

**Определение:**  Пусть $U$ и $W$ -- векторные пространства над полем $F$, $\varphi: U \to W$ -- линейное отображение. *Образ* $\varphi$ -- это $\operatorname{Img} \varphi = \{w \in W: \,\,\,\,\exists u \in U \,\,\,\, \varphi(u) = w\}$.

::::

:::: {#statement-19}

**Утверждение:**  Пусть $U$ и $W$ -- векторные пространства над полем $F$, $\varphi: U \to W$ -- линейное отображение. Тогда $\ker \varphi$ подпространство в $U$ и $\operatorname{Img} \varphi$ подпространство в $W$.

*Доказательство:* очев $\,\,\,\,\blacksquare$

::::

:::: {#statement-20}

**Утверждение:**  Пусть $U$ и $W$ -- векторные пространства над полем $F$, $\varphi: U \to W$ -- линейное отображение.

$\varphi$ -- сюръективно $\Leftrightarrow \operatorname{Img} \varphi = W$

$\varphi$ -- инъективно $\Leftrightarrow \ker \varphi = \{0\}$

*Доказательство:* ну, почти очев $\,\,\,\,\blacksquare$

::::

# Еще про ядра и образы линейных отображений


:::: {#statement-21}

**Утверждение:**  Пусть $\varphi$ -- линейное отображение векторных пространств $U$ и $W$, $e_1, \ldots, e_n$ -- базис в $U$. Тогда
$$\operatorname{img} \varphi = \langle \varphi(e_1), \ldots, \varphi(e_n) \rangle$$

*Доказательство:* $\forall u \in U \,\,\,\, \exists \lambda_1, \ldots, \lambda_n: \,\,\,\, u = \lambda_1 e_1 + \ldots + \lambda_n e_n \Rightarrow \forall w \in W:$

$\exists u \in U: \,\,\,\, \varphi(u) = w \,\,\,\, w \in \langle \varphi(e_1), \ldots, \varphi(e_n) \rangle \,\,\,\,\blacksquare$

::::

:::: {#definition-21}

**Определение:**  Пусть $\varphi$ -- линейное отображение векторных пространств $U$ и $W$. $\dim \operatorname{img} \varphi$ -- это *ранг линейного отображения* $\varphi$.

::::

:::: {#statement-22}

**Утверждение:**  Пусть $\varphi$ -- линейное отображение векторных пространств $U$ и $W$. Тогда $$\dim \operatorname{img} \varphi + \dim \ker \varphi = \dim U$$

*Доказательство:* Пусть $e_1, \ldots, e_m$ -- базис $\ker \varphi$, дополним его до базиса $U \Rightarrow e_1, \ldots, e_m, e_{m + 1}, \ldots, e_n$ -- базис $U$. По предыдущему утверждению $\operatorname{img} \varphi = \langle \varphi(e_1), \ldots, \varphi(e_m), \varphi(e_{m + 1}), \ldots, \varphi(e_n) \rangle$. $\varphi(e_1) = 0, \ldots, \varphi(e_m) = 0$, так как $e_1, \ldots, e_m \in \ker \varphi \Rightarrow \operatorname{img} \varphi = \langle \varphi(e_{m + 1}), \ldots, \varphi(e_n) \rangle$. Докажем, что векторы $\varphi(e_{m + 1}), \ldots, \varphi(e_n)$ линейно независимы, то есть образуют базис $\operatorname{img} \varphi$. Рассмотрим их линейную комбинацию равную нулю: $\lambda_{m + 1} \varphi(e_{m + 1}) + \ldots + \lambda_n\varphi(e_n) = \varphi(\lambda_{m + 1} e_{m + 1} + \ldots + \lambda_n e_n) = 0 \Rightarrow$

$\Rightarrow \lambda_{m + 1} e_{m + 1} + \ldots + \lambda_n e_n \in \ker \varphi \Rightarrow \exists \lambda_1, \ldots, \lambda_m:$

$\lambda_{m + 1} e_{m + 1} + \ldots + \lambda_n e_n = \lambda_1 e_1 + \ldots + \lambda_m e_m$, так как векторы $e_1, \ldots, e_n$ линейно независимы $\lambda_{m + 1} = 0, \ldots, \lambda_{n} = 0 \,\,\,\,\blacksquare$

::::

## Линейные операторы и их матрицы


:::: {#definition-22}

**Определение:**  Пусть $\varphi$ -- линейное отображение векторного пространства $V$ в себя. Тогда $\varphi$ -- это *линейный оператор* пространства $V$.

::::

Пусть $V$ -- векторное пространство над полем $F$, $\varphi$ -- линейный оператор на $V$, $B = \{e_1, \ldots, e_n\}$ -- базис $V$. 

$$\varphi(e_1) = \lambda_{11} e_1 + \ldots + \lambda_{n1} e_n$$
$$\vdots$$
$$\varphi(e_n) = \lambda_{1n} e_1 + \ldots + \lambda_{nn} e_n$$
$$\Downarrow$$
$$A = \left(\begin{array}{ccc}
\lambda_{11} & \dots & \lambda_{1n}\\
\vdots & \ddots & \vdots\\
\lambda_{n1} & \dots & \lambda_{nn}
\end{array}\right)$$
$$\left(\begin{array}{c}
\varphi(e_1)\\
\vdots\\
\varphi(e_n)
\end{array}\right) = A^T \left(\begin{array}{c}
x_1\\
\vdots\\
x_n
\end{array}\right)$$
$$\left(\begin{array}{ccc}
\varphi(e_1) & \dots & \varphi(e_n)
\end{array}\right) = \left(\begin{array}{ccc}
e_1 & \dots & e_n
\end{array}\right)A$$

Пусть $x \in V$ имеет координаты $x_1, \ldots, x_n$, а $y = \varphi(x)$ имеет координаты $y_1, \ldots, y_n$. 
$$\left(\begin{array}{ccc}
e_1 & \dots & e_n
\end{array}\right)\left(\begin{array}{c}
y_1\\
\vdots\\
y_n
\end{array}\right) = \varphi(x) = \varphi(x_1 e_1 + \ldots + x_n e_n)=$$
$$= x_1 \varphi(e_1) + \ldots + x_n \varphi(e_n) = \left(\begin{array}{ccc}
\varphi(e_1) & \dots & \varphi(e_n)
\end{array}\right) \left(\begin{array}{c}
x_1\\
\vdots\\
x_n
\end{array}\right)$$
$$\Downarrow$$
$$\left(\begin{array}{c}
y_1\\
\vdots\\
y_n
\end{array}\right) = A \left(\begin{array}{c}
x_1\\
\vdots\\
x_n
\end{array}\right)$$

:::: {#definition-23}

**Определение:**  $A$ -- *матрица линейного оператора* $\varphi$ относительно базиса $e_1, \ldots, e_n$.

::::

:::: {#statement-23}

**Утверждение:**  Пусть $V$ -- векторное пространство, $\varphi$ -- линейный оператор на $V$, $B, \tilde{B}$ -- базисы $V$, $A, \tilde{A}$ -- матрицы линейного оператора $\varphi$ относительно $B, \tilde{B}$ соответственно. Тогда $$\tilde{A} = C^{-1}_{B \to \tilde{B}}A C_{B \to \tilde{B}}$$

*Доказательство:* следует отсюда $\,\,\,\,\blacksquare$

::::

:::: {#statement-24}

**Утверждение:**  

1. Ранг матрицы линейного оператора не зависит от базиса.
2. Определитель матрицы линейного оператора не зависит от базиса.

*Доказательство:* Пусть $V$ -- векторное пространство, $\varphi$ -- линейный оператор на $V$, $B, \tilde{B}$ -- базисы $V$, $A, \tilde{A}$ -- матрицы линейного оператора $\varphi$ относительно $B, \tilde{B}$ соответственно. 

1. $\tilde{A} = C^{-1}_{B \to \tilde{B}}A C_{B \to \tilde{B}} \Rightarrow$ строки матрицы $A$ линейно выражаются через строки матрицы $\tilde{A} \,\,\,\,\blacksquare$
2. $|\tilde{A}| = |C^{-1}_{B \to \tilde{B}}A C_{B \to \tilde{B}}| = |C^{-1}_{B \to \tilde{B}}||C_{B \to \tilde{B}}||A| = |A| \,\,\,\,\blacksquare$ 

::::

:::: {#statement-25}

**Утверждение:**  Матрица $A$ линейного оператора $\varphi$ на векторном пространстве $V$ невырождена $\Leftrightarrow$ $\varphi$ -- обратимо.

*Доказательство:*

::::

:::: {#statement-26}

**Утверждение:**  Пусть $\varphi$ -- линейное отображение векторных пространств $U$ и $W$. $\ker \varphi = \{0\}$ и $\operatorname{img} \varphi = W$ $\Leftrightarrow$ $\varphi$ -- обратимо.

*Доказательство:* $$\Rightarrow$$

$\varphi$ - биекция
$$\Leftarrow$$
$\varphi$ -- обратимо, следовательно инъекция и сюръекция $\Rightarrow \ker \varphi = \{0\}$ и $\operatorname{img} \varphi = W \,\,\,\,\blacksquare$ 

::::

:::: {#statement-27}

**Утверждение:**  Пусть $\varphi$ -- линейный оператор пространства $V$. Тогда 

1. $\varphi$ обратимо $\Leftrightarrow \ker \varphi = \{0\}$.
2. $\varphi$ обратимо $\Leftrightarrow \operatorname{img} \varphi = V$.

*Доказательство:* это $+$ это $\,\,\,\,\blacksquare$

::::

## Определение алгебры, алгебра линейных операторов


:::: {#definition-24}

**Определение:**  *Алгебра* над полем $F$ -- это множество $\mathfrak{A}$ с операциями сложения $+: \mathfrak{A}\times \mathfrak{A} \to \mathfrak{A}$, умножения $\cdot: \mathfrak{A}\times \mathfrak{A} \to \mathfrak{A}$ и умножения на числа из поля $F$ $\cdot: F\times \mathfrak{A} \to \mathfrak{A}$, удовлетворяющих:

1. Относительно сложения и умножения $\mathfrak{A}$ -- кольцо.
2. Относительно сложения и умножения на число $\mathfrak{A}$ -- векторное пространство над $F$.
3. $\forall x, y \in \mathfrak{A}, \,\,\,\, \lambda \in F, \,\,\,\, \lambda(xy) = (\lambda x)y = x (\lambda y)$.

::::

:::: {#definition-25}

**Определение:**  Множество всех линейных операторов на векторном пространстве $V$ обозначается $\operatorname{end} V$.

::::

:::: {#statement-28}

**Утверждение:**  Пусть $V$ векторное пространство над полем $F$. Тогда $\operatorname{end} V$ -- алгебра над полем $F$ относительно операций:

1. $\forall \mathcal{A}, \mathcal{B} \in \operatorname{end} V,\,\,\,\, \forall v \in V \,\,\,\, (\mathcal{A} + \mathcal{B})(x) = \mathcal{A}(x) + \mathcal{B}(x)$.
2. $\forall \mathcal{A}, \mathcal{B} \in \operatorname{end} V,\,\,\,\, \forall v \in V \,\,\,\, (\mathcal{A} \mathcal{B})(x) = \mathcal{A}(\mathcal{B}(x))$.
3. $\forall \mathcal{A} \in \operatorname{end} V,\,\,\,\, \forall \lambda \in F, \,\,\,\, \forall v \in V \,\,\,\, \lambda\mathcal{A}(x) = \mathcal{A}(\lambda x)$.

*Доказательство:* очев $\,\,\,\,\blacksquare$

::::

:::: {#definition-26}

**Определение:**  Алгебра $\mathfrak{C}$ над $F$ *изоморфна* алгебре $\mathfrak{B}$ над $F$, если $\mathfrak{C}$ изоморфно $\mathfrak{B}$, как кольцо и как векторное пространство над $F$. Обозначается $\mathfrak{C} \cong \mathfrak{B}$.

::::

:::: {#definition-27}

**Определение:**  Множество всех матриц $n \times n$ с элементами из поля $F$ обозначается $\mathbf{M}_{n}(F)$.

::::

:::: {#statement-29}

**Утверждение:**  $M_{n}(F)$ -- алгебра над полем $F$ относительно операций матричного сложения, матричного умножения и умножения каждого элемента матрицы на элемент из поля $F$.

*Доказательство:* очев $\,\,\,\,\blacksquare$

::::

:::: {#statement-30}

**Утверждение:**  Пусть $V$ -- векторное пространство над полем $F$. Тогда $$\operatorname{end} V \cong \mathbf{M}_{n}(F)$$

*Доказательство:* Построим биекцию $\varphi: \mathcal{A} \in \operatorname{end} V \mapsto A \in \mathbf{M}_{n}(F)$, где $A$ -- матрица линейного оператора $\mathcal{A} \,\,\,\,\blacksquare$

::::

## Инвариантные подпространства


:::: {#definition-28}

**Определение:**  Пусть $U$ подпространство векторного пространства $V$ над полем $F$, $\mathcal{A}$ -- линейный оператор на $V$. $U$ *инвариантное (пространство)* остносительно $\mathcal{A}$, если $\forall u \in U \,\,\,\, \mathcal{A}(u) \in U$.

::::

:::: {#definition-29}

**Определение:**  Если $U$ инвариантное пространство относительно линейного оператора $\mathcal{A}$, то ограничение $\mathcal{A}$ на $U$ обозначается $\mathcal{A}_{\vert U}$.

::::

:::: {#statement-31}

**Утверждение:**  $\mathcal{A}_{\vert U}$ -- линейный оператор $U$.

*Доказательство:*

::::

# Собственные векторы


:::: {#definition-30}

**Определение:**  Пусть $V$ -- векторное пространство над полем $F$, $\mathcal{A}$ -- линейный оператор на $V$. $v \ne 0 \in V$ -- *собственный вектор* линейного оператора $\mathcal{A}$, если $\exists \lambda \in F: \,\,\,\, \mathcal{A}(v) = \lambda v$.

::::

$\lambda$ -- *собственное значение* оператора $\mathcal{A}$.(вектор $v$ *отвечает* собственному значению $\lambda$).

:::: {#statement-32}

**Утверждение:** Пусть $V$ -- векторное пространство над полем $F$, $\mathcal{A}$ -- линейный оператор на $V$. Если в $V$ существует базис из собственных векторов $\{e_1, \ldots, e_n\}$ оператора $\mathcal{A}$, отвечающих собственным значениям $\lambda_1, \ldots, \lambda_n$, то матрица $A$ линейного оператора $\mathcal{A}$ в этом базисе имеет вид:
 $$A = \left(\begin{array}{cccc}
    \lambda_1 & 0 & \dots & 0\\
    0 & \lambda_2 & \ldots & 0\\
    \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & \dots & \lambda_n
 \end{array}\right)$$

 *Доказательство:* $\,\,\,\,\blacksquare$

::::

### Характеристическое уравнение и многочлен


:::: {#definition-31}

**Определение:**  $\mathcal{I}$ -- *тождественный линейный оператор*, то есть $\forall v \in V: \,\,\,\, \mathcal{I}(v) = v$.

::::

:::: {#definition-32}

**Определение:**  Пусть $V$ -- векторное пространство над полем $F$, $\mathcal{A}$ -- линейный оператор на $V$, $A$ -- матрица $\mathcal{A}$ в некотором базисе.<br>$\chi(t) = \det \left(\mathcal{A} - t E\right)$ -- *характеристический многочлен* линейного оператора $\mathcal{A}$.<br>Уравнение $\chi(t) = 0$ -- *характеристическое уравнение* линейного оператора $\mathcal{A}$.

::::

:::: {#statement-33}

**Утверждение:** (*определение корректно*) Определение корректно, то есть характеристический многочлен и характеристическое уравнение не зависят от выбора базиса.

*Доказательство:* Пусть $V$ -- векторное пространство над полем $F$, $\mathcal{A}$ -- линейный оператор на $V$, $A$ -- матрица $\mathcal{A}$ в базисе $B$, $\tilde{A}$ -- матрица $\mathcal{A}$ в базисе $\tilde{B}$.

$$|\tilde{A} - t E| = |C_{B \to \tilde{B}}^{-1}A C_{B \to \tilde{B}} - t C_{B \to \tilde{B}}^{-1}C_{B \to \tilde{B}}| = |A - t E| \,\,\,\,\blacksquare$$

::::

:::: {#statement-34}

**Утверждение:**  Пусть $V$ -- векторное пространство над полем $F$, $\mathcal{A}$ -- линейный оператор на $V$. Тогда $\lambda \in F$ -- собственное значение $\mathcal{A} \Leftrightarrow \lambda$ -- корень характеристического уравнения $\mathcal{A}$.

*Доказательство:* $$\Leftarrow$$

$\lambda$ -- корень $\chi(t) \Rightarrow \det(A - \lambda E) = 0 \Rightarrow$
$$\Rightarrow \exists x = \left(\begin{array}{c}
x_1^0\\
\vdots\\
x_n^0
\end{array} \right) \in V: \,\,\,\, (A - \lambda E)\left(\begin{array}{c}
x_1^0\\
\vdots\\
x_n^0
\end{array} \right) = 0 \Rightarrow$$
$$\Rightarrow (\mathcal{A} - \lambda \mathcal{I})(x) = 0 \Rightarrow \mathcal{A}(x) = \lambda x$$
$$\Rightarrow$$
Те же рассуждения в обратную сторону $\,\,\,\,\blacksquare$

::::

## Собственные подпространства


:::: {#definition-33}

**Определение:**  Пусть $V$ -- векторное пространство над полем $F$, $\mathcal{A}$ -- линейный оператор на $V$, $\lambda$ -- собственное значение $\mathcal{A}$. $V_{\lambda}$ -- это множество собственных векторов, отвечающих значению $\lambda$ и нулевой вектор.

::::

:::: {#statement-35}

**Утверждение:**  $V_{\lambda}$ -- подпространство векторного пространства $V$.

*Доказательство:* очев $\,\,\,\,\blacksquare$

::::

:::: {#definition-34}

**Определение:**  $V_{\lambda}$ -- *собственное подпространство*.

::::

:::: {#statement-36}

**Утверждение:**  Пусть $V$ -- векторное пространство над полем $F$, $\mathcal{A}$ -- линейный оператор на $V$, $\lambda$ -- собственное значение $\mathcal{A}$. Тогда
$$V_{\lambda} = \ker (\mathcal{A} - \lambda \mathcal{I})$$

*Доказательство:* $V_{\lambda} = \{v \in V: \,\,\,\, \mathcal{A}(v) = \lambda v\} \,\,\,\,\blacksquare$

::::

:::: {#statement-37}

**Утверждение:**  Пусть $V$ -- векторное пространство над полем $F$ размерности $n$, $\mathcal{A}$ -- линейный оператор на $V$, $\lambda$ -- собственное значение $\mathcal{A}$. $\dim V_{\lambda} = \dim \ker (\mathcal{A} - \lambda \mathcal{I}) = n - \dim \operatorname{img} (\mathcal{A} - \lambda \mathcal{I})$.

*Доказательство:* следует отсюда $\,\,\,\,\blacksquare$

::::

:::: {#statement-38}

**Утверждение:**  Пусть $V$ -- векторное пространство над полем $F$ размерности $n$, $\mathcal{A}$ -- линейный оператор на $V$, $\lambda$ -- корень кратности $k$ характеристического многочлена $\chi(t) = |\mathcal{A} - t E|$. Тогда $\dim V_{\lambda} \le k$.

*Доказательство:* 

::::

:::: {#statement-39}

**Утверждение:**  Пусть $\mathcal{A}$ -- линейный оператор на $V$, $\lambda_1, \ldots, \lambda_s$ -- его различные собственные значения. Тогда векторы $v_1, \ldots, v_s$, отвечающие собственным значениям $\lambda_1, \ldots, \lambda_s$ -- линейно независимы.

*Доказательство:* (индукция по $s$) 

$$\alpha_1 v_1 + \ldots + \alpha_s v_s = 0 \,\,\,\, (1)$$
$$\alpha_1 \lambda_1 v_1 + \ldots + \alpha_s \lambda_s v_s = 0 \,\,\,\, (2)$$
Пусть $\lambda_1 \ne 0$ 
$$(2) - \lambda * (1):\,\,\,\,\,\,\,\, \alpha_2 (\lambda_2 - \lambda_1) v_2 + \ldots + \alpha_s (\lambda_s - \lambda_1) v_s = 0$$
По предположению индукции $v_2, \ldots, v_s$ линейно независимы $\Rightarrow$
$$\begin{cases}
    \alpha_2 (\lambda_2 - \lambda_1) = 0\\
    \vdots\\
    \alpha_s (\lambda_s - \lambda_1) = 0
\end{cases} \Rightarrow \begin{cases}
    \alpha_2 = 0\\
    \vdots\\
    \alpha_s = 0
\end{cases} \Rightarrow \alpha_1 v_1 = 0$$
Противоречие $\,\,\,\,\blacksquare$

::::

:::: {#corollary-1}

**Следствие:**  Сумма собственных подпространств отвечающих различным значениям $\lambda$ -- прямая.

*Доказательство:* 

::::

:::: {#corollary-2}

**Следствие:**  Пусть $V$ -- векторное пространство над полем $F$ размерности $n$, $\mathcal{A}$ -- линейный оператор на $V$. Если $\chi(t) = 0$ имеет $n$ различных корней, то в $V$ существует базис, состоящий из собственных векторов.

*Доказательство:* очев $\,\,\,\,\blacksquare$

::::

:::: {#theorem-6}

**Теорема:**  (*критерий диагонализируемости линейного оператора*) Пусть $V$ -- векторное пространство над полем $F$ размерности $n$, $\mathcal{A}$ -- линейный оператор на $V$. Тогда существование базиса $V$, состоящего из собственных векторов $\mathcal{A} \Leftrightarrow \chi(t)$ -- разлагается на линейные множители над полем $F$ и $\dim V_{\lambda} = k$, где $k$ -- кратность $\lambda$ для любого корня $\lambda$.

*Доказательство:* Пусть $\lambda_1, \ldots, \lambda_s$ -- все корни характеристического многочлена $\chi(t)$, $k_1, \ldots, k_s$ -- кратности этих корней.

$$\Rightarrow$$
В $V$ существует базис $B = \{e_1, \ldots, e_n\}$ из собственных векторов линейного оператора $\mathcal{A}$. Рассмотрим множество $V_1$ из всех векторов $B$, отвечающих собственному значению $\lambda_1$, оно является подмножеством собственного подпространства $V$, отвечающего значению $\lambda_1 \,\,\,\, V_1 \subset V_{\lambda_1}$. Аналогично для $V_1, \ldots,  V_s$. Тогда $V = V_1 \oplus \ldots \oplus V_s \subset V_{\lambda_1} \oplus \ldots \oplus V_{\lambda_s} \subset V \Rightarrow V = V_{\lambda_1} \oplus \ldots \oplus V_{\lambda_s}$. $\dim V = \displaystyle \sum_{i = 1}^{s}\dim V_{\lambda_i} \le \displaystyle \sum_{i = 1}^{s}k_i \le n \Rightarrow \dim V_{\lambda_i} = k_i \,\,\,\, \forall i \in \{1, \ldots, s\}$. (что-то непонятно)

$$\Leftarrow$$
$\dim V_{\lambda_1} \oplus \ldots \oplus \dim V_{\lambda_s} = \displaystyle \sum_{i = 1}^{s}\dim V_{\lambda_i} = \displaystyle \sum_{i = 1}^{s}k_i = n = \dim V \Rightarrow$ можем взять базис, состоящий из базисов $V_{\lambda_i} \,\,\,\,\blacksquare$

::::

# Комплексификация


:::: {#definition-35}

**Определение:**  Пусть $V$ -- векторное пространство над $\mathbb{R}$. Рассмотрим множество $V(\mathbb{C}) = \{(v_1, v_2)| v_1, v_2 \in V\}$. Определим

сложение: $\forall (v_1, v_2), (\tilde{v}_1, \tilde{v}_2) \in V(\mathbb{C}) \,\,\,\,\,\,\,\, (v_1, v_2) + (\tilde{v}_1, \tilde{v}_2) = (v_1 + \tilde{v}_1, v_2 + \tilde{v}_2)$,

умножение на числа из $\mathbb{C}$:
$\forall (\alpha + i \beta) \in \mathbb{C}, \,\,\,\, \alpha, \beta \in \mathbb{R},\,\,\,\, (v_1, v_2) \in V(\mathbb{C}) \,\,\,\,\,\,\,\, (\alpha + i \beta)(v_1, v_2) = (\alpha v_1 - \beta v_2, \beta v_1 + \alpha v_2)$.

Будем обозначать пару $(v, 0) \in V(\mathbb{C})$, как $v$. Заметим, что $i(v, 0) = (0, v)$, а следовательно $(v_1, v_2)$ записывается так: $v_1 + i v_2$.

::::

:::: {#statement-40}

**Утверждение:**  Пусть $V$ -- векторное пространство над $\mathbb{R}$. Тогда $V(\mathbb{C})$ -- векторное пространство над $\mathbb{C}$.

*Доказательство:* очев $\,\,\,\,\blacksquare$

::::

:::: {#statement-41}

**Утверждение:**  Пусть $V$ -- векторное пространство над $\mathbb{R}$. Тогда любой базис $V$ является базисом в $V(\mathbb{C})$.

*Доказательство:* не очев $\,\,\,\,\blacksquare$

::::

:::: {#statement-42}

**Утверждение:**  Пусть $V$ -- векторное пространство над $\mathbb{R}$, $\mathcal{A}$ -- линейный оператор на $V$. Определим отображение $\mathcal{A}_{\mathbb{C}}: V(\mathbb{C}) \to V(\mathbb{C}) \,\,\,\,\,\,\,\, v_1 + i v_2 \in V(\mathbb{C}) \mapsto \mathcal{A}(v_1) + i \mathcal{A}(v_2)$. Тогда $\mathcal{A}_{\mathbb{C}}$ линейный оператор на $V(\mathbb{C})$.

*Доказательство:* очев $\,\,\,\,\blacksquare$

::::

:::: {#statement-43}

**Утверждение:**  Пусть $V$ -- векторное пространство над $\mathbb{R}$, $\mathcal{A}$ -- линейный оператор на $V$, $B$ -- базис в $V$. Тогда матрица линейного оператора $\mathcal{A}_{\mathbb{C}}$ в базисе $B$ совпадает с матрицей линейного оператора $\mathcal{A}$ в базисе $B$.

*Доказательство:* очев $\,\,\,\,\blacksquare$

::::

:::: {#statement-44}

**Утверждение:**  Пусть $V$ -- векторное пространство над $\mathbb{R}$, $\mathcal{A}$ -- линейный оператор на $V$. Тогда линейный оператор $\mathcal{A}_{\mathbb{C}}$ имеет собственный вектор $x + i y$ с собственным значением $\lambda = \alpha + i \beta$
$$\Downarrow$$
$$\begin{cases}
    \mathcal{A}(x) = \alpha x - \beta y\\
    \mathcal{A}(y) = \beta x + \alpha y
\end{cases}$$

*Доказательство:* $$\Rightarrow$$

$$\mathcal{A}_{\mathbb{C}}(x + i y) = (\alpha + i \beta)(x + i y) = \alpha x - \beta y + i (\beta x + \alpha y) = \mathcal{A}(x) + i \mathcal{A}(y) \,\,\,\,\blacksquare$$
$$\Leftarrow$$
То же самое в обратную сторону.

::::

:::: {#corollary-3}

**Следствие:**  Пусть $V$ -- векторное пространство над $\mathbb{R}$, $\mathcal{A}$ -- линейный оператор на $V$. Линейный оператор $\mathcal{A}_{\mathbb{C}}$ имеет собственный вектор $x + i y$ с собственным значением $\lambda = \alpha + i \beta$. Тогда $<x , y >$ -- двумерное инвариантное подпространство линейного оператора $\mathcal{A}$.

*Доказательство:*

::::

## Приведение матрицы линейного оператора к треугольному виду


:::: {#definition-36}

**Определение:**  Поле $F$ *алгебраически замкнуто*, если любой многочлен над $F$ имеет хотя бы один корень.

::::

:::: {#theorem-7}

**Теорема:**  Пусть $V$ -- векторное пространство размерности $n$ над алгебраически замкнутым полем $F$, $\mathcal{A}$ -- линейный оператор на $V$, $A$ -- матрица $\mathcal{A}$ в некотором базисе. Тогда $\exists$ такой базис, что матрица линейного оператора $\mathcal{A}$ в нем верхнетреугольная. 

**Эквивалентная формулировка:** Пусть $F$ -- алгебраически замкнуто, $A \in M_n(F)$. Тогда $$\exists C \in M_n(F), \,\,\,\, \det(C) \ne 0: \,\,\,\, C^{-1}AC = \left(\begin{array}{cccc}
\star & \star & \dots & \star\\
0 & \star & \dots & \star\\
\vdots & \ddots & \ddots & \vdots\\
0 & \dots & 0 & \star
\end{array}\right)$$

*Доказательство:* (индукция по $n$)

Пусть утверждение верно для $n - 1$, докажем, что оно верно для $n$. $F$ -- алгебраически замкнуто, то есть характеристический многочлен $\chi(t)$ имеет хотя бы одни корень, а значит у $\mathcal{A}$ существует собственный вектор $e_1 \ne 0$, отвечающий собственному значению $\lambda$. Дополним его до базиса $V \Rightarrow \mathcal{e} = \{e_1, \ldots, e_n\}$. Матрица $\mathcal{A}$ в базисе $\mathcal{e}$ имеет вид $A_{\mathcal{e}} = \left(\begin{array}{c|ccc}
\lambda & \star & \dots & \star\\
\hline
0\\
\vdots & \,\,\,\, & B\\
0\\
\end{array}\right)$, где $B$ -- матрица размера $n - 1$, а значит по предположению индукции существует $S: \,\,\,\, S^{-1}BS$ -- верхнетреугольная матрица. Рассмотрим матрицу $C = \left(\begin{array}{c|ccc}
1 & 0 & \dots & 0\\
\hline
0\\
\vdots & \,\,\,\, & S\\
0\\
\end{array}\right)$.
$$C^{-1}AC = \left(\begin{array}{c|ccc}
1 & 0 & \dots & 0\\
\hline
0\\
\vdots & \,\,\,\, & S^{-1}\\
0\\
\end{array}\right)\left(\begin{array}{c|ccc}
\lambda & \star & \dots & \star\\
\hline
0\\
\vdots & \,\,\,\, & B\\
0\\
\end{array}\right)\left(\begin{array}{c|ccc}
1 & 0 & \dots & 0\\
\hline
0\\
\vdots & \,\,\,\, & S\\
0\\
\end{array}\right)=$$
$$= \left(\begin{array}{c|ccc}
\lambda & \star & \dots & \star\\
\hline
0\\
\vdots & \,\,\,\, & S^{-1}BS\\
0\\
\end{array}\right) \,\,\,\,\blacksquare$$

::::

## Теорема Гамильтона-Кэли


:::: {#theorem-8}

**Теорема:**  (*Теорема Гамильтона-Кэли*) Пусть $\mathcal{A}$ линейный оператор на векторном пространстве $V$ размерности $n$ над полем $F$. Тогда $A$ является корнем своего характеристического многочлена.

*Доказательство:* 

1. Пусть $F$ -- алгебраически замкнуто. Тогда в $V$ существует базис, в котором матрица линейного оператора $A$ является верхнетреугольной. 
$$A = \left(\begin{array}{cccc}
a_{11} & \star & \dots & \star\\
0 & a_{22} & \dots & \star\\
\vdots & \ddots & \ddots & \vdots\\
0 & \dots & 0 & a_{nn}
\end{array}\right)$$
$$\chi_{\mathcal{A}}(t) = \det (A - tE) = (a_{11} - t)\cdot \ldots \cdot (a_{nn} - t)$$
$$\chi_{\mathcal{A}}(A) = (-1)^n(A - a_{11}E)\cdot \ldots \cdot (A - a_{nn}E)=$$
$$= \left(\begin{array}{c|ccc}
0 & \star & \dots & \star\\
\hline
0\\
\vdots & C - a_{11}E\\
0\\
\end{array}\right)\cdot\ldots\cdot\left(\begin{array}{c|ccc}
a_{11} - a_{nn} & \star & \dots & \star\\
\hline
0\\
\vdots & C - a_{nn}E\\
0\\
\end{array}\right)=$$
$(C - a_{22}E)\cdot\ldots\cdot(C - a_{nn}E) = 0$ по предположению индукции (многочлен степени $n - 1$).

$$=\left(\begin{array}{c|ccc}
0 & \star & \dots & \star\\
\hline
0\\
\vdots & \,\,\,\, & C - a_{11}E\\
0\\
\end{array}\right)\cdot\left(\begin{array}{c|ccc}
\displaystyle \prod_{i = 2}^{n}(a_{11} - a_{ii}) & \star & \dots & \star\\
\hline
0\\
\vdots & \,\,\,\, & 0\\
0\\
\end{array}\right) = \left(0\right)$$

2. Пусть поле $F$ алгебраически не замкнуто. Тогда по теореме, которая будет доказана в неопределенном будущем $F$ является подполем некоторого алгебраически замкнутого поля $F’$. $\,\,\,\,\blacksquare$

::::

# Аннулирующй и минимальный многочлены

:::: {#definition-37}

**Определение:**  Пусть $V$ векторное пространство над полем $F$, $\mathcal{A}$ -- линейный оператор на $V$. $f \in F[t]$ -- *аннулирующий многочлен* для $\mathcal{A}$, если $f(\mathcal{A}) = 0$.

::::

По теореме Гамильтона-Кэли характеристический многочлен является аннулирующим.

Для $\mathcal{A} = \mathcal{I}$ аннулирющим многочленом является $t - 1$, т.к. $\mathcal{A} - 1 \mathcal{I} = 0$.

:::: {#definition-38}

**Определение:**  Пусть $V$ векторное пространство над полем $F$, $\mathcal{A}$ -- линейный оператор на $V$. Аннулирующий многочлен $\mathcal{A}$ минимальной степени со старшим коэффицентом равным $1$ -- *минимальный многочлен* для $\mathcal{A}$.

Обозначается: $\mu_{\mathcal{A}}(t)$.

::::

### Простейшие свойства аннулирующего многочлена

:::: {#statement-45}

**Утверждение:**  Пусть $V$ векторное пространство над полем $F$, $\mathcal{A}$ -- линейный оператор на $V$. Тогда

1. Минимальный многочлен делит любой аннулирующий.
2. $\mu_{\mathcal{A}}$ -- единственный.
3. Множество корней $\mu_{\mathcal{A}}$ совпадает с множеством корней характеристического многочлена.

*Доказательство:* 

1. Пусть $\zeta(t)$ -- аннулирующий многочлен оператора $\mathcal{A}$. Разделим с остатком $\zeta(t)$ на $\mu_{\mathcal{A}}(t) \Rightarrow \zeta(t) = \xi(t)\mu_{\mathcal{A}}(t) + r(t)$, где степень $r(t)$ меньше степени $\mu_{\mathcal{A}}(t)$, если $r(t) \ne 0$, то получим противоречие с минимальностью степени $\,\,\,\,\blacksquare$
2. Пусть $\mu_{\mathcal{A}}(t)$ и $\tilde{\mu}_{\mathcal{A}}(t)$ -- минимальные многочлены $\mathcal{A}$. Тогда по $1$-му свойству $\mu_{\mathcal{A}}(t)$ делит $\tilde{\mu}_{\mathcal{A}}(t)$. То есть $\mu_{\mathcal{A}}(t) = \lambda\tilde{\mu}_{\mathcal{A}}(t)$, а следовательно эти многочлены совпадают, так как коэффицент при старшем члене о минимального многочлена $1 \,\,\,\,\blacksquare$ 
3. По свойству $1$ множество корней минимального многочлена является подмножеством корней характеристического. Пусть $\lambda$ корень $\chi_{\mathcal{A}}(t)$. Значит существует собственный вектор $e$ оператора $\mathcal{A}$, отвечающий значению $\lambda$. Для любого $f(t) \in F[t] \,\,\,\, f(\mathcal{A})(e) = f(\lambda)e \Rightarrow 0 = \mu_{\mathcal{A}}(\mathcal{A})(e) = \mu_{\mathcal{A}}(\lambda)e \Rightarrow (e \ne 0) \,\,\,\, \mu_{\mathcal{A}}(\lambda) = 0 \,\,\,\,\blacksquare$

::::

## Жорданова нормальная форма

### Определения

:::: {#definition-39}

**Определение:**  Квадратная матрица вида $\operatorname{J}_k(\lambda) = \left(\begin{array}{ccccc}
\lambda & 1 & 0 & \dots & 0\\
0 & \lambda & 1 & \dots & 0\\
\vdots & \ddots & \ddots & \ddots & \vdots\\
0 & \dots & 0 & \lambda & 1\\
0 & \dots & 0 & 0 & \lambda\\
\end{array}\right)$ -- *жорданова клетка* с $\lambda$ на диагонали размера $k$.

Обозначение: $\operatorname{J}_k(\lambda)$.

::::

:::: {#definition-40}

**Определение:**  Квадратная матрица размера $n \times n$, состоящая из жордановых клеток на диагонали и нулей на остальных местах -- это *жорданова матрица* размера $n \times n$.

::::

:::: {#definition-41}

**Определение:**  Пусть $V$ -- векторное пространство, $\mathcal{A}$ -- линейный оператор на $V$. Если существует базис, в котором матрица $\mathcal{A}$ жорданова, то такой базис -- *жорданов*, а сама матрица *жорданова нормальная форма* линейного оператора $\mathcal{A}$.

::::

### Простейшие свойства

:::: {#statement-46}

**Утверждение:**  Пусть матрица линейного оператора $\mathcal{A}$ имеет жорданову нормальную форму размера $n \times n$ и состоит из жордановых клеток $\operatorname{J}_{k_1}(\lambda_1), \ldots, \operatorname{J}_{k_s}(\lambda_s)$. Тогда

1. $\chi_{\mathcal{A}}(t) = (-1)^n \displaystyle \prod_{i = 1}^{s}(t - \lambda_i)^k_i$.
2. Жорданов базис $\mathcal{A}$ состоит из объединения жордановых базисов клеток $\operatorname{J}_{k_1}(\lambda_1), \ldots, \operatorname{J}_{k_s}(\lambda_s)$.

*Доказательство:*

1. очев $\,\,\,\,\blacksquare$
2. не очев $\,\,\,\,\blacksquare$

::::

:::: {#statement-47}

**Утверждение:**  

1. $\operatorname{J}_{k}(0)^m = \begin{cases}
    m,\,\,\,\, m < k\\
    0,\,\,\,\, m \ge k
\end{cases}$
2. $\mu_{\operatorname{J}_{k}(\lambda)}(t) = (t - \lambda)^k$
3. $\mu_{\operatorname{J}_n}$ -- это наименьшее общее кратное всех минимальных многочленов ее жордановых клеток.
4. $\operatorname{rk}(\operatorname{J}_k(\lambda) - \alpha E)^m = \begin{cases}
    k,\,\,\,\, \lambda \ne \alpha\\
    k - m,\,\,\,\, \lambda = \alpha, k \ge m\\
    0,\,\,\,\, \lambda = \alpha, k < m
\end{cases}$

*Доказательство:* все кроме $3$ очевидно $\,\,\,\,\blacksquare$

::::

:::: {#statement-48}

**Утверждение:**  Пусть $V$ -- векторное пространство размерности $n$. Пусть матрица линейного оператора $\mathcal{A}$ в некотором базисе имеет жорданову нормальную форму $\operatorname{J}_n$. Тогда $\dim V_{\lambda}$ равно количеству жордановых клеток в матрице $\mathcal{A}$ с $\lambda$ на диагонали.

*Доказательство:* $V_{\lambda} = \{v \in V: \,\,\,\, \mathcal{A}(v) = \lambda v\}$, а это множество решений $\mathcal{A} - \lambda \mathcal{I} = 0$ или $\operatorname{J}_n - \lambda E = 0$. Следовательно, $\dim V_{\lambda} = n - \operatorname{rk}\operatorname{J}_n$. Ранг жордановой матрицы -- это сумма рангов составляющих ее клеток $J_{k_1}(\lambda_1), \ldots, J_{k_s}(\lambda_s)$, а ранг жордановой клетки $\operatorname{J}_k(\lambda) = \begin{cases}
    k, \lambda \ne 0\\
    k - 1, \lambda = 0
\end{cases}$. То есть $n - \operatorname{rk}\operatorname{J}_n = \displaystyle \sum_{i = 1}^{s}k_i - \displaystyle \sum_{i = 1}^{s}\operatorname{rk}J_{k_i}(\lambda_i)$ значение этого выражения равно $1$ на всех клетках с $\lambda$ на диагонали и $0$ на остальных $\,\,\,\,\blacksquare$

::::

# Существование жорданова базиса у линейного оператора над алгебраически замкнутым полем

:::: {#theorem-9}

**Теорема:**  Пусть $V$ -- векторное пространство размерности $n$ над алгебраически замкнутым полем $F$, $\mathcal{A}$ -- линейный оператор на $V$. Тогда существует базис, в котором матрица оператора $\mathcal{A}$ является жордановой.

*Доказательство:* 

![](img/jordan-basis-exists.png)

Если $\mathcal{A}$ невырожден(его матрица невырождена), то можем рассматривать вырожденный линейный оператор $\mathcal{A} - \lambda \mathcal{I}$, где $\lambda$ -- собственное значение $\mathcal{A}$ (сущесвует, так как поле алгебраически замкнуто). Почему можно рассматривать такой оператор? И почему $\mathcal{A} - \lambda \mathcal{I}$ -- вырожден?

Если $\ker \mathcal{A} = V$, то жорданова нормальная форма -- нулевая матрица, и жордановым является любой базис. $\mathcal{A}$ -- вырожден, а значит $\ker \mathcal{A} \ne \{0\}$.(Почему?)

Индукция по $n$:

Далее $0 < \dim \ker \mathcal{A} < n$, тогда из $\dim \ker \mathcal{A} + \dim \operatorname{img} \mathcal{A} = n$ следует, что $0 < \dim \operatorname{img} \mathcal{A} < n$, а значит по предположению индукции 🕵️‍ у $\mathcal{A}_{|\operatorname{img} \mathcal{A}}$ существует жорданова нормальная форма $\operatorname{J}_{\operatorname{img}\mathcal{A}}$ и в ней есть жордановы клетки с $0$ на диагонали, так как $\mathcal{A}$ -- вырожден. (И что с того?) Пусть клеток с $0$ на диагонали $s$. Жорданов базис матрицы $\operatorname{J}_{\operatorname{img}\mathcal{A}}$ -- это объединение жордановых базисов ее клеток. Запишем жорданов базис для $\mathcal{A}_{|\operatorname{img} \mathcal{A}}$ $e = \{e_{11}, \ldots, e_{1k_1}, \ldots, e_{s1}, \ldots, e_{sk_s}, \ldots, e_{s+1 1}, \ldots, e_{s + 1 k_{s + 1}}, e_{m1}, \ldots, e_{mk_m}\}$, где $k_1, \ldots, k_m$ -- размеры жордановых клеток, $\lambda_1 = \ldots = \lambda_s = 0$, $m$ -- количество жордановых клеток. Пусть $V_0$ подпространство в $\operatorname{img} \mathcal{A}$ с собственным значением ноль, имеем: $V_0 = \{v \in V: \,\,\,\, \mathcal{A}(v) = 0 \cdot v\} = \ker \mathcal{A}$. То есть $\operatorname{img} \mathcal{A} \cap \ker \mathcal{A} = V_0$. Размерность $V_0$ равна количеству клеток с $0$ на диагонали, то есть $s$. Векторы $e_{12}, \ldots, e_{s2}$ линейно независимы, а следовательно являются базисом $V_0$. Дополним $e_{12}, \ldots, e_{s2}$ векторами $f_1, \ldots, f_q$ до базиса $f$ подпространства $\ker \mathcal{A}$.
$$\dim (\operatorname{img} \mathcal{A} \cap \ker \mathcal{A}) + \dim(\operatorname{img} \mathcal{A} + \ker \mathcal{A}) = \dim \operatorname{img} \mathcal{A} + \dim \ker \mathcal{A}$$
$$\dim \operatorname{img} \mathcal{A} + \dim \ker \mathcal{A} = n$$
$$\Downarrow$$
$$\dim (\operatorname{img} \mathcal{A} + \ker \mathcal{A}) = n - s$$
Так как $\operatorname{img} \mathcal{A} + \ker \mathcal{A}$ -- это линейная оболочка векторов из $f$ и $e$, которые являются линейно независимыми, а следовательно базисом $\operatorname{img} \mathcal{A} + \ker \mathcal{A}$, получаем, что нужно добавить $s$ векторов к $f \cup e$, чтобы получить базис $V$. Добавим векторы $g = \{g_1, \ldots, g_s\}$:
$$\mathcal{A}(g_1) = e_{1k_1}$$
$$\mathcal{A}(g_2) = e_{2k_2}$$
$$\vdots$$
$$\mathcal{A}(g_s) = e_{sk_s}$$
Такие векторы существуют, потому что $e_{1k_1}, \ldots, e_{sk_s}$ принадлежат $\operatorname{img}\mathcal{A}$.

Докажем, что $g \cup f \cup e$ -- базис в $V$.
Количество векторов верное, осталось доказать линейную независимость. Рассмотрим линейную комбинацию равную $0$:

$$\displaystyle \sum_{i = 1}^{s}\alpha_i g_i + \displaystyle \sum_{i = 1}^{q}\beta_i f_i + \displaystyle \sum_{i = 1}^{s}\displaystyle \sum_{j = 1}^{k_i}\gamma_{ij} e_{ij} + \displaystyle \sum_{i = s}^{n}\displaystyle \sum_{j = 1}^{k_i}\gamma_{ij} e_{ij} = 0$$ 

Применим к этой линейной комбинации $\mathcal{A}$:
$0 + \displaystyle \sum_{i = 1}^{s}\alpha_i e_{ik_i} +$ комбинация векторов $e_{ij} = 0$, а так как все $e_{ij}$ линейно независимы, все коэффиценты равны $0$.

Если увеличить разверы всех клеток с $0$ на диагонали на $1$(векторы $g_1, \ldots, g_s$, дополняют базис каждой клетки до базиса клетки с размером на $1$ больше) и добавить $q$ клеток с $0$ на диагонали, то получим искомую жорданову нормальную форму $\,\,\,\,\blacksquare$

::::

## Единственность жордановой нормальной формы

все так сложно

## Критерий диагонализируемости в терминах минимального многочлена

:::: {#theorem-10}

**Теорема:**  Пусть $V$ -- конечномерное векторное пространство над алгебраически замкнутым полем $F$, $\mathcal{A}$ -- линейный оператор на $V$. Тогда $\mathcal{A}$ диагонализируем $\Leftrightarrow$ минимальный многочлен $\mu_{\mathcal{A}}(t)$ не имеет кратных корней.

*Доказательство:* 

$$\Rightarrow$$
Поле алгебраически замкнуто, следовательно существует базис, в котором матрица $\mathcal{A}$ жорданова. $\mu_{\mathcal{A}}(t) = \displaystyle \prod_{i = 1}^{s}(t - \lambda_i)^k_i$, где $k_i$ размер жордановой клетки с $\lambda_i$ на диагонали. Оператор $\mathcal{A}$ диагонализируем, следовательно все клетки в жордановой нормальной форме размера $1$, а значит $\mu_{\mathcal{A}}$ не имеет кратных корней.
$$\Leftarrow$$
В обратную сторону $\,\,\,\,\blacksquare$

::::

## Подобная матрица


:::: {#definition-42}

**Определение:**  Матрица $A \in M_n(F)$ *подобна* матрице $B \in M_n(F)$, если $\exists C \in M_n(F): \,\,\,\, A = C^{-1}BC$.

::::

:::: {#corollary-4}

**Следствие:**  Любая матрица $A$ над алгебраически замкнутым полем подобна некоторой жордановой матрице.

*Доказательство:* По теореме существует базис в векторном пространстве строк, в котором матрица линейного оператора, заданного матрицей $A$, жорданова. Далее по формуле перехода от одного базиса к другому получаем утверждение следствия $\,\,\,\,\blacksquare$

::::


# Корневые подпространства


:::: {#definition-43}

**Определение:**  Пусть $V$ -- конечномерное векторное пространство, $\mathcal{A}$ -- линейный оператор на $V$. $v \in V$ -- *корневой вектор* линейного оператора $\mathcal{A}$, *отвечающий* собственному значению $\lambda$, если $\exists m \in \mathbb{N}: \,\,\,\, (\mathcal{A} - \lambda \mathcal{I})^m(v) = 0$.

($(\mathcal{A} - \lambda \mathcal{I})^m(v) = (\mathcal{A} - \lambda \mathcal{I})((\mathcal{A} - \lambda \mathcal{I})^{m - 1}(v)) = (\mathcal{A} - \lambda \mathcal{I})(y) = 0 \Rightarrow \lambda$ действительно собственное значение линейного оператора $\mathcal{A}$)

Так как $V$ конечномерно, у любого корневого вектора $x$ существует минимальное значение $m$, такое что $(\mathcal{A} - \lambda \mathcal{I})^m(x) = 0$. Такое минимальное $m$ -- *высота* корневого вектора.

**Пример:** Собственный вектор -- это корневой вектор с высотой $1$.

::::

:::: {#statement-49}

**Утверждение:**  Пусть $V$ -- конечномерное векторное пространство, $\mathcal{A}$ -- линейный оператор на $V$, $\lambda$ -- собственное значение $\mathcal{A}$. Тогда $V(\lambda) = \{v \in V| \,\,\,\, \exists m \in \mathbb{N}: \,\,\,\, (\mathcal{A} - \lambda \mathcal{I})(v) = 0\}$ -- подпространство в $V$.

*Доказательство:* очев $\,\,\,\,\blacksquare$

::::

:::: {#definition-44}

**Определение:**  $V(\lambda)$ -- *корневое* подпространство $V$, отвечающее собственному значению $\lambda$.

::::

:::: {#statement-50}

**Утверждение:**  Пусть $V$ -- конечномерное векторное пространство, $\mathcal{A}$ -- линейный оператор на $V$, $\lambda$ -- собственное значение $\mathcal{A}$. Тогда $V(\lambda)$ инвариантное подпространство оператора $\mathcal{A}$.

*Доказательство:* $\forall v \in V(\lambda) \,\,\,\, \exists m \in \mathbb{N}: \,\,\,\, (\mathcal{A} - \lambda \mathcal{I})^m(v) = 0$ (ничего непонятно)

::::

:::: {#statement-51}

**Утверждение:**  Пусть $V$ -- конечномерное векторное пространство, $\mathcal{A}$ -- линейный оператор на $V$, $\lambda_1, \ldots, \lambda_s$ -- все собственные значения $\mathcal{A}$. Тогда все пространство $V$ разбивается на прямую сумму корневых подпространств, отвечающих значениям $\lambda_1, \ldots, \lambda_s$.

*Доказательство:* Так как поле алгебраически замкнуто, существует базис, в котором матрица $A$ линейного оператора $\mathcal{A}$ жорданова. Базис жордановой матрицы -- это объединение базисов ее клеток. Пусть жорданов базис $\mathcal{A}$ -- это $e = \{e_{1 \lambda_1}, \ldots, e_{k_1 \lambda_1}\} \cup \ldots \cup \{e_{1 \lambda_s}, \ldots, e_{k_s \lambda_s}\}$, где $e_{1 \lambda_i}, \ldots, e_{k_i \lambda_i}$ базис всех клеток с $\lambda_i$ на диагонали. $U_i = < e_{1 \lambda_i}, \ldots, e_{k_i \lambda_i}>$. $V = U_1 \oplus \ldots \oplus U_s$ (почему сумма прямая?). Докажем, что $U_i = V(\lambda_i)$. $U_i$ состоит из линейных комбинаций векторов жорданова базиса, каждый из которых является корневым(почему?), отвечающим значению $\lambda_i$, а значит $U_i \subset V(\lambda_i)$. Пусть $x \in V(\lambda_i)$. Тогда $x = x_i + \tilde{x}$, где $x_i \in U_i$, $\tilde{x} \in U_1 \oplus \ldots \oplus  U_{i - 1} \oplus U_{i + 1} \oplus \ldots \oplus U_s$. $\tilde{x} = x - x_i \in U_i$, то есть $\exists m \in \mathbb{N}: \,\,\,\, \tilde{x} = (\mathcal{A} - \lambda_i \mathcal{I})^m(\tilde{x}) = 0$. Ограничение $\mathcal{A} - \lambda_i \mathcal{I}$ на $U_1 \oplus \ldots \oplus  U_{i - 1} \oplus U_{i + 1} \oplus \ldots \oplus U_s$ невырождено (**почему?**), а следовательно $\tilde{x} = 0 \Rightarrow x = x_i \,\,\,\,\blacksquare$

::::

## Билинейные функции


:::: {#definition-45}

**Определение:**  Пусть $V$ -- векторное пространство над полем $F$. Отображение $\beta: \,\,\,\, V \times V \to F$ -- *билинейная функция*, если:

1. $\forall x, y, z \in V, \,\,\,\, \lambda \in F \,\,\,\, \beta(x + y, \lambda z) = \lambda \beta(x, z) + \lambda \beta(y, z)$
2. $\forall x, y, z \in V, \,\,\,\, \lambda \in F \,\,\,\, \beta(\lambda x, y + z) = \lambda \beta(x, y) + \lambda \beta(x, z)$

::::

#### Матрица билинейной функции

Пусть $V$ -- векторное пространство размерности $n$ над полем $F$, $e = \{e_1, \ldots, e_n\}$ -- базис $V$, $\beta$ -- билинейная функция.

$$\forall x, y \in V \,\,\,\, \beta(x, y) = \beta(\displaystyle \sum_{i = 1}^{n}x_i e_i, \displaystyle \sum_{i = 1}^{n}y_i e_i) = \displaystyle \sum_{i = 1, j = 1}^{n}x_i \beta(e_i, e_j) y_i$$

Обозначим $\beta(e_i, e_j) = b_{ij}$.

:::: {#definition-46}

**Определение:**  $B = \left(\begin{array}{ccc}b_{11} & \dots & b_{1n}\\
\vdots & \ddots & \vdots\\
b_{n1} & \dots & b_{nn}\end{array}\right)$ -- *матрица билинейной функции* $\beta$ *в базисе* $e$.

$\beta(x, y) = X^T B Y$, где $X, Y$ столбцы координат векторов $x, y$ соответственно.

::::

### Изменение матрицы билинейной функции при переходе от одного базиса к другому

:::: {#statement-52}

**Утверждение:**  Пусть $V$ -- векторное пространство размерности $n$ над полем $F$, $e, \tilde{e}$ -- базисы $V$, $\beta$ -- билинейная функция, $B, \tilde{B}$ -- ее матрицы в базисах $e$ и $\tilde{e}$ соответственно. Тогда 
$$\tilde{B} = C_{e \to \tilde{e}}^TB C_{e \to \tilde{e}}$$

*Доказательство:* записать все и подставить одно в другое $\,\,\,\,\blacksquare$

::::


# Симметрические билинейные функции


:::: {#definition-47}

**Определение:**  Пусть $V$ -- векторное пространство над полем $F$, $\beta: V\times V \to F$ -- билинейная функция на $V$.

Функция $\beta$ *симметрическая*, если $\forall x, y \in V \,\,\,\, \beta(x, y) = \beta(y, x)$.

::::

:::: {#statement-53}

**Утверждение:**  Пусть $V$ -- векторное пространство над полем $F$.

$\beta: V\times V \to F$ -- симметрическая билинейная функция на $V \Leftrightarrow$ матрица $B$ функции $\beta$ симметричекая, то есть $B^T = B$.

*Доказательство:* $$\Rightarrow$$
$B = (b_{ij})$. $b_{ij} = \beta(e_i, e_j) = \beta(e_j, e_i) = b_{ji} \Rightarrow B = B^T$

$$\Leftarrow$$
$B = B^T \,\,\,\, \forall x, y \in V \,\,\,\, \beta(x, y) = X^TBY =$(так как это число)$=(X^TBY)^T = Y^TB^TX = Y^TBX = \beta(y, x) \,\,\,\,\blacksquare$

::::

:::: {#definition-48}

**Определение:**  Если в базисе $e = \{e_1, \ldots, e_n\}$ матрица $B$ билинейной функции $\beta$ диагональная, то $\beta(x, y) = b_{11}x_1y_1 + \ldots + b_{nn}x_n y_n$ и такой вид называется *каноническим видом билинейной функции* $\beta$.

::::

:::: {#definition-49}

**Определение:**  Пусть $S \subset V$, $V$ -- векторное пространство. $S^{\perp} = \{x \in V: \,\,\,\, \beta(x, s) = 0 \,\,\,\, \forall s \in S\}$ -- *ортогональное дополнение множества* $S$.

::::

:::: {#statement-54}

**Утверждение:**  Пусть $V$ -- векторное пространство над полем $F, \,\,\,\, \operatorname{char} F \ne 2$ размерности $n$.
$\beta: V\times V \to F$ -- симметрическая билинейная функция на $V$. Тогда существует базис $\{e_1, \ldots, e_n\}$, в котором матрица $B$ функции $\beta$ диагональная.

*Доказательство:* (индукция по $n$)
Для $n = 1$ очевидно.
Докажем, что из $n - 1$ следует $n$. 

1. $\beta$ тождественный ноль, тогда в любом базисе матрица $B$ диагональна, так как она нулевая.
2. $\beta$ не тождественный ноль, тогда существует вектор $e_1$, такой что $\beta(e_1, e_1) \ne 0$. Докажем, предположим противное, а именно $\forall x, y \in V \,\,\,\, \beta(x, x) = 0$, $\beta(y, y) = 0$ и $\beta(x + y, x + y) = 0 = \beta(x, x) + 2\beta(x, y) + \beta(y, y) \Rightarrow \beta(x, y) = 0$ противоречие с тем, что $\beta$ не тождественный ноль. Рассмотрим ортогональное дополнение вектора $e_1$. $U = \{e_1\}^{\perp}$. Для произвольного базиса $f = \{f_1, \ldots, f_n\}$. $\forall x \in U \,\,\,\, \beta(x, e_1) = \beta(x_1 f_1 + \ldots, x_n f_n, \lambda_1 f_1 + \ldots + \lambda_n f_n) = 0 = \displaystyle \sum_{i, j = 1}^{n}x_i \lambda_j \tilde{b}_{ij}$, а это система однородных линейных уравнений относительно $x_1, \ldots, x_n$, состоящая из одного уравнения. Размерность фундаментальной системы решений равна $n -$ ранг матрицы системы. То есть $\dim U = n$ или $\dim U = n - 1$. Докажем, что $\dim U \ne n$. Вектор $e_1 \not\in U$, так как $\beta(e_1, e_1) \ne 0 \Rightarrow \dim U \ne n \Rightarrow \dim U = n - 1 \Rightarrow$ по предположению индукции существует такой базис $\{e_2, \ldots, e_n\}$, что матрица $\beta$ в нем диагональна. Базис $\{e_1, \ldots, e_n\}$ будет искомым $\,\,\,\,\blacksquare$(почему матрица в нем диагональна и почему это базис?)

::::

## Квадратичные функции


:::: {#definition-50}

**Определение:**  Пусть $V$ -- векторное пространство над полем $F$, $\beta: V \times V \to F$ -- симметрическая билинейная функция на $V$.<br>$q: V \to F$ -- *квадратичная функция*, если $\forall x \in V \,\,\,\, q(x) = \beta(x, x)$.<br>Матрица $B$ билинейной функции $\beta$ -- *матрица квадратичной функции*.<br>$q(x) = \beta(x, x) = X^TBX = \displaystyle \sum_{i, j = 1}^{n}x_i x_j b_{ij}$ такая запись -- *квадратичная форма* $q$.<br>Если в каком-то базисе $B$ -- диагональна, то $q(x) = \beta(x, x) = X^TBX = \displaystyle \sum_{i = 1}^{n}x_i^2 b_{ii}$ и такая запись называется *каноническим видом* квадратичной функции $q$.

::::

:::: {#statement-55}

**Утверждение:**  

1. Для любой квадратичной функции $q: V \to F$ существует базис, в котором $q$ имеет канонический вид.
2. Любая квадратичная форма может быть некоторой невырожденной линейной заменой переменных приведена у каноническому виду.

*Доказательство:*

1. Следует отсюда
2. способы такого приведения рассматриваются далее.

::::

### Алгоритм Лагранжа приведения квадратичной формы к каноничекому виду

потом

### Приведение квадратичной формы к каноничекому виду унитреугольными преобразованиями

:::: {#definition-51}

**Определение:**  Матрица $S \in M_n(F)$ -- *унитреугольная*, если она верхнетреугольная с $1$ на главной диагонали.

::::

:::: {#definition-52}

**Определение:**  Пусть $B = \left(\begin{array}{ccc}
b_{11} & \dots & b_{1n}\\
\vdots & \ddots & \vdots\\
b_{n1} & \dots & b_{nn}
\end{array}\right)$

$\Delta_0 = 1$
$\Delta_1 = |b_{11}|$
$\Delta_2 = \left|\begin{array}{cc}
b_{11} & b_{12}\\
b_{21} & b_{22}
\end{array}\right|$
$\vdots$
$\Delta_k = \left|\begin{array}{ccc}
b_{11} & \dots & b_{1k}\\
\vdots & \ddots & \vdots\\
b_{k1} & \dots & b_{kk}
\end{array}\right|$
$\vdots$ -- *(главные) угловые миноры матрицы* $B$.

::::

:::: {#statement-56}

**Утверждение:**  Пусть $V$ -- векторное пространство размерности $n$ над полем $F$, $\Delta_i \ne 0 \,\,\,\, \forall i$. Для любой квадратичной формы квадратичной функции $q: V \to F$ существует базис $f = \{f_1, \ldots, f_n\}$, в котором $q$ имеет канонический вид: $\frac{\Delta_1}{\Delta_0}x_1^2 + \ldots \frac{\Delta_n}{\Delta_{n - 1}}x_n^2$, где $\Delta_0, \ldots, \Delta_n$ -- угловые миноры матрицы $B$ функции $q$ в некотором базисе $e$ и матрица перехода от $e$ к $f$ унитреугольная.

*Доказательство:* (индукция по $n$)
$n = 1$ очевидно.
Докажем, что из $n - 1$ следует $n$. Пусть $e = \{e_1, \ldots, e_n\}$ -- базис $V$. Рассмотрим $U = <e_1, \ldots, e_{n - 1}>$ -- это подпространство $V$ размерности $n - 1$, а следовательно по предположению индукции существует базис $f_1, \ldots, f_{n - 1}$, в котором $$q(x_1f_1 + \ldots + x_{n - 1}f_{n - 1}) = \frac{\Delta_1}{\Delta_0}x_1^2 + \ldots +\frac{\Delta_{n - 1}}{\Delta_{n - 2}}x_n^2$$

Будем искать $f_n$ в виде $f_n = e_n + \mu_1 f_1 + \ldots + \mu_{n - 1}f_{n - 1}$, $e_n \not\in U \Rightarrow$ любой вектор такого вида будет дополнять $f_1, \ldots, f_{n - 1}$ до базиса.

Хотим, чтобы в базисе $f_1, \ldots, f_n \,\,\,\,$ $q$ имела канонический вид, то есть $\forall i \in \{1, \ldots, n - 1\} \,\,\,\, \beta(f_n, f_i) = 0 = \beta(e_n + \mu_1 f_1 + \ldots + \mu_{n - 1}f_{n - 1}, f_i)$
$= \beta(e_n, f_i) + \beta(f_i, f_i)\mu_i \Rightarrow \mu_i = -\frac{\beta(e_n, f_i)}{\beta(f_i, f_i)}$, $\beta(f_i, f_i) = \frac{\Delta_i}{\Delta_{i - 1}} \ne 0$ следовательно нашли такие коэффиценты, что вид канонический. Нужно доказать, что $\beta(f_n, f_n) = \frac{\Delta_n}{\Delta_{n - 1}}$.

Матрица перехода от $e$ к $f$:
$$C_{e \to f} = \left(\begin{array}{ccc}
1 & & \star\\
 & \ddots & \\
0 & & 1
\end{array}\right)$$

Матрица $q$ в базисе $f$:
$$C = \left(\begin{array}{cccc}
\frac{\Delta_1}{\Delta_0} & \dots & 0 & 0\\
\vdots & \ddots & \vdots & \vdots\\
0 & \dots & \frac{\Delta_{n - 1}}{\Delta_{n - 2}} & 0\\
0 & \dots & 0 & c
\end{array}\right)$$

$$\det(C) = \frac{\Delta_1}{\Delta_0} \cdot \ldots \cdot \frac{\Delta_{n - 1}}{\Delta_{n - 2}}\cdot c = \Delta_{n - 1}c = \det(C_{e \to f}^T B C_{e \to f}) = \det(B) = \Delta_n \,\,\,\,\blacksquare$$

::::

# Квадратичные формы над полями действительных и комплексных чисел


Пусть $q: V \to F$ -- квадратичная функция, $F$ -- это $\mathbb{R}$ или $\mathbb{C}$. Тогда сущесвтует базис, в котором $q$ имеет канонический вид: $q(x) = \lambda_1 x_1^2 + \ldots + \lambda_n x_n^2$. Считаем, что $\lambda_1 \ne 0, \ldots, \lambda_r \ne 0$ и $\lambda_{r + 1} = 0, \ldots, \lambda_{n} = 0$.

:::: {#statement-57}

**Утверждение:**  Над $\mathbb{C}$ в $V$ существует базис, в котором 

$q(x) = x_1^2 + \ldots + x_r^2$.

*Доказательство:* $\blacksquare$

::::

:::: {#statement-58}

**Утверждение:**  Над $\mathbb{R}$ в $V$ существует базис, в котором 
$q(x) = x_1^2 + \ldots + x_k^2 - x_{k + 1}^2 - \ldots - x_{k + l}^2$, $k + l = 0$.

*Доказательство:* $\lambda_i = \frac{1}{\sqrt{|\lambda_i|}} \,\,\,\,\blacksquare$ 

::::

### Индексы инерции


:::: {#definition-53}

**Определение:**  <br><br>$k$ -- *положительный индекс инерции*.<br><br>$l$ -- *отрицательный индекс инерции*.

::::


:::: {#theorem-11}

**Теорема:**  Положительный и отрицательный индексы инерции инварианты вещественной квадратичной функции $q: V \to \mathbb{R}$, то есть, если в базисах $e = \{e_1, \ldots, e_n\}$ и $f = \{f_1, \ldots, f_n\}\,\,\,\, q$ имеет вид:

$$q(x)=x_1^2+\ldots+x_k^2-x_{k+1}^2-\ldots-x_{k+l}^2$$
$$q(x)=\tilde{x}_1^2+\ldots+\tilde{x}_s^2-\tilde{x}_{s+1}^2-\ldots-\tilde{x}_{s+t}^2$$ соответственно, то $k = s$ и $l = t$.

*Доказательство:* $k + l = s + t = r$, то есть достаточно доказать, что $k = s$. Пусть $k \ne s$. Без ограничения общности считаем, что $s > k$. Рассмотрим подпространства $U = <f_1, \ldots, f_s>$ и $W = <e_{k + 1}, \ldots, e_{k + l}, \ldots, e_n>$. Докажем, что $U \cap W \ne \varnothing$. По формуле Грассмана: $\dim U \cap W = \dim U + \dim W - \dim U \cup W = s + n - k - \dim U \cup W > 0$. То есть $\exists x \in U \cap W$. Тогда $q(x) = \tilde{x}_1^2+\ldots+\tilde{x}_s^2 > 0$ и $q(x) = -x_{k+1}^2-\ldots-x_{k+l}^2 < 0$. Противоречие $\,\,\,\,\blacksquare$

::::

## Положительно определенные квадратичные функции


$V$ -- векторное пространство над $\mathbb{R}$.
$q: V \to \mathbb{R}$ -- квадратичная функция.

:::: {#definition-54}

**Определение:**  $q$ *положительно определена*, если $\forall x \in V,\,\,\,\, x \ne 0 \,\,\,\, q(x) > 0$.

::::

:::: {#definition-55}

**Определение:**  $q$ *отрицательно определена*, если $\forall x \in V,\,\,\,\, x \ne 0 \,\,\,\, q(x) < 0$.

::::

### Критерий Сильвестра


:::: {#theorem-12}

**Теорема:**  (критерий Сильвестра)
Вещественная симметричекая билинейная функция $\beta: V\times V \to \mathbb{R}$ положительно определена $\Leftrightarrow$ все угловые миноры матрицы $B$ функции $\beta$ положительны.

*Доказательство:*
$$\Leftarrow$$
По теореме существует базис, в котором $\beta(x, x) = q(x) = \frac{\Delta_1}{\Delta_0}x_1^2 + \ldots \frac{\Delta_n}{\Delta_{n - 1}}x_n^2 > 0 \,\,\,\, \forall x \ne 0$.
$$\Rightarrow$$
Индукция по $n$. Рассмотрим попространство $U = <e_1, \ldots, e_{n - 1}>$ по предположению индукции в матрице ограничения $q$ на $U$ все угловые миноры положительны, то есть $\Delta_1 > 0, \ldots, \Delta_{n - 1} > 0$. Докажем, что $\Delta_n > 0$. Существует базис $f$, в котором матрица $D$ функции $\beta$ диагональная с положительными числами на диагонали, так как $b_{ii} = \beta(f_i, f_i) > 0 \,\,\,\, \forall i \in \{1, \ldots, n\}$, то есть $\det(D) > 0$. $\Delta_n = \det(B) = \det(C_{f \to e}^T D C_{f \to e}) = \det(C_{f \to e})^2\det(D) > 0 \,\,\,\,\blacksquare$

::::

# Евклидовы пространства


:::: {#definition-56}

**Определение:**  Пусть $V$ - векторное пространство над $\mathbb{R}$. Симметрическая положительно определенная билинейная функция $\beta: V \times V \to \mathbb{R}$ -- это *скалярное произведение* на $V$.

::::

**Обозначение:** $\beta(u, v)$ обозначается, как $(u, v)$.

:::: {#definition-57}

**Определение:**  Векторное пространство $V$ над полем $R$ -- *евклидово*, если существует скалярное произведение на $V$.

::::

## Длина вектора и угол между векторами


:::: {#definition-58}

**Определение:**  Пусть $V$ евклидово пространство. *Длина вектора* $v \in V$ -- это число $|x| = \sqrt{(x, x)}$.

Определение корректно, так как скалярное произведение положительно определеннная функция.

::::

:::: {#definition-59}

**Определение:**  Пусть $V$ евклидово пространство. *Косинус угла* $\alpha$ *между векторами* $u, v \in V$ -- это число $\cos{\alpha} = \frac{(u, v)}{|u|\cdot|v|}$.

::::

:::: {#statement-59}

**Утверждение:**  (*Неравенство Коши-Буняковского*)
Пусть $V$ евклидово пространство. Тогда $\forall x, y \in V$:
$$(x, y)^2 \le (x, x)\cdot(y, y)$$
Равенство достигается только в случае $x$ пропорционально $y$.

*Доказательство:* Рассмотрим вектор $x + ty, \,\,\,\, t \in \mathbb{R}, x, y \in V$. Из того, что скалярное произведение положительно определено, получаем: $(x + ty, x + ty) \ge 0$, причем равенство выполняется в случае $x + ty = 0$, то есть $x$ пропорционально $y$.

$(x + ty, x + ty) = (x, x) + 2t(x, y) + t^2(y, y) \ge 0$ -- это квадратное уравнение относительно $t$, чтобы выполнялось неравенство нужна неположительность дискриминанта: $D = 4 (x, y)^2 - 4 (x, x)(y, y) \le 0 \Rightarrow (x, y)^2 \le (x, x)\cdot(y, y) \,\,\,\,\blacksquare$

::::

:::: {#corollary-5}

**Следствие:**  Пусть $V$ -- евклидово пространство. Тогда:

1. $|x + y| \le |x| + |y|$ (неравенство треугольника)
2. $-1 \le \cos{\alpha} \le 1$, где $\cos{\alpha}$ угол между ненулевыми векторами $x, y \in V$.

*Доказательство:* неравенство Коши-Буняковского $\,\,\,\,\blacksquare$

::::

## Матрица Грама и объем


:::: {#definition-60}

**Определение:**  Квадратная матрица $$G(v_1, \ldots, v_m) = \left(\begin{array}{cccc}
(v_1, v_1) & (v_1, v_2) & \dots & (v_1, v_m)\\
(v_2, v_1) & (v_2, v_2) & \dots & (v_2, v_m)\\
\vdots & \vdots & \ddots & \vdots\\
(v_m, v_1) & (v_m, v_2) & \dots & (v_m, v_m)
\end{array}\right)$$ -- *матрица Грама* векторов $v_1, \ldots, v_m$ евклидова пространства $V$.

::::

:::: {#statement-60}

**Утверждение:**  Матрица Грама симметрическая, то есть $G(v_1, \ldots, v_m) = G^T(v_1, \ldots, v_m)$.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#statement-61}

**Утверждение:**  Если $e = \{e_1, \ldots, e_n\}$ -- базис евклидова пространства $V$, то $\forall x, y \in V \,\,\,\, (x, y) = \left(\begin{array}{ccc}x_1 \dots x_n\end{array}\right)G(e_1, \ldots, e_n)\left(\begin{array}{c}y_1\\\vdots\\y_n\end{array}\right)$, $x = \displaystyle \sum_{i = 1}^{n}x_ie_i, \,\,\,\, y = \displaystyle \sum_{i = 1}^{n}y_ie_i$.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#statement-62}

**Утверждение:**  Векторы $e_1, \ldots, e_m$ евклидова пространства $V$ линейно независимы $\Leftrightarrow$ $\det G(v_1, \ldots, v_m) > 0$. Иначе $\det G(v_1, \ldots, v_m) = 0$.

*Доказательство:* $$\Rightarrow$$
Дополним векторы $v_1, \ldots, v_m$ до базиса $V$: $e = \{v_1, \ldots, v_m, v_{m + 1}, \ldots, v_n\}$. $G(v_1, \ldots, v_m, v_{m + 1}, \ldots, v_n)$ -- матрица скалярного произведения, которое является симметрической положительно определенной билинейной функцией, а следовательно по критерию Сильвестра все миноры $G(v_1, \ldots, v_m, v_{m + 1}, \ldots, v_n)$ положительны, то есть $\Delta_m = \det G(v_1, \ldots, v_m) > 0$.
$$\Leftarrow$$
Пусть $\det G(v_1, \ldots, v_m) > 0$. предположим, что $v_1, \ldots, v_m$ -- линейно зависимы. Тогда существует нетривиальная линейная комбинация равная $0$: $\lambda_1 v_1 + \ldots + \lambda_n v_n = 0$. Без ограничения общности считаем, что $\lambda_1 \ne 0$. Рассмотрим скалярное произведение векторов $\lambda_1 v_1 + \ldots + \lambda_n v_n$ и $v_i$. Имеем $\lambda_1(v_1, v_i) + \ldots + \lambda_n (v_n, v_i) = (0, v_i) = 0 \,\,\,\, \forall i \in \{1, \ldots, m\} \Rightarrow$
$\exists$ линейная зависимость строк матрицы $G(v_1, \ldots, v_m) \Rightarrow \det G(v_1, \ldots, v_m) = 0$. Противоречие $\,\,\,\,\blacksquare$

::::

:::: {#definition-61}

**Определение:**  *Объем параллелепипеда, натянутого на векторы* $v_1, \ldots, v_m$ -- это число $V(v_1, \ldots, v_m) = \sqrt{\det G(v_1, \ldots, v_m)}$.

::::

## Ортогональные и ортонормированные базисы


:::: {#definition-62}

**Определение:**  Пусть $V$ -- евклидово пространство. Векторы $x, y \in V$ -- *ортогональны*, если $(x, y) = 0$.

::::

:::: {#statement-63}

**Утверждение:**  Если $v_1, \ldots, v_m$ -- ненулевые попарно ортогональные векторы евклидова пространства $V$, то $v_1, \ldots, v_m$ -- линейно независимы.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#definition-63}

**Определение:**  Базис евклидова пространства $V$, состоящий из ортогональных векторов -- *ортогональный*.

::::

:::: {#definition-64}

**Определение:**  Отртогональный базис евклидова пространства $V$, состоящий из единичных векторов -- *ортонормированный*.

::::

:::: {#statement-64}

**Утверждение:**  Пусть $e = \{e_1, \ldots, e_n\}$ -- ортонормированный базис евклидова пространства $V$. Тогда

1. $G(e_1, \ldots, e_n) = E$
2. $(x, y) = x_1y_1 + \ldots + x_ny_n, \,\,\,\, x = \displaystyle \sum_{i = 1}^{n}x_i e_i, \,\,\,\, y = \displaystyle \sum_{i = 1}^{n}y_i e_i$
3. $(x, e_i) = x_i, \,\,\,\, x = \displaystyle \sum_{i = 1}^{n}x_i e_i$

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#definition-65}

**Определение:**  Квадратная матрица $C$ *ортогональна*, если $C^T\cdot C = E$.

::::

:::: {#statement-65}

**Утверждение:**  

1. Пусть $e = \{e_1, \ldots, e_n\}$ и $\tilde{e} = \{\tilde{e}_1, \ldots, \tilde{e}_n\}$ -- ортонормированные базисы евклидова пространства $V$. Тогда $C_{e \to \tilde{e}}$ -- ортогональна.

2. Пусть $e = \{e_1, \ldots, e_n\}$ -- ортонормированный базис евклидова пространства $V$, $\tilde{e} = \{\tilde{e}_1, \ldots, \tilde{e}_n\}$ -- базис $V$ и $C_{e \to \tilde{e}}$ -- ортогональна. Тогда базис $\tilde{e}$ ортонормированный.

*Доказательство:*

1. $$C_{e \to \tilde{e}} = (c_{ij})$$
$$\begin{cases}
    0, i \ne j\\
    1, i = j
\end{cases} = \delta^k_j = (\tilde{e}_k, \tilde{e}_j) = \left(\displaystyle \sum_{i = 1}^{n}c_{ij}e_i, \displaystyle \sum_{l = 1}^{n}c_{lk}e_l\right)=$$
$$= \displaystyle \sum_{i = 1}^{n}\displaystyle \sum_{l = 1}^{n}c_{ij}c_{lk}(e_i, e_l) = \displaystyle \sum_{i = 1}^{n}c_{ij}c_{ik} \Rightarrow C_{e\to \tilde{e}}^TC_{e\to \tilde{e}} = E \,\,\,\,\blacksquare$$

2. что-то интересное

::::

# Процесс ортогонализации Грама-Шмидта(существование ортогонального базиса)


Пусть Пусть $V$ -- евклидово пространство. Векторы $\{f_1, \ldots, f_m\}$ -- базис $V$.

Построим ортогональный базис $\{e_1, \ldots, e_m\}$.

$e_1 = f_1$
$e_2 = f_2 + \lambda e_1$, причем $(e_2, e_1) = 0 = (f_2, e_1) + \lambda (e_1, e_1) \Rightarrow \lambda = -\frac{(f_2, e_1)}{(e_1, e_1)}$, можем делить на $(e_1, e_1)$, так как $e_1 \ne 0$
$\vdots$
$e_n = f_n - \lambda_1 e_1 - \lambda_2 e_2 - \ldots - \lambda_{n - 1} e_{n - 1}$, $\forall i \in \{1, \ldots, n - 1\} \,\,\,\, (e_n, e_i) = 0 = (f_n, e_i) - \lambda_i (e_i, e_i)$, все остальные коэффиценты равны нулю, так как $e_1, \ldots, e_{n - 1}$ -- ортогональны, а следовательно $\lambda_i = \frac{(f_n, e_i)}{(e_i, e_i)}$, $e_i \ne 0$, так как ...

:::: {#theorem-13}

**Теорема:**  В любом $n$-мерном евклидовом пространстве существоет ортогональный базис.

*Доказательство:* см. выше $\,\,\,\,\blacksquare$

::::

:::: {#corollary-6}

**Следствие:**  Пусть $f = \{f_1, \ldots, f_n\}$ -- базис евклидова пространства $V$. $e = \{e_1, \ldots, e_n\}$ -- ортогональный базис $V$, полученный ортогонализацией Грама-Шмидта. Тогда матрица перехода от $f$ к $e$ унитреугольная.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#statement-66}

**Утверждение:**  (о $QR$- разложении) Любая невырожденная квадратная матрица $A$ представима в виде произведения унитреугольной матрицы $Q$ и ортогональной матрицы $R$.

*Доказательство:* Невырожденная матрица -- это матрица перехода между базисами $e$ и $f$ некоторого евклидова пространства, то есть $A = C_{e \to f}$. Найдем ортогональный базис $e’$ процессом ортогонализации Грама-Шмидта. Матрица перехода от $e$ к $e’$ унитреугольная, а матрица перехода от $e’$ к $f$ ортогональная. $C_{e \to f} = C_{e \to e’} \cdot C_{e’ \to f} \,\,\,\,\blacksquare$

::::

## Ортогональное дополнение


:::: {#definition-66}

**Определение:**  $V$ -- евклидово пространство, $U$ -- его подпространство. Множество $U^{\perp} = \{x \in V: \,\,\,\, (x, u) = 0 \,\,\,\, \forall u \in U\}$ -- *ортогональное дополнение* подпространства $U$.

::::

:::: {#statement-67}

**Утверждение:**  $V$ -- евклидово пространство, $U$ -- его подпространство. Тогда $U^{\perp}$ -- подпространство $V$.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#statement-68}

**Утверждение:**  $V$ -- евклидово пространство, $U$ -- его подпространство. Тогда 

1. $U \oplus U^{\perp}$, в частности $U \cap U^{\perp} = \{0\}$
2. $V = U \oplus U^{\perp}$.

*Доказательство:* 

1. Пусть $\exists x \in U \cap U^{\perp} \Rightarrow (x, x) = 0 \Rightarrow x = 0 \,\,\,\,\blacksquare$
2. Пусть $\{e_1, \ldots, e_m\}$ ортогональный базис в $U$. Дополним его до базиса $V$ векторами $\{f_{m + 1}, \ldots, f_n\}$. Процессом ортогонализации Грама-Шмидта получим ортогональный базис $\{e_1, \ldots, e_n\}$ (векторы $e_1, \ldots, e_m$ при ортогонализации не изменятся, так как ортогональны). Рассмотрим вектор $x \in U^{\perp}$. $x \in V \Rightarrow x = x_1 e_1 + \ldots + x_n e_n$, где $x_i = (x, e_i)$. $\forall u \in U \,\,\,\, (x, u) = 0 \Rightarrow \forall i \in \{1, \ldots, m\} \,\,\,\, (x, e_i) = 0 \Rightarrow \forall x \in U^{\perp} \,\,\,\, x \in <e_{m + 1}, \ldots, e_n> \,\,\,\,\blacksquare$

::::

:::: {#corollary-7}

**Следствие:**  $V$ -- евклидово пространство, $U$ -- его подпространство. Тогда любой вектор $x$ из $V$ единственным образом представляется в виде суммы $u + u^{\perp}$, где $u \in U$ и $u^{\perp} \in U^{\perp}$.

*Доказательство:*

::::

:::: {#definition-67}

**Определение:**

$u$ -- *ортогональная проекция вектора* $x$ *на* $U$. Обозначается: $\operatorname{пр}_{U}x$.
$u^{\perp}$ -- *ортогональная составляющая вектора* $x$. Обозначается: $\operatorname{ort}_{U}x$.

::::

## Расстояния в евклидовом пространстве

:::: {#definition-68}

**Определение:**  Пусть $V$ -- евклидово пространство.

*Расстояние между векторами* $x, y \in V$ -- это $\rho(x, y) = |x - y|$.

*Расстояние между подпространствами* $X, Y \subset V$ -- это $\inf\{\rho(x, y): \,\,\,\, x \in X, \,\,\,\, y \in Y\}$.

*Расстояние между вектором* $x \in V$ *и  подпространством* $U \subset V$ -- это $\rho(x, U) = \inf\{\rho(x, u): \,\,\,\, u \in U\}$.

*Угол между вектором* $x \in V$ *и  подпространством* $U \subset V$ -- это наименьший из всех углов между $x$ и вектором из $U$.

::::

**Утверждение:**<a name="statement-3"></a> Пусть $V$ -- евклидово пространство, $U$ -- попространство $V$, $x \in V$. Тогда

1. $\rho(x, U) = |\operatorname{ort}_Ux|$
2. Угол между $x$ и $U$ равен углу между $x$ и $\operatorname{пр}_{U}x$.

*Доказательство:* неприятно.

::::

## Изоморфизм евклидовых пространств


:::: {#definition-69}

**Определение:**  Евклидовы пространства $U$ и $W$ *изоморфны*, если существует отображение $\varphi: U \to W$:

1. $\varphi$ - изоморфизм $U$ и $W$, как векторных пространств.
2. $\forall x, y \in U \,\,\,\, (x, y) = (\varphi(x), \varphi(y))$

Обозначается: $U \cong W$.

::::

:::: {#theorem-14}

**Теорема:**  Пусть $U$ и $W$ -- конечномерные евклидовы пространства. Тогда $U \cong W \Leftrightarrow \dim U = \dim V$.

*Доказательство:* 

$$\Rightarrow$$

$U \cong W \Rightarrow U$ изоморфно $W$, как векторное пространство, а следовательно по теореме размерности $U$ и $W$ совпадают.

$$\Leftarrow$$
Возьмем ортогональные базисы $\{e_1, \ldots, e_n\}$ в $U$ и $\{f_1, \ldots, f_n\}$ в $W$. Рассмотрим $\varphi: e_i \mapsto f_i \,\,\,\,\blacksquare$ 

::::

# Линейные функции в евклидовом пространстве


:::: {#theorem-15}

**Теорема:**  Пусть $V$ -- конечномерное евклидово пространство. Тогда

1. $\forall a \in V \,\,\,\, \exists$ линейная функция $\varphi_a: V \to V \,\,\,\, \varphi_a: x \mapsto (x, a)$.
2. Отображение $\psi: V \to V^{*} \,\,\,\, \psi: a \to \varphi_a$ - изоморфизм пространств $V$ и $V^{*}$.
3. В ортонормированном базисе $e$ координаты вектора $a$ совпадают с коэффицентами $\varphi_a$ в сопряженном к $e$ базисе.

*Доказательство:*

1. По определению скалярного произведения.
2. Докажем, что $\psi$ -- линейно.
$\forall x, y, z \in V \,\,\,\, \psi(x + y) = \varphi_{x + y} = (z, x + y) = (z, x) + (z, y) = \varphi_x + \varphi_y = \psi(x) + \psi(y)$.
Линейность по $\lambda \in \mathbb{R}$ аналогично.

Докажем, что $\psi$ -- биекция.
Пусть $x_1, x_2 \in V, \,\,\,\, x_1 \ne x_2$ и $\psi(x_1) = \psi(x_2) \Rightarrow \varphi_{x_1} = \varphi_{x_2} \Rightarrow \forall x \in V \,\,\,\, (x, x_1) = (x, x_2) \Rightarrow (x, x_1 - x_2) = 0$. Возьмем $x = x_1 - x_2 \Rightarrow x_1 = x_2$, следовательно $\psi$ -- инъекция. 

Докажем, что $\psi$ -- сюръекция.
Пусть $\psi(x) = 0 \Rightarrow \varphi_x = 0 \Rightarrow \forall v \in V \,\,\,\, (v, x) = 0$. Возьмем $v = x \Rightarrow (x, x) = 0 \Rightarrow x = 0$, следовательно $\ker(\psi) = \{0\}$. Так как $V$ и $V^{*}$ - изоморфны размерности $V$ и $V^{*}$ совпадают. По утверждению $\dim V = \dim \operatorname{img}\psi + \dim \ker \psi = \dim \operatorname{img}\psi \Rightarrow V = \operatorname{img}\psi$, следовательно $\psi$ -- сюръекция. $\,\,\,\,\blacksquare$

3. $\,\,\,\,\blacksquare$

::::

## Билинейные функции и линейные операторы в евклидовом пространстве


:::: {#theorem-16}

**Теорема:**  Пусть $V$ -- конечномерное евклидово пространство. Тогда

1. Для любого линейного оператора $\mathcal{A}$ существует билинейная функция $\beta_{\mathcal{A}}(x, y) = (x, \mathcal{A}(y))$.
2. Для любой билинейной функции$\beta$ существует линейный оператор $\mathcal{A}$, такой, что $\beta(x, y) = (x, \mathcal{A}(y)) \,\,\,\, \forall x, y \in V$.
3. В ортонормированном базисе матрица билинейной функции $\beta_{\mathcal{A}}$ совпадает с матрицей линейного оператора $\mathcal{A}$.

*Доказательство:* 

1. Докажем, что $\beta$ билинейная функция. $\beta(x + y, z) = (x + y, \mathcal{A}(z)) = (x, \mathcal{A}(z)) + (y, \mathcal{A}(z)) = \beta(x, z) + \beta(y, z)$ и т.д. $\,\,\,\,\blacksquare$

2. Рассмотрим линейный оператор с матрицей, совпадающей с матрицей $\beta \,\,\,\,\blacksquare$

3. Пусть $B$ -- матрица билинейной функции $\beta_{\mathcal{A}}$, $A$ -- матрица линейного оператора $\mathcal{A}$. $x$ -- вектор с столбцом координат $X$, $y$ -- вектор с столбцом координат $Y$. Тогда $\beta_{\mathcal{A}}(x, y) = X^TBY$. И $(x, \mathcal{A}(y)) = X^TAY \Rightarrow B = A \,\,\,\,\blacksquare$

::::

## Сопряженный линейный оператор

:::: {#definition-70}

**Определение:**  Пусть $V$ - евклидово пространство, $\mathcal{A}$ - линейный оператор на $V$. Линейный оператор $\mathcal{A}^{*}$ -- *сопряженный* к $\mathcal{A}$, если $\forall x, y \in V \,\,\,\, (\mathcal{A}(x), y) = (x, \mathcal{A}^{*}(y))$.

::::

:::: {#theorem-17}

**Теорема:**  Пусть $V$ - евклидово пространство, $\dim V = n$. Тогда у любого линейного оператора $\mathcal{A}$ существует единственный сопряженный линейный оператор $\mathcal{A}^{*}$.

*Доказательство:* Пусть $A$ матрица линейного оператора $\mathcal{A}$. Рассмотрим $\mathcal{B}$ -- линейный оператор с матрицей $A^T$. Имеем $(\mathcal{A}(x), y) = (AX)^TY = X^TA^TY = (x, \mathcal{B}(y))$, то есть $\mathcal{B}$ сопряженный к $\mathcal{A}$ линейный оператор. Существование доказано.

Докажем единственность. Пусть $\mathcal{B}$ и $\mathcal{C}$ сопряженные к $\mathcal{A}$ линейные операторы, то есть $(\mathcal{A}(x), y) = (x, \mathcal{B}(y)) = (x, \mathcal{C}(y)) \Rightarrow$ матрицы $\mathcal{B}$ и $\mathcal{C}$ сопадают $\,\,\,\,\blacksquare$ 

::::

:::: {#corollary-8}

**Следствие:**  Пусть $V$ -- конечномерное евклидово пространство. $\mathcal{A}$ -- линейный оператор на $V$, $A$ -- матрица $\mathcal{A}$ в ортонормированном базисе $e$. Тогда матрица сопряженного к $\mathcal{A}$ линейного оператора $\mathcal{A}^{*}$ в базисе $e$ -- это $A^T$.

*Доказательство:* см. утверждение $\,\,\,\,\blacksquare$

::::

### Самосопряженный линейный оператор


:::: {#definition-71}

**Определение:**  Пусть $V$ -- евклидово пространство. Линейный оператор $\mathcal{A}$ -- *самосопряженный*, если $\mathcal{A}^{*} = \mathcal{A}$.

::::

:::: {#statement-69}

**Утверждение:**  Линейный оператор $\mathcal{A}$ на конечномерном евклидовом пространстве самосопряженный $\Leftrightarrow$ его матрица $A$ *симметрическая*, то есть $A = A^T$.

*Доказательство:* см. утверждение $\,\,\,\,\blacksquare$

::::

#### Канонический вид самосопряженного линейного оператора

:::: {#lemma-2}

**Лемма:**  Пусть $V$ -- конечномерное евклидово пространство, $\mathcal{A}$ - самосопряженный линейный оператор на $V$, $U$ -- инвариантное подпространство оператора $\mathcal{A}$. Тогда $U^{\perp}$ (ортогональное дополнение $U$) -- инвариантное подпространство оператора $\mathcal{A}$.

*Доказательство:* 

$U$ -- инвариантное пространство относительно оператора $\mathcal{A}$, то есть $\forall u \in U \,\,\,\, \mathcal{A}(u) \in U$. $\forall u^{\perp} \in U^{\perp} \,\,\,\, (u^{\perp}, u) = 0$ $\forall u \in U \,\,\,\, (\mathcal{A}(u^{\perp}), u) = (u^{\perp}, \mathcal{A}(u)) = 0 \,\,\,\,\blacksquare$

::::

:::: {#theorem-18}

**Теорема:**  (канонический вид самосопряженного линейного оператора) Пусть $V$ - евклидово пространство, $\dim V = n$. Тогда у любого самосопряженного линейного оператора $\mathcal{A}$ существует ортонормированный базис, состоящий из собственных векторов $\mathcal{A}$.

*Доказательство:* 

По индукции по размерности пространства.

**База:** 

$n = 1$ Очевидно $\,\,\,\,\blacksquare$

$n = 2$ Пусть матрица $\mathcal{A}$ -- это $A = \left(\begin{array}{cc} a & c \\ c & b \end{array}\right)$. $\chi_{\mathcal{A}}(t) = \left|\begin{array}{cc} t - a & -c \\ -c & t - b \end{array}\right| = t^2 - t (a + b) + ab - c^2$. $D = (a + b)^2 - 4(ab - c^2) = (a - b)^2 + c^2 > 0 \Rightarrow$ существует два действительных корня, то есть два собственных значения, а так как векторы, отвечающие различным собственным значениям самосопряженного линенйного оператора ортогональны $(\mathcal{A}(x), y) = \lambda_1 (x, y) = (x, \mathcal{A}(y)) = \lambda_2 (x, y)$, искомый базис найден $\,\,\,\,\blacksquare$

**Предположение индукции:** Для любого $k, \,\,\,\, 3 \le k < n$ существует базис из собственных векторов у самосопряженного линейного оператора на пространстве размерности $k$.

**Шаг:** У любого векторного пространства над $\mathbb{R}$ существует одномерное или двумерное инвариантное подпространство $U$. $V = U \oplus U^{\perp}$ (см. утверждение), $\dim U^{\perp} < n \Rightarrow$ по предположению индукции в $U^{\perp}$ существует ортогональный базис из собственных векторов $\,\,\,\,\blacksquare$

::::

# Свойства самосопряженного линейного оператора

:::: {#statement-70}

**Утверждение:**  (свойства) Пусть $\mathcal{A}$ самосопряженный линейный оператор.

1. $\chi_{\mathcal{A}}(t)$ -- имеет только действительные корни.
2. Для любого собственного значения $\lambda \,\,\,\, \dim V_{\lambda} = k$, где $k$ -- кратность $\lambda$.
3. Собственные вектора, отвечающие различным собственным значениям, ортогональны.

*Доказательство:*

1. По теореме $\,\,\,\,\blacksquare$
2. По теореме $\mathcal{A}$ диагонализируем, а следовательно по теореме утверждение выполнено $\,\,\,\,\blacksquare$
3. $(\mathcal{A}(x), y) = \lambda_1 (x, y) = (x, \mathcal{A}(y)) = \lambda_2 (x, y) \,\,\,\,\blacksquare$

::::

:::: {#definition-72}

**Определение:**  Матрица $A \in M_n(\mathbb{R})$ -- *симметрическая*, если $A = A^T$.

::::

:::: {#corollary-9}

**Следствие:**  Пусть $A$ - симметрическая вещественная матрица. Тогда $\exists D, C \in M_n(\mathbb{R}): \,\,\,\, D$ -- диагональна, $C$ -- ортогональна и $A = C^{-1}DC$.

*Доказательство:*

$A$ -- симметрическая матрица, а значит ей соответствует самосопряженный линейный оператор. По теореме существует ортонормированный базис, в котором матрица $\mathcal{A}$ диагональна, то есть $A = C^{-1}DC$, где $C$ -- ортогональна (так как матрица перехода от ортогонального базиса к ортогональному), а $D$ -- диагональна $\,\,\,\,\blacksquare$ 

::::

:::: {#corollary-10}

**Утверждение:** Для любой симметрической билинейной функции существует ортонормированный базис, такой, что в этом базисе матрица билинейной функции диагональна и $\beta(x, y) = \lambda_1 x_1 y_1 + \ldots + \lambda_n x_n y_n$, а $\lambda_1, \ldots, \lambda_n$ -- корни характеристического многочлена.

*Доказательство:* Рассмотрим самосопряженный линейный оператор с матрицей билинейной функции $\,\,\,\,\blacksquare$ 

::::

:::: {#theorem-19}

**Теорема:**  Для любой квадратичной функции $q: V\times V \to \mathbb{R}$ существует ортонормированный базис $e$, в котором $q(x) = \lambda_1 x_1^2 + \ldots + \lambda_n x_n^2$, а $\lambda_1, \ldots, \lambda_n$ -- корни характеристического многочлена в некотором данном базисе.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#definition-73}

**Определение:**  Нахождение ортонормированного базиса, в котором квадратичная функция равна сумме квадратов -- *приведение к главным осям*.

**Например:** Нахождение канонического базиса для кривой второго порядка -- это приведение к главным осям.

::::

#### Одновременное приведение пары квадратичных форм к сумме квадратов

:::: {#theorem-20}

**Теорема:**  <details>
<summary></summary>
а что нет чего-то что нельзя описать
</details> 

Пусть $V$ - векторное пространство. $\dim V = n$. $q$ и $h$ - квадратичные функции, $h$ - положительно определена. Тогда существует базис, в котором:
$$q(x) = \lambda_1 x_1^2 + \ldots + \lambda_n x_n^2$$
$$h(x) = x_1^2 + \ldots + x_n^2$$

*Доказательство:*

$h$ -- положительно определена. Пусть $h$ -- скалярное произведение. Тогда по теореме существует ортонормированный базис, в котором $q$ имеет нужный вид, а $h(x)$ в любом ортонормированном базисе имеет нужный вид (так как скалярное произведение) $\,\,\,\,\blacksquare$

::::

## Ортогональный линейный оператор

:::: {#definition-74}

**Определение:**  $V$ - евклидово пространство. Линейный оператор $\mathcal{A}$ -- *ортогональный*, если он сохраняет скалярное произведение, то есть $(\mathcal{A}(x), \mathcal{A}(y)) = (x, y)$.

::::

## Свойства ортогонального линейного оператора


:::: {#statement-71}

**Утверждение:**  $\mathcal{A}$ - ортогональный линейный оператор $\Leftrightarrow$ в ортонормированном базисе матрица $A$ линейного оператора $\mathcal{A}$ ортогональна, то есть $A^TA = E$.

*Доказательство:* Пусть $A$ матрица $\mathcal{A}$ в ортонормированном базисе. Тогда $X^TY = (x, y) = (\mathcal{A}(x), \mathcal{A}(y)) = (AX)^TAY = X^TA^TAY \Rightarrow A^TA = E \,\,\,\,\blacksquare$

::::

:::: {#statement-72}

**Утверждение:**  $\mathcal{A}$ - ортогональный линейный оператор $\Leftrightarrow$ $\mathcal{A}\mathcal{A}^{*} = \mathcal{I}$.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#statement-73}

**Утверждение:**  

Пусть $\mathcal{A}$ -- ортогональный линейный оператор. $A$ -- его матрица. Тогда

1. $\mathcal{A}$ сохраняет длины векторов.
2. $\mathcal{A}$ сохраняет углы между векторами.
3. $\mathcal{A}$ переводит ортогональный базис в ортогональный.
4. $\det(A) = \pm 1$
5. Если существуют собственные значения $\mathcal{A}$, они равны $\pm 1$.
6. $\mathcal{A}$ невырожден.

*Доказательство:*

::::

### Канонический вид ортогонального линейного оператора

:::: {#lemma-3}

**Лемма:** Пусть $\mathcal{A}$ ортогональный линейный оператор на евклидовом пространстве $V$, $\dim V = n$, $U$ -- инвариантное подпространство оператора $\mathcal{A}$. Тогда $U^{\perp}$ -- инвариантное подпространство $\mathcal{A}$.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#theorem-21}

**Теорема:**  Пусть $\mathcal{A}$ ортогональный линейный оператор на евклидовом пространстве $V$, $\dim V = n$. Тогда существует ортонормированный базис, в котором матрица $\mathcal{A}$ блочно-диагональная и состоит из матриц вида $\left(\begin{array}{cc}
\cos(\varphi) & \sin(\varphi)\\
-\sin(\varphi) & \cos(\varphi)
\end{array}\right)$ и не более, чем одного блока $1$, и не более, чем одного блока $-1$.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

# Положительно определенный линейный оператор

:::: {#definition-75}

**Определение:**  Линейный оператор $\mathcal{A}$ *положительно определен*, если он самосопряженный и $\forall x \in V \,\,\,\, (x, \mathcal{A}(x)) > 0$.

::::

:::: {#statement-74}

**Утверждение:**  Пусть $v$ собственный вектор положительно определенного линейного оператора $\mathcal{A}$, отвечающий собственному значению $\lambda$. Тогда $\lambda > 0$.

*Доказательство:* $\mathcal{A}$ -- положительно определен, следовательно $0 < (v, \mathcal{A}(v)) = \lambda (v, v)$, а так как $(v, v) > 0, \,\,\,\, v \ne 0$, $\,\,\,\,\lambda > 0 \,\,\,\,\blacksquare$ 

::::

:::: {#statement-75}

**Утверждение:**  Все собственные значения самосопряженного линейного оператора $\mathcal{A}$ положительны $\Leftrightarrow$ $\mathcal{A}$ - положительно определен.

*Доказательство:* $\mathcal{A}$ самосопряженный, значит диагонализируем, значит $V = V_1 \oplus \ldots \oplus V_s$, значит $\forall v$ существует собственное значение $\lambda$, такое, что $\mathcal{A}(v) = \lambda v \Rightarrow (v, \mathcal{A}) = \lambda (v, v) > 0 \,\,\,\,\blacksquare$

::::

:::: {#lemma-4}

**Лемма:**  Из любого положительно определенного линейного оператора $\mathcal{A}$ можно извлечь квадратный корень, то есть существует единственный положительно определенный линейный оператор $\mathcal{B}$, такой, что $\mathcal{B}^2 = \mathcal{A}$.

*Доказательство:* $\mathcal{A}$ положительно определен, а значит диагонализируем, причем на главной диагонали стоят положительные числа: $A = \left(\begin{array}{ccc} \lambda_1 & \dots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \dots & \lambda_s \end{array}\right)$. Рассмотрим $B = \left(\begin{array}{ccc} \sqrt{\lambda_1} & \dots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \dots & \sqrt{\lambda_s} \end{array}\right) \,\,\,\,\blacksquare$

::::

## Полярное разложение


:::: {#theorem-22}

**Теорема:**  (о полярном разложении) Пусть $\mathcal{A}$ невырожденный линейный оператор. Тогда $\mathcal{A}$ единственным образом представляется в виде $\mathcal{A} = \mathcal{A}^{+}\mathcal{A}^{\perp}$, где $\mathcal{A}^{+}$ - положительно определенный линейный оператор, а $\mathcal{A}^{\perp}$ - ортогональный линейный оператор. 

*Доказательство:*

Рассмотрим линейный оператор $\mathcal{A}\mathcal{A}^{*}$. По свойствам линейного оператора $\mathcal{A}\mathcal{A}^{*}$ -- самосопряженный ($(\mathcal{A}\mathcal{A}^{*})^{*} = \mathcal{A^{**}}\mathcal{A}^{*} = \mathcal{A}\mathcal{A}^{*}$). 

Докажем, что $\mathcal{A}\mathcal{A}^{*}$ положительно определен $(x, \mathcal{A}\mathcal{A}^{*}(x)) = (\mathcal{A}^{*}(x), \mathcal{A}^{*}(x)) > 0$.

Значит по лемме можем извлечь корень из $\mathcal{A}\mathcal{A}^{*}$, который также будет положительно определенным линейным оператором. Обозначим $\left(\mathcal{A}^{+}\right)^2 = \mathcal{A}\mathcal{A}^{*}$. Так как $\mathcal{A}^{+}$ положительно определен, он невырожден, а следовательно у него существует обратный. Пусть $\mathcal{A}^{\perp} = \left(\mathcal{A}^{+}\right)^{-1} \mathcal{A}$.

Докажем, что $\mathcal{A}^{\perp}$ -- ортогональный линейный оператор. $\mathcal{A}\mathcal{A}^{*} = \mathcal{A}^{+}\mathcal{A}^{\perp}(\mathcal{A}^{+}\mathcal{A}^{\perp})^{*} = \mathcal{A}^{+}\mathcal{A}^{\perp}(\mathcal{A}^{\perp})^{*}\mathcal{A}^{+} = \left(\mathcal{A}^{+}\right)^2 \Rightarrow$

$\mathcal{A}^{\perp}(\mathcal{A}^{\perp})^{*} = \mathcal{I} \,\,\,\,\blacksquare$

(Единственность -- возьмите разные и докажите, что они одинаковые)

::::

## Векторные пространства над полем комплексных чисел


:::: {#definition-76}

**Определение:**  Пусть $V$ - векторное пространство над $\mathbb{C}$. Функция $\beta: V \times V \to \mathbb{C}$ -- *полуторалинейная*, если $\forall x, y, z \in V, \,\,\,\, \lambda \in \mathbb{C}$:

1. $\beta(x + y, z) = \beta(x, z) + \beta(y, z)$.
2. $\beta(\lambda x, y) = \lambda \beta(x, y)$.
3. $\beta(x, y + z) = \beta(x, y) + \beta(x, z)$.
4. $\beta(x, \lambda y) = \bar{\lambda} \beta(x, y)$.

::::

:::: {#definition-77}

**Определение:**  Пусть $V$ - векторное пространство над $\mathbb{C}$, $\{e_1, \ldots, e_n\}$ - базис $V$, $\beta$ - полуторалинейная функция. $\left(\begin{array}{ccc}b_{11} & \dots & b_{1n}\\\vdots & \ddots & \vdots\\b_{n1} & \dots & b_{nn}\end{array}\right) = B$, где $b_{ij} = \beta(e_i, e_j)$ -- *матрица полуторалинейной функции* $\beta$.

::::

:::: {#statement-76}

**Утверждение:**  Пусть $\beta$ - полуторалинейная функция, $B$ -- ее матрица в базисе $\{e_1, \ldots, e_n\}$. Тогда $\beta(x, y) = X^TB\bar{Y}$, где $X$ и $Y$ -- столбцы координат векторов $x$ и $y$.

*Доказательство:*

$\beta(x, y) = \beta(\displaystyle \sum_{i = 1}^{n}\lambda_i e_i, \displaystyle \sum_{j = 1}^{n}\mu_j e_j) = \displaystyle \sum_{i, j = 1}^{n}\lambda_i \beta(e_i, e_j) \bar{\mu}_j = X^T B \bar{Y} \,\,\,\,\blacksquare$

::::

:::: {#statement-77}

**Утверждение:**  Пусть $\beta$ - полуторалинейная функция, $B$ -- ее матрица в базисе $\{e_1, \ldots, e_n\}$, $\tilde{B}$ -- ее матрица в базисе $\{\tilde{e}_1, \ldots, \tilde{e}_n\}$. Тогда
$$\tilde{B} = C_{e \to \tilde{e}}^TB\bar{C}_{e \to \tilde{e}}$$

*Доказательство:*

$$X^TB\bar{Y} = (C\tilde{X})^T B \bar{C\tilde{Y}} = \tilde{X}^T \tilde{B} \bar{\tilde{Y}} \,\,\,\,\blacksquare$$

::::

:::: {#definition-78}

**Определение:**  Полуторалинейная функция $\beta$ -- *эрмитова*, если $\forall x, y \in V \,\,\,\, \beta(x, y) = \overline{\beta(y, x)}$.

::::

:::: {#definition-79}

**Определение:**  Матрица $n$ на $n$ -- *эрмитова*, если $B^T = \overline{B}$.

::::

:::: {#statement-78}

**Утверждение:**  Полуторалинейная функция $\beta$ - эрмитова $\Leftrightarrow$ ее матрица в некотором базисе эрмитова.

*Доказательство:* 

$$\Rightarrow$$

$\beta(x, y) = X^T B \bar{Y} =$ (так как $\beta(x, y)$ -- число) $=(X^T B \bar{Y})^T = \bar{Y}^T B^T X =\overline{\beta(y, x)} = \overline{Y^TB\bar{X}} = \bar{Y}^T \bar{B} X \,\,\,\,\blacksquare$

::::

### Свойства эрмитовой матрицы


:::: {#statement-79}

**Утверждение:**  Пусть $B$ - эрмитова матрица. Тогда

1. $b_{ii} \in \mathbb{R}$.
2. $\det(B) \in \mathbb{R}$.

*Доказательство:* 

1. Пусть $B = \left(\begin{array}{ccc} b_{11} & \dots & b_{1n} \\ \vdots & \ddots & \vdots \\ b_{n1} & \dots & b_{nn} \end{array}\right)$. Имеем $B^T = \left(\begin{array}{ccc} b_{11} & \dots & b_{n1} \\ \vdots & \ddots & \vdots \\ b_{1n} & \dots & b_{nn} \end{array}\right) = \bar{B} = \left(\begin{array}{ccc} \bar{b}_{11} & \dots & \bar{b}_{1n} \\ \vdots & \ddots & \vdots \\ \bar{b}_{n1} & \dots & \bar{b}_{nn} \end{array}\right) \Rightarrow b_{ii} = \bar{b}_{ii} \Rightarrow b_{ii} \in \mathbb{R} \,\,\,\,\blacksquare$
2. $\det(B) = \det(B^T) = \det(\bar{B})$. Так как определитель -- это сумма произведений элементов матрицы, а $\bar{a}\bar{b} = \bar{ab}$ и $\bar{a} + \bar{b} = \bar{a + b}$, имеем $\det(\bar{B}) = \bar{\det(B)} \Rightarrow \det(B) \in \mathbb{R} \,\,\,\,\blacksquare$

::::

:::: {#definition-80}

**Определение:**  $q: V \to \mathbb{C}$ -- *эрмитова квадратичная форма*, если $\forall x \in V \,\,\,\, q(x) = \beta(x, x)$, где $\beta$ - эрмитова функция.

::::

#### Нахождение эрмитовой функции по ее квадратичной функции


:::: {#statement-80}

**Утверждение:**  Пусть $q(x)$ - эрмитова квадратичная форма. Тогда $\beta(x, y) = \frac{1}{4}(q(x + y) + i q(x + i y) - q(x - y) - i q(x - i y))$.

*Доказательство:*

::::

:::: {#statement-81}

**Утверждение:** Эрмитова квадратичная функция принимает только вещественные значения.

*Доказательство:*

$q(x) = \beta(x, x) = \overline{\beta(x, x)} = \overline{q(x)} \,\,\,\,\blacksquare$

::::

:::: {#statement-82}

**Утверждение:** Любая эрмитова полуторалинейная функция $\beta$ и соответствующая ей эрмитова квадратичная форма $q$ приводятся к следующему виду: 
$$\beta(x, y) = x_1 \overline{y}_1 + \ldots + x_k \overline{y}_k - x_{k + 1} \overline{y}_{k + 1} - \ldots - x_{k + l} \overline{y}_{k + l}$$
$$q(x) = |x_1|^2 + \ldots + |x_k|^2 - |x_{k + 1}|^2 - \ldots - |x_{k + l}|^2$$

*Доказательство:*

::::

:::: {#definition-81}

**Определение:**  <br>$k$ -- *положительный индекс инерции*.<br><br>$l$ -- *отрицательный индекс инерции*.

::::


:::: {#theorem-23}

**Теорема:**  Положительный и отрицательный индексы инерции инварианты полуторалинейной эрмитовой функции.

*Доказательство:*

::::

:::: {#definition-82}

**Определение:**  Эрмитова квадратичная форма $q$ *положительно определенная*, если $\forall x \in V \,\,\,\, q(x) > 0$. Cоответствующая $q$ эрмитова полуторалинейная функция $\beta$ -- *положительно определена*.

::::

Для эрмитовой полуторалинейной функции верен критерий Cильвестра и аналог формулы Якоби.

## Унитарные пространства


:::: {#definition-83}

**Определение:**  Векторное пространство, на котором фиксирована положительно определенная эрмитова полуторалинейная функция $\beta$ -- *унитарное*. $\beta$ называется *скалярное произведение*.

**Обозначение:** $\beta(x, y) = (x, y)$

::::

:::: {#definition-84}

**Определение:**  *Длина вектора* в унитарном пространстве со скалярным произведением $(x, y)$ -- это $|x| = \sqrt{(x, x)}$.

::::

:::: {#statement-83}

**Утверждение:**  (свойства длины)

1. $|x + y| \le |x| + |y|$
2. $|(x, y)|^2 = (x, y)(y, x) \le (x, x)(y, y)$

*Доказательство:*

1. $$(x, y) = |(x, y)|e^{i \varphi}$$
$$0 \le (xt + ye^{i \varphi}, xt + ye^{i \varphi}) =$$
$$=(xt, xt) + (xt, ye^{i \varphi}) + (y e^{i \varphi}, xt) + (y e^{i \varphi}, y e^{i \varphi}) =$$
$$= (x, x)t^2 + t (e^{-i \varphi}(x, y) + e^{i \varphi}\overline{(x, y)}) + (y, y)$$
($t = \bar{t}$, так как $t \in \mathbb{R}$)
$$D < 0$$
$$4|(x, y)|^2 - 4 (x, x) (y, y) < 0 \,\,\,\,\blacksquare$$

::::


# Ортогональные и ортонормированные базисы в унитарном пространстве


:::: {#definition-85}

**Определение:**  Пусть $V$ - унитарное пространство. Векторы $x, y \in V, \,\,\,\, x \ne 0, \,\,\,\, y \ne 0$ -- *ортогональны*, если $(x, y) = 0$.

::::

:::: {#statement-84}

**Утверждение:**  Пусть $V$ - унитарное пространство, $e_1, \ldots, e_k$ - ортогональные векторы. Тогда $e_1, \ldots, e_k$ - линейно независимы.

*Доказательство:*

$$\lambda_1 e_1 + \ldots + \lambda_n e_n = 0$$
$$(\lambda_1 e_1 + \ldots + \lambda_n e_n, e_1) = (0, e_1)$$
$$\Downarrow$$
$$\lambda_1 (e_1, e_1) + \ldots + \lambda_n(e_n, e_1) = 0$$
$$\Downarrow$$
$$\lambda_1 = 0 \,\,\,\,\blacksquare$$

::::

:::: {#definition-86}

**Определение:**  Базис унитарного пространства, состоящий из ортогональных векторов -- *ортогональный*.

::::

:::: {#definition-87}

**Определение:**  Ортогональный базис унитарного пространства, состоящий из единичных векторов -- *ортонормированный*.

::::

:::: {#definition-88}

**Определение:**  Квадратная матрица $A$ -- *унитарная*, если $A^T\overline{A} = E$.

::::

:::: {#statement-85}

**Утверждение:**  (*свойства ортонормированного базиса*)

1. $(x, y) = x_1 \overline{y}_1 + \ldots + x_n \overline{y}_n$.
2. $(x, e_i) = x_i$.
3. Матрица перехода от одного ортонормированного базиса к другому - унитарная.

*Доказательство:*

::::

:::: {#statement-86}

**Утверждение:**<a name="statement-1"></a> В конечномерном унитарном пространстве существует ортогональный базис.

*Доказательство:* процесс ортогонализации Грама-Шмидта для унитарного пространства.

::::

## Изоморфизм унитарных пространств


:::: {#definition-89}

**Определение:**  Унитарные пространства $U$ и $W$ *изоморфны*, если $\exists \varphi: U \to W$:

1. $\varphi$ - изоморфизм $U$ и $W$, как векторных пространств.
2. $(\varphi(x), \varphi(y)) = (x, y) \,\,\,\, \forall x, y \in U$.

::::

:::: {#statement-87}

**Утверждение:**  Пусть $U$ и $W$ унитарные пространства. Тогда $U$ изоморфно $W \,\,\,\, \Leftrightarrow \,\,\,\, \dim U = \dim W$.

*Доказательство:*

::::

:::: {#definition-90}

**Определение:**  Пусть $U$ подпространство унитарного пространства $V$. $U^{\perp} = \{x \in V: \,\,\,\, (x, u) = 0 \,\,\,\, \forall u \in U\}$ -- *ортогональное дополнение* $U$.

::::

:::: {#statement-88}

**Утверждение:**  Пусть $V$ унитарное пространство, $U$ -- его подпространство. Тогда $V = U \oplus U^{\perp}$.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

## Линейные операторы в унитарном пространстве


:::: {#statement-89}

**Утверждение:**  $\beta$ - полуторалинейная функция, $\mathcal{A}$ - линейный оператор. $\beta(x, y) = (x, \mathcal{A}(y))$ -- взаимнооднозначное соответствие между линейными операторами и полуторалинейными функциями.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

### Эрмитов линейный оператор


:::: {#definition-91}

**Определение:**  Линейный оператор $\mathcal{A}$ на унитарном пространстве -- *эрмитов*, если $\forall x, y \in V \,\,\,\, (\mathcal{A}(x), y) = (x, \mathcal{A}(y))$.

::::

:::: {#statement-90}

**Утверждение:**  Линейный оператор $\mathcal{A}$ - эрмитов $\Leftrightarrow$ матрица $A$ линейного оператора $\mathcal{A}$ в ортонормированном базисе эрмитова.

*Доказательство:* $(\mathcal{A}(x), y) = (AX)^T\bar{Y} = X^TA^T\bar{Y} = (x, \mathcal{A}(y)) = X^T\bar{A}\bar{Y} \,\,\,\,\blacksquare$

::::

:::: {#statement-91}

**Утверждение:**  Пусть $v$ собственный вектор эрмитова линейного оператора с собственным значением $\lambda$. Тогда $\lambda \in \mathbb{R}$.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

#### Канонический вид эрмитова линейного оператора

:::: {#statement-92}

**Утверждение:**  Пусть $V$ - конечномерное унитарное пространство, $\mathcal{A}$ - эрмитов оператор на $V$. Тогда существует ортонормированный базис, в котором матрица линейного оператора $\mathcal{A}$ диагональна с вещественными числами на диагонали.

*Доказательство:*

По индукции. $\,\,\,\,\blacksquare$

::::

### Унитарный линейный оператор


:::: {#definition-92}

**Определение:**  Линейный оператор $\mathcal{A}$ на унитарном пространстве -- *унитарный*, если $\forall x, y \in V \,\,\,\, (\mathcal{A}(x), \mathcal{A}(y)) = (x, y)$.

::::

:::: {#statement-93}

**Утверждение:**  Линейный оператор $\mathcal{A}$ - унитарный $\Leftrightarrow$ матрица $A$ линейного оператора $\mathcal{A}$ в ортонормированном базисе унитарная.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#statement-94}

**Утверждение:**  Пусть $v$ собственный вектор унитарного линейного оператора с собственным значением $\lambda$. Тогда $|\lambda| = 1$.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

#### Канонический вид унитарного линейного оператора

:::: {#statement-95}

**Утверждение:**  Пусть $V$ - конечномерное унитарное пространство, $\mathcal{A}$ - унитарный оператор на $V$. Тогда существует ортонормированный базис, в котором матрица линейного оператора $\mathcal{A}$ диагональна с числами на диагонали по модулю равными $1$.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#theorem-24}

**Теорема:**  Пусть $V$ - унитарное пространство. $\dim V = n$. $q$ - эрмитова квадратичная форма. Тогда существует ортонормированный базис, в котором $q(x) = \lambda_1 x_1 \overline{x}_1 + \ldots + \lambda_n x_n \overline{x}_n$.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#definition-93}

**Определение:**  Линейный оператор $\mathcal{A}$ на унитарном пространстве *положительно определен*, если он эрмитов и $(x, \mathcal{A}(x)) > 0 \,\,\,\, \forall x \in V$.

::::

:::: {#theorem-25}

**Теорема:**  (о полярном разложении) В конечномерном унитарном пространстве любой невырожденный линейный оператор $\mathcal{A}$ единственным образом представляется в виде композиции $\mathcal{A} = \mathcal{S} \mathcal{R}$, где $S$ - положительно определенный линейный оператор, а $\mathcal{R}$ - унитарный линейный оператор.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

## Получение унитарного пространства при комплексификации евклидова


:::: {#statement-96}

**Утверждение:**  Пусть $V$ - евклидово пространство. Тогда $(x + i y, a + i b) = (x, a) + (y, b) + i ((y, a) - (x, b))$ - эрмитова положительно определенная полуторалинейная функция.

*Доказательство:* $\,\,\,\,\blacksquare$

::::


# Аффинные пространства


:::: {#definition-94}

**Определение:**  Пусть $\mathbb{A}$ -- множество, элементы которого называются *точки*, $V$ - векторное пространство. Пара $(\mathbb{A}, V)$ (обозначается $\mathbb{A}$) -- *аффинное пространство*, если существует отображение $f: (a, b) \mapsto v = \overline{ab}$ из множества упорядоченных пар точек из $\mathbb{A}$ в множество векторов из $V$, такое, что:

1. $\forall v \in V, \,\,\,\,\forall a \in \mathbb{A} \,\,\,\, \exists ! b \in \mathbb{A}: \,\,\,\, \overline{ab} = v$. **Обозначение:** $b = a + v$.
2. $\forall a, b, c \in \mathbb{A} \,\,\,\, \overline{ab} + \overline{bc} = \overline{ac}$.

::::

## Простейшие свойства аффинных пространств


:::: {#statement-97}

**Утверждение:**  Пусть $\mathbb{A}$ - аффинное пространство. Тогда

1. $\forall a \in \mathbb{A} \,\,\,\, \overline{aa} = 0$
2. $\forall a, b \in \mathbb{A} \,\,\,\, \overline{ab} = -\overline{ba}$
3. $\forall a, b \in \mathbb{A} \,\,\,\, \overline{ab} = 0 \Leftrightarrow a = b$
4. $\forall a \in \mathbb{A}, v_1, v_2 \in V \,\,\,\, (a + v_1) + v_2 = a + (v_1 + v_2)$

*Доказательство:*

1. $\overline{aa} + \overline{aa} = \overline{aa} \,\,\,\,\blacksquare$
2. $\overline{ab} + \overline{ba} = \overline{aa} = 0 \,\,\,\,\blacksquare$
3. $\,\,\,\,\blacksquare$
4. $b = a + v_1, \,\,\,\, c = a + (v_1 + v_2)$
$$\overline{ab} = v_1, \,\,\,\, \overline{ac} = v_1 + v_2$$
$$\Downarrow$$
$$v_2 = \overline{bc} \,\,\,\,\blacksquare$$

::::

## Изоморфизм аффинных пространств


:::: {#definition-95}

**Определение:**  Пусть $(\mathbb{A}_1, V_1)$ и $(\mathbb{A}_2, V_2)$ - аффинные пространства, причем $V_1$ и $V_2$ - векторные пространства над одним и тем же полем $F$. $\Phi: \mathbb{A}_1 \to \mathbb{A}_2$ -- *аффинное отображение*, если существует линейное отображение $\varphi: V_1 \to V_2$:

$$\overline{\Phi(a)\Phi(b)} = \varphi(\overline{ab})$$

::::


:::: {#statement-98}

**Утверждение:**  $$\Phi(b) = \Phi(a) + \varphi(\overline{ab})$$

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#definition-96}

**Определение:**  Пусть $(\mathbb{A}_1, V_1)$ и $(\mathbb{A}_2, V_2)$ - аффинные пространства, причем $V_1$ и $V_2$ - векторные пространства над одним и тем же полем $F$. Аффинные пространства $\mathbb{A}_1$ и $\mathbb{A}_2$ -- *изоморфны*, если существует биективное аффинное отображение $\Phi: \mathbb{A}_1 \to \mathbb{A}_2$.

::::

:::: {#lemma-5}

**Лемма:**  Аффинное отображение $\Phi: \mathbb{A}_1 \to \mathbb{A}_2$ - изоморфизм $\mathbb{A}_1$ и $\mathbb{A}_2$ (биекция) $\Leftrightarrow \varphi: V_1 \to V_2$ изоморфизм $V_1$ и $V_2$.

*Доказательство:*

$$\Leftarrow$$
Рассмотрим отображение с дифференциалом $\varphi$.

::::

:::: {#statement-99}

**Утверждение:**  Пусть $\mathbb{A}_1$ и $\mathbb{A}_2$ конечномерные аффинные пространства. Тогда $\mathbb{A}_1 \cong \mathbb{A}_2 \Leftrightarrow \dim \mathbb{A}_1 = \dim \mathbb{A}_2$.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#definition-97}

**Определение:**  Пусть $(\mathbb{A}, V)$ - аффинное пространство. *Аффинная система координат* -- это пара $(O, e)$, где $O \in \mathbb{A}$(*начало координат*), $e$ - базис в $V$.<br> *Координаты точки* $a \in \mathbb{A}$ в системе координат $(O, e)$ -- это координаты вектора $\overline{Oa}$ в базисе $e$ю

::::

## Переход от одной системы координат к другой


это было так много раз, что я не буду писать

## Аффинные подпространства


:::: {#definition-98}

**Определение:**  Пусть $(\mathbb{A}, V)$ - аффинное пространство, $a \in \mathbb{A}$, $U$ - подпространство $V$. Множество $\pi = a + U = \{a + v| \,\,\,\, v \in U\}$ -- *плоскость*. $U$ -- *направляющее подпространство* плоскости $\pi$.

::::

:::: {#definition-99}

**Определение:**  (*размерность плоскости*) $\dim \pi = \dim U$. Нульмерная плоскость -- *точка*, одномерная плоскость -- *прямая*, $n - 1$ -- мерная плоскость -- *гиперплоскость*.

::::

:::: {#statement-100}

**Утверждение:**  Пусть $\pi = a + U$, $b \in \pi$. Тогда $\pi = b + U$.

*Доказательство:*

Докажем включение туда и обратно.

$b \in \pi \Rightarrow \exists v \in U: \,\,\,\, b = a + v$
$c = b + u = a + v + u \in \pi$
$a + u = b + (-v) + u \,\,\,\,\blacksquare$

::::

:::: {#definition-100}

**Определение:**  Пусть $(\mathbb{A}, V)$ - аффинное пространство. Непустое $B \subset \mathbb{A}$ -- *аффинное подпространство*, если $\{\overline{pq}\,\,\,\, p, q \in B$ - подпространство $V$.

::::

:::: {#statement-101}

**Утверждение:**  Аффинное подпространство -- это аффинное пространство.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#statement-102}

**Утверждение:**  Аффинное подпространство -- это плоскость.

*Доказательство:* $\,\,\,\,\blacksquare$

::::


# Свойства плоскостей


:::: {#statement-103}

**Утверждение:**  Пусть $\mathbb{A}$ - аффинное пространство, $\pi = a + U$ и $\tau = b + W$ - плоскости. Тогда $\pi \cap \tau = \varnothing$ или $\pi \cap \tau = c + U \cap W$, где $c \in \pi \cap \tau$.

*Доказательство:*

Пусть $\pi \cap \tau \ne \varnothing \Rightarrow \exists c \in \pi \cap \tau \Rightarrow$

$\pi = c + U$ и $\tau = c + W \Rightarrow$

$\forall d \in \tau \cap \pi \,\,\,\, d = c + u = c + w \Rightarrow u = w \Rightarrow \pi \cap \tau = c + U \cap W$.

::::

:::: {#definition-101}

**Определение:**  *Аффинная оболочка* точек аффинного пространства -- это плоскость наименьшей размерности, содержащая эти точки. Обозначается: $<...>_A$.

::::

:::: {#statement-104}

**Утверждение:**  Пусть $\mathbb{A}$ - аффинное пространство, $\pi = a + U$ и $\tau = b + W$ - плоскости. Тогда аффинная оболочка $\langle \pi, \tau\rangle_A = a + \langle\overline{ab}, U + W\rangle$. 

*Доказательство:* туда обратно $\,\,\,\,\blacksquare$

::::

:::: {#theorem-26}

**Теорема:**  Пусть $\mathbb{A}$ - аффинное пространство, $\dim \mathbb{A} = n$, $\pi = a + U$ и $\tau = b + W$ - плоскости.

1. Если $\pi \cap \tau = \varnothing$, то $\dim \langle\pi, \tau\rangle = \dim \pi + \dim \tau - \dim U \cap W$
2. Если $\pi \cap \tau \ne \varnothing$, то $\dim \langle\pi, \tau\rangle = \dim \pi + \dim \tau - \dim U \cap W + 1$.

*Доказательство:*

Пусть $\overline{ab} \in U + W$. По формуле Грассмана имеем $\dim\langle\pi, \tau\rangle_A = \dim(U + W) = \dim U + \dim W - \dim(U \cap W)$.
Иначе, $\dim \langle\pi, \tau\rangle_A = \dim (U + W) + 1$ и далее опять по формуле Грассмана $\,\,\,\,\blacksquare$

::::

:::: {#definition-102}

**Определение:**  Пусть $\mathbb{A}$ - аффинное пространство, $\dim \mathbb{A} = n$, $\pi = a + U$ и $\tau = b + W$ - плоскости. $\pi$ *параллельна* $\tau$ ($\pi \parallel \tau$), если $U \subset W$ или $W \subset U$.

::::

:::: {#statement-105}

**Утверждение:**  Пусть $\mathbb{A}$ - аффинное пространство, $\dim \mathbb{A} = n$, $\pi = a + U$ и $\tau = b + W$ - плоскости, $\pi \parallel \tau$. Тогда $\pi \cap \tau = \varnothing$, или $\tau \subset \pi$, или $\pi \subset \tau$.

*Доказательство:* см. здесь $\,\,\,\,\blacksquare$

::::

:::: {#definition-103}

**Определение:**  Пусть $\mathbb{A}$ - аффинное пространство, $\dim \mathbb{A} = n$, $\pi = a + U$ и $\tau = b + W$ - плоскости. $\pi$ и $\tau$ *скрещиваются*, если $\pi \cap \tau \ne \varnothing$ и $\pi \nparallel \tau$.

::::

:::: {#statement-106}

**Утверждение:**  Пусть $\mathbb{A}$ - аффинное пространство, $\pi$ и $\tau$ - гиперплоскости. Если $\pi \cap \tau = \varnothing$, то $\pi \parallel \tau$.

*Доказательство:*

::::

## Аффинные линейные функции


:::: {#definition-104}

**Определение:**  $f: \mathbb{A} \to F$ -- *аффинная линейная функция*, если существует линейная функция $\varphi$ на V, такая, что $\forall a, b \in \mathbb{A} \,\,\,\, \overline{f(a)f(b)} = \varphi(\overline{ab})$. $F$ рассматривается как одномерное векторное пространство (базис в $F$ - $1$).

::::

### Координатная запись аффинных линейных функций


Пусть $(O, e)$ - аффинная система координат, $f$ - аффинная линейная функция, $e = \{e_1, \ldots, e_n\}$. $\forall a \in \mathbb{A} \,\,\,\, a = O + \overline{Oa}$. Пусть $x_1, \ldots, x_n$ координаты точки $a$ в $(O, e)$. $f(a) = f(O) + \varphi(\overline{Oe}) = \alpha + \varphi(x_1 e_1 +\ldots + x_n e_n) = \alpha + \alpha_1 x_1 + \ldots + \alpha_n x_n$.

:::: {#definition-105}

**Определение:**  Пусть $f$ - аффинная линейная функция. *Ядро* $f$ -- это $\ker f = \{a \in \mathbb{A}: \,\,\,\, f(a) = 0\}$.

::::

:::: {#statement-107}

**Утверждение:**  Пусть $f$ - аффинная линейная функция. Тогда

1. $\ker f$ - аффинное подпространство или $\ker f = \varnothing$.
2. Если $\ker f \ne \varnothing$, то $ker f = c + \ker \varphi$, где $f(c) = 0$ и $\varphi$ - линейная часть аффинной функции $f$.

*Доказательство:*

1-2. Пусть $\ker f \ne \varnothing \Rightarrow \exists a \in \mathbb{A}: \,\,\,\, f(a) = 0$. $f(a + v) = f(a) + \varphi(v) \Rightarrow \forall v \in \ker \varphi \,\,\,\, f(a + v) = 0 \,\,\,\,\blacksquare$

::::

# Плоскость в аффинном пространстве, как множество решений совместной системы линейных уравнений

:::: {#statement-108}

**Утверждение:**  $\mathbb{A}$ - аффинное пространство, $\dim \mathbb{A} = n$.

1. Пусть дана совместная система линейных уравнений $(*)$ с матрицей коэффицентов $A$. Тогда множество ее решений совпадает с координатами точек некоторой плоскости $\pi \subset \mathbb{A}$ размерности $n - \operatorname{rk} A$.

2. Пусть дана плоскость $\pi \subset \mathbb{A}$. Тогда существует совместная система линейных уравнений, такая, что множество ее решений совпадает с координатами точек $\pi$.

*Доказательство:* ну, просто порассуждать $\,\,\,\,\blacksquare$

::::

## Аффинные отображения


<details>
<summary>Хм</summary>
Кажется, что это уже было
</details>

Пусть $(\mathbb{A}, U)$ и $(\mathbb{B}, W)$ - аффинные пространства.

:::: {#definition-106}

**Определение:**  $f: \mathbb{A} \to \mathbb{B}$ -- *аффинное отображение*, если существует линейное отображение $\varphi: U \to W$, такое, что $\overline{f(x)f(y)} = \varphi(\overline{xy})$, при этом $\varphi$ -- *линейная часть* (*дифференциал*) аффинного отображения $f$.

::::

:::: {#statement-109}

**Утверждение:**  Композиция аффинных отображений -- аффинное отображение, линейная часть которого является композицией линейных частей исходных отображений.

*Доказательство:*

::::

:::: {#statement-110}

**Утверждение:**  Аффинное отображение $\Phi$ -- биекция $\Leftrightarrow$ дифференциал $\Phi$ является биекцией соответствующих векторных пространств.

*Доказательство:* было $\,\,\,\,\blacksquare$

::::

## Какая-то муть про матрицы


## Аффинные операторы


:::: {#definition-107}

**Определение:**  *Аффинный оператор* -- это аффинное отображение аффинного пространства $\mathbb{A}$ в себя.

::::

:::: {#definition-108}

**Определение:**  Пусть $\Phi$ - аффинное отображение. *Ранг* $\Phi (\operatorname{rk}\Phi)$ -- это ранг матрицы линейной части $\Phi$.

::::

:::: {#definition-109}

**Определение:**  Аффинный оператор $\Phi$ *невырожден*, если $\operatorname{rk}\Phi = \operatorname{rk}\mathbb{A}$.

::::

:::: {#statement-111}

**Утверждение:**  Множество всех невырожденных операторов аффинного пространства $\mathbb{A}$ образует группу относительно композиции.

*Доказательство:*

::::

:::: {#definition-110}

**Определение:**  Эта группа обозначается $\operatorname{Aff}(\mathbb{A})$.

::::

:::: {#definition-111}

**Определение:**  Пусть $(\mathbb{A}, V)$ - аффинное пространство. *Сдвиг на вектор* $v \in V$ -- это отображение $f_v: \mathbb{A} \to \mathbb{A} \,\,\,\, f_v: a \mapsto a + v$.

::::

:::: {#statement-112}

**Утверждение:**  

1. Сдвиг на вектор -- это аффинный оператор с тождественной линейной частью.
2. Любой аффинный оператор с тождественной линейной частью является сдвигом на вектор.

*Доказательство:*

1. $f_v(a) = a + v \,\,\,\,\blacksquare$
2. Пусть $v = \overline{a\Phi(a)} \Rightarrow a + v = \Phi(a)$. Тогда $\forall b \in \mathbb{A} \,\,\,\, \Phi(b) = \Phi(a) + \overline{ab} = a + v + \overline{ab} = b + v \,\,\,\,\blacksquare$

::::

:::: {#definition-112}

**Определение:**  Множество всех сдвигов на вектор обозначается $\operatorname{tran}\mathbb{A}$.

::::

:::: {#statement-113}

**Утверждение:**  $\operatorname{tran}\mathbb{A}$ подгруппа в группе $\operatorname{Aff}(\mathbb{A})$.

*Доказательство:*

::::

:::: {#definition-113}

**Определение:**  Пусть $a$ точка аффинного пространства $\mathbb{A}$. Множество всех невырожденных аффинных операторов $\Phi$, таких, что $\Phi(a) = a$ обозначается $G_a$. 

::::

:::: {#statement-114}

**Утверждение:** (представление аффинного преобразование в виде композиции поворота и движения) Пусть $(\mathbb{A}, V)$ - аффинное пространство. $a \in \mathbb{A}$. $\Phi$ - аффинное отображение. Тогда $\exists ! \Psi_a \in G_a, t_v \in \operatorname{tran}\mathbb{A}, t_w  \in \operatorname{tran}\mathbb{A}: \,\,\,\, \Phi = t_v \circ \Psi_a = \Psi_a \circ t_w$.

*Доказательство:*

Пусть $v = \overline{a\Phi(a)} \Rightarrow \Phi(a) = a + v$. Пусть $\Psi = (t_{v})^{-1}\circ\Phi = t_{-v}\circ\Phi$(почему?)

Докажем, что $\Psi \in G_a \,\,\,\, \Psi(a) = t_{-v}(\Phi(a)) = \Phi(a) - v = a$.

Имеем $\Phi = t_v\circ \Psi$

$\Phi = \Psi \circ \Psi^{-1} \circ t_v \circ \Psi$.

Докажем, что $t_w = \Psi^{-1} \circ t_v \circ \Psi$ -- сдвиг на вектор. Дифференциал $t_w$ равен композиции дифференциалов $\varphi^{-1}\varphi$, то есть тождественной линейной функции $\,\,\,\,\blacksquare$

::::

## Аффинно независимая система точек


:::: {#definition-114}

**Определение:**  Система точек $a_0, a_1, \ldots, a_s$ *аффинно независима*, если $\dim \langle a_0, a_1, \ldots, a_s\rangle_A = s$ (точек $s + 1$ штука).

::::

:::: {#statement-115}

**Утверждение:**  Система точек $a_0, a_1, \ldots, a_s$ аффинно независима $\Leftrightarrow$ векторы $a_1 - a_0, \ldots, a_s - a_0$ линейно независимы.

*Доказательство:*

$$\Leftarrow$$
$\langle a_0, a_1, \ldots, a_s\rangle_A = a_0 + \langle a_1 - a_0, \ldots, a_s - a_0\rangle \Rightarrow \dim \langle a_0, a_1, \ldots, a_s\rangle_A = s \,\,\,\,\blacksquare$

$$\Rightarrow$$
$\,\,\,\,\blacksquare$

::::

:::: {#statement-116}

**Утверждение:**  Пусть $(O, e)$ - аффинная система координат. Тогда точки $a_0, a_1, \ldots, a_s$ с координатами $(x_1^0, \ldots, x_n^0), (x_1^1, \ldots, x_n^1), \ldots, (x_1^s, \ldots, x_n^s)$ в $(O, e)$ аффинно независимы $\Leftrightarrow$ $\operatorname{rk}\left(\begin{array}{ccc}x_1^0 & \ldots & x_n^0\\x_1^1 & \ldots & x_n^1\\ & \vdots & \\x_1^s & \ldots & x_n^s\end{array}\right) = s$.

*Доказательство:* 

$\operatorname{rk}\left(\begin{array}{ccc}x_1^0 & \ldots & x_n^0\\x_1^1 & \ldots & x_n^1\\ & \vdots & \\x_1^s & \ldots & x_n^s\end{array}\right)$ -- это количество линейно независимых векторов среди $\overline{Oa_0}, \ldots, \overline{Oa_s}$. $a_1 - a_0 = Oa_1 - Oa_0 \,\,\,\,\blacksquare$

::::

:::: {#statement-117}

**Утверждение:**  Пусть $a_0, \ldots, a_n$ аффинно независимая система точек, $b_0, \ldots, b_n \in \mathbb{A}$. Тогда $\exists !$ аффинный оператор $\Phi: \mathbb{A} \to \mathbb{A}: \,\,\,\, \Phi(a_i) = b_i \,\,\,\, \forall i \in \{1, \ldots, n\}$, причем, если $b_i$ аффинно независимы, $\Phi$ невырожден.

*Доказательство:* Существует единственный линейный оператор, переводящий базисные векторы $a_1 - a_0, \ldots, a_n - a_0$ в векторы $b_1 - b_0, \ldots, b_n - b_0 \,\,\,\,\blacksquare$

::::


# Аффинно-евклидовы пространства


:::: {#definition-115}

**Определение:**  Аффинное пространство $\mathbb{A}$ над евклидовым пространстом $V$ -- *аффинно-евклидово*.

::::

:::: {#definition-116}

**Определение:**  $\mathbb{A}$ - аффинно-евклидово пространство. $a, b \in \mathbb{A}$. *Расстояние* от $a$ до $b$ -- это $\rho(a, b) = |\overline{ab}|$.

::::

:::: {#definition-117}

**Определение:**  Пусть $(\mathbb{A}, U)$ и $(\mathbb{B}, W)$ аффинно-евклидовы пространства. $\mathbb{A}$ *изоморфно* $\mathbb{B}$, если существует биективное аффинное отображение $\Phi: \mathbb{A} \to \mathbb{B}: \,\,\,\, \forall a, b \in \mathbb{A} \,\,\,\, \rho_{\mathbb{A}}(a, b) = \rho_{\mathbb{B}}(\Phi(a), \Phi(b))$.

::::

:::: {#statement-118}

**Утверждение:**  Аффинно-евклидовы пространства изоморфно $\Leftrightarrow$ их размерности совпадают. (для конечномерных пространств)

*Доказательство:*

::::

:::: {#definition-118}

**Определение:**  Пусть $\mathbb{A}$ аффинно-евклидово пространство. $\pi$ и $\tau$ - плоскости. *Расстояние между плоскостями* $\pi$ и $\tau$ -- это $\rho(\pi, \tau) = \inf\{\rho(a, b): \,\,\,\, a \in \pi, \,\,\,\, b \in \tau\}$.

::::

:::: {#statement-119}

**Утверждение:**  Пусть $\mathbb{A}$ аффинно-евклидово пространство. $\pi = a_0 + U$ и $\tau = b_0 + W$ - плоскости. Тогда 
$$\rho(\pi, \tau) = \operatorname{pr}_{U + W}\overline{a_0b_0}$$

*Доказательство:*

$$\overline{a_0b_0} = \operatorname{pr}_{U + W}\overline{a_0b_0} + \operatorname{ort}_{U + W}\overline{a_0b_0}$$
$$a = a_0 + u, \,\,\,\, u \in U$$
$$b = b_0 + w, \,\,\,\, w \in W$$
$$\rho(a, b) = |\overline{a_0b_0} + w - u|^2$$
$$= |\operatorname{pr}_{U + W}\overline{a_0b_0} + w - u + \operatorname{ort}_{U + W}\overline{a_0b_0}|^2 =$$
По теореме Пифагора ($w - u + \operatorname{ort}_{U + W}\overline{a_0b_0} \in U + W, \,\,\,\, \operatorname{pr}_{U + W}\overline{a_0b_0} \in (U + W)^{\perp}$)
$$= |\operatorname{pr}_{U + W}\overline{a_0b_0}|^2 + |w - u + \operatorname{ort}_{U + W}\overline{a_0b_0}|^2 \ge |\operatorname{pr}_{U + W}\overline{a_0b_0}|^2 \,\,\,\,\blacksquare$$

::::

:::: {#definition-119}

**Определение:**  Пусть $\mathbb{A}$ аффинно-евклидово пространство. $\pi = a_0 + U$ и $\tau = b_0 + W$ - плоскости. Тогда $\tau \perp \pi$ ($\tau$ *ортогональна* $\pi$), если угол между $U$ и $W$ равен $\frac{\pi}{2}$.

::::

# Движения


:::: {#definition-120}

**Определение:**  Пусть $\mathbb{A}$ аффинное пространство. Отображение $f: \mathbb{A} \to \mathbb{A}$ -- *движение*, если $\rho(a, b) = \rho(f(a), f(b)), \,\,\,\, \forall a, b \in \mathbb{A}$.

::::

:::: {#definition-121}

**Определение:**  Аффинный оператор $\Phi$ *ортогональный*, если его дифференциал - ортогональный линейный оператор.

::::

:::: {#statement-120}

**Утверждение:**  Сдвиг на вектор -- это движение и аффинный ортогональный оператор.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#statement-121}

**Утверждение:**  Композиция движений -- это движение.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#theorem-27}

**Теорема:**  Движение -- это ортогональный аффинный оператор.

*Доказательство:*

$$\Leftarrow$$
Пусть $\Phi$ -- ортогональный аффинный оператор. $\rho(\Phi(a), \Phi(b)) = |\overline{\Phi(a)\Phi(b)}| = |\varphi(\overline{ab})| =$ ($\varphi$ -- ортогональный линейный оператор, а значит сохраняет длину вектора) $= |\overline{ab}| = \rho(a, b) \,\,\,\,\blacksquare$

$$\Rightarrow$$
Пусть $\Phi$ -- движение, то есть $\rho(\Phi(a), \Phi(b)) = \rho(a, b)$. Пусть $s \in \mathbb{A}$, $u = \overline{s\Phi(s)}$, $\Psi = \left(t_u\right)^{-1}\Phi$.

Докажем, что $\Psi$ -- ортогональный аффинный оператор. 

Пусть $\psi: v \in V \mapsto \overline{s\Psi(s + v)} \in V$.
$\Psi(s) = t_{-u}(\Phi(s)) = \Phi(s) - u = s$
Докажем, что $\psi$ -- ортогональный линейный оператор.
$|\psi(v)| = |\overline{s\Psi(s + v)}| = \rho(s, \Psi(s + v)) = \rho(\Psi(s), \Psi(s + v)) = \rho(s, s + v) = |v|$

<details>
<summary>Кому-то было плохо (по предыдущей теореме :)</summary>

Пусть $f$ движение, по предыдущей теореме $f$ -- ортогональный аффинный оператор. Пусть дифференициал $f$ -- это $\varphi$(ортогональный линейный оператор). Выберем аффинную систему координат $(O, e)$, где $e$ -- ортонормированный базис. Тогда матрица $A$ оператора $\varphi$ -- ортогональна. $\forall a \in \mathbb{A} \,\,\,\, f(a) = f(O) + \varphi(\overline{Oa})$. Пусть $X_0$ -- столбец координат $f(O)$ в $(O, e)$, $X$ -- столбец координат $f(a)$, $X_{\overline{Oa}}$ -- столбец координат вектора $\overline{Oa}$ в $e$. Тогда $X = X_0 + A X_{\overline{Oa}}$.

</details>

::::

:::: {#definition-122}

**Определение:**  

Если $\det A = 1$, то движение *собственное*.

Если $\det A = -1$, то движение *несобственное*.

Если $f(O) = O$, то движение -- *поворот*.

::::

### Основная теорема о движении


:::: {#theorem-28}

**Теорема:**  Пусть $\mathbb{A}$ аффинно-евклидово пространство над $V$. Пусть $\Phi$ - движение с дифференциалом $\varphi$. Тогда $\exists u \in V: \,\,\,\, \varphi(u) = u$ и $\exists \Psi$ - движение с неподвижной точкой, такое, что $\Phi = t_u \circ \Psi$ ($t_u$ - сдвиг на вектор).

*Доказательство:*

Если у $\varphi$ существует собственное значение $1$, то берем вектор $u$ с таким собственным значением, иначе $u = 0$. Пусть $\Psi = (t_u)^{-1}\circ \Phi \,\,\,\,\blacksquare$

::::

# Аффинно-квадратичные функции

:::: {#definition-123}

**Определение:**  Пусть $(\mathbb{A}, V)$ - аффинное пространство, $V$ - векторное пространство над полем $F$. Отображение $L: \mathbb{A} \to F$ -- *аффинно-линейное*, если существует линейная функция $l: V \to F$, такая, что $L(a) = L(b) + l(\overline{ba})\,\,\,\, \forall a, b \in \mathbb{A}$.

::::

:::: {#definition-124}

**Определение:**  Отображение $Q: \mathbb{A} \to F$ -- *аффинно-квадратичная функция*, если существует линейная функция $l: V \to F$ и квадратичная форма $q: V \to F$, такие, что $\forall a, b \in \mathbb{A} \,\,\,\, Q(b) = Q(a) + q(\overline{ab}) + 2l(\overline{ab})$.

::::


### Координатная запись аффинно-квадратичной функции


Пусть $(O, e)$ - аффинная система координат. $Q$ - аффинно-квадратичная функция.

$$\forall a \in \mathbb{A} \,\,\,\, Q(a) = Q(O) + q(\overline{Oa}) + 2 l(\overline{Oa})$$
$$Q(a) = Q(O) + \displaystyle \sum_{i, j = 1}^{n}b_{ij}x_ix_j + 2 \displaystyle \sum_{i = 1}^{n}s_i x_i$$
$$Q(a) = Q(O) + X^T B X + 2 X^T S$$
$$Q(a) = Q(O) + X^T B X + X^T S + S^T X$$

$S$ -- столбец коэффицентов линейной части $Q$.

:::: {#definition-125}

**Определение:**  $\tilde{B} = \left(\begin{array}{c|c} B & S \\\hline S^T & Q(O)\end{array}\right)$ -- *матрица аффинно-квадратичной функции* $Q$ в базисе $(O, e)$.

$$\tilde{X} = \left(\begin{array}{c}X\\\hline 1\end{array}\right)$$

::::

:::: {#statement-122}

**Утверждение:**  $$Q(a) = \tilde{X}^T\tilde{B}\tilde{X}$$

Пусть $(O’, e’)$ - аффинная система координат. Матрица перехода от $e$ к $e’$ - $C_{e \to e’}$.

*Доказательство:*

::::

:::: {#definition-126}

**Определение:**  $\tilde{C} = \left(\begin{array}{ccc|c} & & & v_1\\ & C_{e \to e’} & & \vdots\\& & & v_n \\\hline 0 & \dots & 0 & 1\end{array}\right)$ -- *матрица перехода от аффинной системы координат* $(O, e)$ *к аффинной системе координат* $(O’, e’)$, $w_1, \ldots, w_n$ координаты $\overline{OO’}$ в базисе $e$.

::::

#### Изменение матрицы аффинно-квадратичной функции при переходе от одной аффинной системы координат к другой

:::: {#statement-123}

**Утверждение:**

$$B’ = C_{e \to e’}^T B C_{e \to e’}$$
$$S’ = C_{e \to e’}^T(B W + S)$$
$W$ -- столбец координат вектора $\overline{OO’}$ (догадайтесь в каком базисе)
$S$ -- столбец $l(e_i)$, где $e_i$ -- базисный вектор.
$$Q(O’) = W^T B W + S^T W + W^T S + Q(O)$$

*Доказательство:*

::::

### Центр аффинно-квадратичной функции


:::: {#definition-127}

**Определение:**  Пусть $W$ -- столбец координат вектора $\overline{OO’}$, таков, что $B W + S = 0$. Тогда $S’ = 0$ и $Q(O’ + v) = q(v) + Q(O’) = Q(O’ - v) \,\,\,\, \forall v \in V$. Точка $O’$ -- *центр аффинно-квадратичной функции* $Q$.

::::

:::: {#statement-124}

**Утверждение:** Множество центров аффинно-квадратичной функции либо $\varnothing$, либо плоскость. 

*Доказательство:*

Если система $BW + S = 0$ разрешима относительно $W$(столбец координат вектора $\overline{OO’}$), то по утверждению получаем плоскость, иначе пустое множество $\,\,\,\,\blacksquare$

::::

:::: {#definition-128}

**Определение:**  Аффинно-квадратичная функция $Q$ *невырождена*, если существует аффинная система координат $(O, e)$, в которой матрица $\tilde{B}$ невырождена.

::::

#### Инварианты аффинно-квадратичной функции


:::: {#statement-125}

**Утверждение:**  Пусть $Q: \mathbb{A} \to F$ - аффинно-квадратичная функция, $\tilde{B}$ - матрица $Q$, $B$ - матрица $q$. Тогда следующие величины инварианты $Q$, то есть не зависят от системы координат:

1. $\operatorname{rk} B$
2. $\operatorname{rk} \tilde{B}$
3. Если $F = \mathbb{R}$, то положительный и отрицательный индексы инерции $q$.

*Доказательство:* Следует из соответствующих теорем :) $\,\,\,\,\blacksquare$

::::

### Канонический вид аффинно-квадратичной функции


:::: {#theorem-29}

**Теорема:**  Пусть $Q: \mathbb{A} \to F$ - аффинно-квадратичная функция, не являющаяся аффинно-линейной. Тогда существует аффинная система координат, в которой $Q$ имеет вид:

$$Q(a) = \lambda_1 x^2_1 + \ldots + \lambda_r x^2_r + \lambda_{r + 1}$$

или

$$Q(a) = \lambda_1 x^2_1 + \ldots + \lambda_r x^2_r + 2 x_{r + 1}$$

$\lambda_1, \ldots, \lambda_r$ не равны $0$.

*Доказательство:* Приведем $q$ к диагональному виду, и по-заменяем $\,\,\,\,\blacksquare$

::::

# Аффинно-квадратичные функции в аффинно-евклидовых пространствах


:::: {#definition-129}

**Определение:**  Пусть $\mathbb{A}$ - аффинно-евклидово пространство. Аффинная система координат $(O, e)$ *прямоугольная*, если базис $e$ - ортонормирован.

::::

:::: {#definition-130}

**Определение:**  Пусть $\mathbb{A}$ - аффинно-евклидово пространство. $Q$ - аффинно-квадратичная функция, $q$ - квадратичная форма функции $Q$. Если матрица $B$ формы $q$ -- диагональна в прямоугольной системе координат  $(O, e)$, то $(O, e)$ -- *главные оси*.

::::

:::: {#theorem-30}

**Теорема:**  Пусть $\mathbb{A}$ - аффинно-евклидово пространство. $Q: \mathbb{A} \to \mathbb{R}$ - аффинно-квадратичная функция, которая не является аффинно-линейной. Тогда существует прямоугольная система координат, в которой $Q$ имеет вид (такой вид единственен с точностью до перенумерации координат):

$$Q(a) = \lambda_1 x^2_1 + \ldots + \lambda_r x^2_r + \lambda$$

или

$$Q(a) = \lambda_1 x^2_1 + \ldots + \lambda_r x^2_r + 2 \lambda_{r + 1} x_{r + 1}$$

$\lambda_1, \ldots, \lambda_r$ не равны $0$, $\lambda_{r + 1} > 0$.

*Доказательство:* Неприятно и долго $\,\,\,\,\blacksquare$

::::

## Квадрики

:::: {#definition-131}

**Определение:**  Пусть $\mathbb{A}$ - аффинное пространство ассоциированное с векторным пространством $V$ над полем $F$ и $\operatorname{char}F \ne 2$, $Q$ - аффинно-квадратичная функция. Множество $\Gamma(Q) = \{a \in \mathbb{A}: \,\,\,\, Q(a) = 0\}$, если оно не пустое и не является плоскостью -- *квадрика* или *гиперповерхность второго порядка*.

::::

:::: {#statement-126}

**Утверждение:**  Любая прямая либо целиком лежит в квадрике, либо пересекается с ней не более, чем в двух точках.

*Доказательство:* 

Прямая -- это плоскость размерности $1$, то есть $p = a_0 + <v>, \,\,\,\, v \in V$. Произвольная точка на прямой -- это $a = a_0 + t v$.

$$0 = Q(a) = Q(a_0 + t v) = Q(a_0) + q(tv) + 2l(tv) = t^2 q(v) + 2 t l(v) + Q(a_0) \,\,\,\,\blacksquare$$

::::

:::: {#definition-132}

**Определение:**   Точка $O$ *центр* квадрики $\Gamma(Q)$, если $\forall v: \,\,\,\, O + v \in \Gamma(Q) \,\,\,\, O - v \in \Gamma(Q)$.

::::

:::: {#definition-133}

**Определение:**  Пусть $O$ центр квадрики $\Gamma(Q)$. Если $O \in \Gamma(Q)$, то $O$ -- *вершина* $\Gamma(Q)$.

::::

:::: {#statement-127}

**Утверждение:**  Пусть $\Gamma(Q)$ квадрика, $O$ -- ее вершина, $a \in \Gamma(Q), \,\,\,\, a \ne O$. Тогда прямая $l = O + <\overline{Oa}> \subset \Gamma(Q)$(прямая, проходящая через $O$ и $a$ лежит в квадрике).

*Доказательство:*

$O$ -- вершина, следовательно $O -\overline{Oa} \in Q$. Значит минимум три точки прямой лежат на квадрике, следовательно по предыдущему утверждению $l \subset \Gamma(Q) \,\,\,\,\blacksquare$

::::

:::: {#statement-128}

**Утверждение:**  Любая квадрика содержит точку, не являющуюся ее вершиной.

*Доказательство:*

Пусть это неправда. Докажем, что $\Gamma(Q)$ в таком случае будет плоскостью. Пусть $a \in \Gamma(Q), \,\,\,\, U = <\overline{ab}: \,\,\,\, b \in \Gamma(Q)>$.

Докажем, что $U$ -- векторное подпространство $V$. $\forall u_1, u_2 \in U \,\,\,\, \exists b_1, b_2 \in \Gamma(Q): \,\,\,\, u_1 = \overline{ab_1}$ и $u_2 = \overline{ab_2}$. Так как любая точка -- вершина $b_1 + <\overline{b_1b_2}> \subset \Gamma(Q) \Rightarrow c = b_1 + \lambda \overline{b_1b_2} \in \Gamma(Q) \Rightarrow \overline{ac} = \overline{ab_1} + \lambda \overline{b_1b_2} \in \Gamma(Q) \Rightarrow$
$\Rightarrow u_1 + \lambda(u_2 - u_1) \in \Gamma(Q) \,\,\,\,\blacksquare$

::::

## Пропорциональные аффинно-квадратичные функции и квадрики


:::: {#theorem-31}

**Теорема:**  Пусть $\Gamma = \Gamma(Q_1) = \Gamma(Q_2)$, $\Gamma$ - квадрика, $Q_1, Q_2$ - аффинно-квадратичные функции на аффинном пространстве над бесконечным полем характеристики отличной от $2$. Тогда $Q_1$ пропорциональна $Q_2$.

*Доказательство:*

фуу

::::

:::: {#definition-134}

**Определение:**  Квадрики $\Gamma_1$ и $\Gamma_2$ *аффинно-эквивалентны* ($\operatorname{GA}$-*эквивалентны*), если существует аффинный оператор $\Phi$, такой, что $\Phi(\Gamma_1) = \Gamma_2$.

::::

:::: {#theorem-32}

**Теорема:**  Пусть $Q_1, Q_2$ - аффинно-квадратичные функции на аффинном пространстве над бесконечным полем характеристики отличной от $2$. $Q_1$ и $Q_2$ задают аффинно-эквивалентные квадрики $\Leftrightarrow$ $Q_1$ пропорциональна $Q_2$ в некоторых системах координат.

*Доказательство:* 

::::

:::: {#definition-135}

**Определение:**  Квадрики $\Gamma_1$ и $\Gamma_2$ *изометрически эквивалентны* ($\operatorname{Isom}$-*эквивалентны*), если существует ортогональный аффинный оператор $\Phi$, такой, что $\Phi(\Gamma_1) = \Gamma_2$.

::::

:::: {#theorem-33}

**Теорема:**  Пусть $Q_1, Q_2$ - аффинно-квадратичные функции на аффинном пространстве над бесконечным полем характеристики отличной от $2$. $Q_1$ и $Q_2$ задают изометрически эквивалентные квадрики $\Leftrightarrow$ $Q_1$ пропорциональна $Q_2$ в некоторых прямоугольных системах координат.

*Доказательство:*

::::



# Тензоры


:::: {#definition-136}

**Определение:**  Функция от нескольких переменных *полилинейная*, если она линейна по каждому аргументу при фиксированном значении остальных.

::::

:::: {#definition-137}

**Определение:**  Пусть $V$ - векторное пространство, $V^{*}$ - сопряженное к $V$ пространство. Полилинейная функция $$f: \underbrace{V\times \ldots \times V}_p \times \underbrace{V^{*}\times \ldots \times V^{*}}_q \to F$$ -- *тензор на* $V$ *типа* $(p, q)$ *валентности* $p + q$.

::::

:::: {#definition-138}

**Определение:**  Множество всех тензоров типа $(p, q)$ обозначается $\mathbb{T}^q_p$.

::::

## Координаты тензора


Пусть $V$ - векторное пространство, $V^{*}$ - сопряженное к $V$ пространство. $t: \underbrace{V\times \ldots \times V}_p \times \underbrace{V^{*}\times \ldots \times V^{*}}_q \to F$ - тензор на $V$.

Выберем в $V$ базис $e = \{e_1, \ldots, e_n\}$.

Возьмем в $V^{*}$ сопряженный к $e$ базис $\{\varepsilon^1, \ldots, \varepsilon^n\}$.

$\forall v \in V \,\,\,\, v = \displaystyle \sum_{i = 1}^{n}v^i e_i$.

$\forall f \in V^{*} \,\,\,\, f = \displaystyle \sum_{i = 1}^{n}f_i \varepsilon^i$.

Да, координаты векторов (ковекторов) обозначаются верхними (нижними) индексами, а базисные векторы $V$ обозначаются нижними индексами, $V^{*}$ -- верхними.

Тогда $$t(\underbrace{u, \ldots, w}_p, \underbrace{\xi, \ldots, \zeta}_q) = t(\displaystyle \sum_{i = 1}^{n}u^i e_i, \ldots, \displaystyle \sum_{i = 1}^{n}w^i e_i, \displaystyle \sum_{i = 1}^{n}\xi_i \varepsilon^i, \ldots, \displaystyle \sum_{i = 1}^{n}\zeta_i \varepsilon^i)=$$
$$= \displaystyle \sum_{i, \ldots, j, k, \ldots, l = 1}^{n} u^i \cdot \ldots \cdot w^j \cdot \xi_k \cdot \ldots \cdot \zeta_l \cdot t(e_i, \ldots, e_j, \varepsilon^k, \ldots, \varepsilon^l) =$$
$$= \displaystyle \sum_{i, \ldots, j, k, \ldots, l = 1}^{n} u^i \cdot \ldots \cdot w^j \cdot \xi_k \cdot \ldots \cdot \zeta_l \cdot t^{k \ldots l}_{i \ldots j}$$ 

:::: {#definition-139}

**Определение:**  Числа $t^{k \ldots l}_{i \ldots j} = t(e_i, \ldots, e_j, \varepsilon^k, \ldots, \varepsilon^l)$ -- *координаты тензора* $t$ в базисе $e$.

::::


## Операции над тензорами


### Сложение

:::: {#definition-140}

**Определение:**  (*сложение тензоров*) Пусть $t_1, t_2 \in \mathbb{T}^q_p$. $(t_1 + t_2)(v_1, \ldots, v_p, f_1, \ldots, f_q) = t_1(v_1, \ldots, v_p, f_1, \ldots, f_q) + t_2(v_1, \ldots, v_p, f_1, \ldots, f_q)$.

::::

### Умножение тензора на число

:::: {#definition-141}

**Определение:**  (*умножение тензора на число*) Пусть $t \in \mathbb{T}^q_p, \,\,\,\, \lambda \in F$. $(\lambda t)(v_1, \ldots, v_p, f_1, \ldots, f_q) = \lambda (t(v_1, \ldots, v_p, f_1, \ldots, f_q))$.

::::

:::: {#statement-129}

**Утверждение:**  Относительно операций сложения и умножения на число тензоры типа $(p, q)$ образуют векторное пространство.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

## Тензорное произведение


:::: {#definition-142}

**Определение:**  Пусть $t \in \mathbb{T}^q_p, \,\,\,\, \hat{t} \in \mathbb{T}^{\hat{q}}_{\hat{p}}$. *Тензорное произведение* $t \otimes \hat{t}$ -- это отображение $$t \otimes \hat{t}: \underbrace{V\times \ldots \times V}_p \times \underbrace{V\times \ldots \times V}_{\hat{p}} \times \underbrace{V^{*}\times \ldots \times V^{*}}_q \times \underbrace{V^{*}\times \ldots \times V^{*}}_{\hat{q}} \to F$$ $$(t \otimes \hat{t})(v_1, \ldots, v_p, u_1, \ldots, u_{\hat{p}}, f_1, \ldots, f_q, g_1, \ldots, g_{\hat{q}})=$$$$= t(v_1, \ldots, v_p, f_1, \ldots, f_q)\cdot \hat{t}(u_1, \ldots, u_{\hat{p}}, g_1, \ldots, g_{\hat{q}})$$

::::

:::: {#theorem-34}

**Теорема:**  Пусть $V$ - векторное пространство, $V^{*}$ - сопряженное к $V$ пространство. $e = \{e_1, \ldots, e_n\}$ базис $V$, $e^{*} = \{\varepsilon^1, \ldots, \varepsilon^n\}$ сопряженный к $e$ базис. Тогда $\mathbb{T}^q_p$ -- векторное пространство относительно операций сложения и умножения на число, причем тензоры вида

$$\varepsilon^{i_1} \otimes \ldots \otimes \varepsilon^{i_p} \otimes e_{j_1} \otimes \ldots \otimes e_{j_q}$$

являются базисом $\mathbb{T}^q_p$ и $\dim \mathbb{T}^q_p = n^{p + q}$, где $n = \dim V$

*Доказательство:* $\,\,\,\,\blacksquare$

::::

## Изменение кординат тензора при переходе к другому базису


:::: {#statement-130}

**Утверждение:**  Пусть $t \in \mathbb{T}^q_p$ и координаты $t$ в базисе $e = \{e_1, \ldots, e_n\}$ -- это $t^{i_1\,\,\ldots\,\, i_q}_{j_1\,\,\ldots\,\,j_p}$.

Пусть $\hat{e} = \{\hat{e_1}, \ldots, \hat{e_n}\}$ -- другой базис $V$.

$C_{e \to \hat{e}} = C$ -- матрица перехода от $e$ к $\hat{e}$.

$D = C^{-1}$

$C^i_j$ -- элемент $i$-й строки и $j$-ого столбца матрицы $C$ и аналогично для матрицы $D$.

Тогда координаты $t$ в базисе $\hat{e}$ выражаются по формуле

$$\hat{t}^{i_1\,\,\ldots\,\, i_q}_{j_1\,\,\ldots\,\,j_p} = \displaystyle \sum C_{j_1}^{l_1}\ldots C_{j_p}^{l_p} t^{k_1\,\,\ldots\,\, k_q}_{l_1\,\,\ldots\,\,l_p} D^{i_1}_{k_1}\ldots D^{i_q}_{k_q}$$

*Доказательство:* $\,\,\,\,\blacksquare$

::::

## Свертка тензора


Пусть $t \in \mathbb{T}^q_p$. Рассмотрим тензор $\bar{t}$ типа $(p - 1, q - 1)$, полученный по формуле: 

$$\bar{t} = \displaystyle \sum_{i = 1}^{n}t(v_1, \ldots, v_{r - 1}, e_i, v_{r + 1}, \ldots, v_p, f_1, \ldots, f_{s - 1}, \varepsilon^i, f_{s + 1}, \ldots, f_q)$$

:::: {#statement-131}

**Утверждение:** $\bar{t}$ не зависит от выбора базиса.

*Доказательство:* Можно доказывать для полилинейной функции $g(e_i, \varepsilon^i)$, так как остальные аргументы фиксированы. Пусть $e$ и $\tilde{e}$ базисы в $V$. Необходимо $$\displaystyle \sum_{i}^{n}g(e_i, \varepsilon^i) = \displaystyle \sum_{i = 1}^{n}g(\tilde{e}_i, \tilde{\varepsilon}^i)$$

Проверяется напрямую $\,\,\,\,\blacksquare$

::::

:::: {#definition-143}

**Определение:**  Пусть $t \in \mathbb{T}^q_p$. Тензор $\bar{t}$ типа $(p - 1, q - 1)$, полученный по формуле: $$\bar{t} = \displaystyle \sum_{i = 1}^{n}t(v_1, \ldots, v_{r - 1}, e_i, v_{r + 1}, \ldots, v_p, f_1, \ldots, f_{s - 1}, \varepsilon^i, f_{s + 1}, \ldots, f_q)$$ -- *свертка* тензора $t$ по $r$-ому ковариантному индексу и $s$-ому контравариантному.

::::

:::: {#statement-132}

**Утверждение:**  Пусть координаты тензора $t \in \mathbb{T}^q_p$ -- это $t^{i_1\,\,\ldots\,\, i_q}_{j_1\,\,\ldots\,\,j_p}$. Тогда координаты свертки тензора получаются по формуле:
$$\hat{t}^{i_1\,\,\ldots\,\,i_{s - 1}i_{s + 1}\,\,\ldots\,\, i_q}_{j_1\,\,\ldots\,\,j_{r - 1}j_{r + 1}\,\,\ldots\,\,j_p} = \displaystyle \sum t^{i_1\,\,\ldots\,\,i_{s - 1}\,\, l \,\,i_{s + 1}\,\,\ldots\,\, i_q}_{j_1\,\,\ldots\,\,j_{r - 1} \,\,l\,\, j_{r + 1}\,\,\ldots\,\,j_p}$$

*Доказательство:* $\,\,\,\,\blacksquare$

::::

## Симметрические и кососимметрические тензоры


:::: {#definition-144}

**Определение:**  Тензор $t$ типа $(p, 0)$ -- *симметричный*, если $\forall \pi \in S_p$ (группа перестановок) $\forall v_1, \ldots, v_p \in V \,\,\,\, t(v_1, \ldots, v_p) = t(v_{\pi(1)}, \ldots, v_{\pi(p)})$.

::::

:::: {#definition-145}

**Определение:**  Множество симметричных тензоров типа $(p, 0)$ обозначается $\mathbb{T}^{+}_p$.

::::

:::: {#statement-133}

**Утверждение:**  Множество $\mathbb{T}^{+}_p$ является подпространством в пространстве $\mathbb{T}^0_p$.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

:::: {#definition-146}

**Определение:**  Тензор $t$ типа $(p, 0)$ -- *кососимметричный*, если $\forall \pi \in S_p$ (группа перестановок) $\forall v_1, \ldots, v_p \in V^{*} \,\,\,\, t(v_1, \ldots, v_p) = \operatorname{sgn} (\pi) t(v_{\pi(1)}, \ldots, v_{\pi(p)})$.

::::

:::: {#definition-147}

**Определение:**  Множество кососимметричных тензоров типа $(p, 0)$ обозначается $\Lambda^p(V^{*})$.

::::

:::: {#statement-134}

**Утверждение:**  Множество $\Lambda^p(V^{*})$ является подпространством в пространстве $\mathbb{T}^0_p$.

*Доказательство:* $\,\,\,\,\blacksquare$

::::

## Симметрирование и альтернирование тензоров


:::: {#definition-148}

**Определение:**  Пусть $t \in \mathbb{T}^0_p$, $\sigma \in S_n$. Определим отображение $\vartheta_{\sigma}: \mathbb{T}^0_p \to \mathbb{T}^0_p \,\,\,\, \,\,\,\, (\vartheta_{\sigma}(t))(v_1, \ldots, v_p) = t(v_{\sigma(1)}, \ldots, v_{\sigma(p)}) \,\,\,\, \forall v_1, \ldots, v_p \in V$.

::::

:::: {#definition-149}

**Определение:**  *Симметрирование* тензора $t \in \mathbb{T}^0_p$ -- это результат применения к нему оператора $\operatorname{Sym}: t \mapsto \frac1{p!}\displaystyle \sum_{\sigma \in S_p}\vartheta_{\sigma}(t)$.

::::

### Свойства оператора симметрирования

:::: {#statement-135}

**Утверждение:**  

1. $\operatorname{Sym}\circ \operatorname{Sym} = \operatorname{Sym}$
2. $\operatorname{img} \operatorname{Sym} = \mathbb{T}^{+}_p$

*Доказательство:* $\,\,\,\,\blacksquare$ 

::::

:::: {#definition-150}

**Определение:**  *Альтернирование* тензора $t \in \mathbb{T}^0_p$ -- это результат применения к нему оператора $\operatorname{Alt}: t \mapsto \frac1{p!}\displaystyle \sum_{\sigma \in S_p}\operatorname{sgn}(\sigma)\vartheta_{\sigma}(t)$.

::::

### Свойства оператора альтернирования

:::: {#statement-136}

**Утверждение:**  

1. $\operatorname{Alt}\circ \operatorname{Alt} = \operatorname{Alt}$
2. $\operatorname{img} \operatorname{Alt} = \Lambda^p(V^{*})$

*Доказательство:* $\,\,\,\,\blacksquare$ 

::::

# Алгебра тензоров


:::: {#definition-151}

**Определение:**  Пусть $U$ и $W$ векторные пространства над полем $F$. Рассмотрим $V = U \times W = \{(u, w): \,\,\,\, u \in U, w \in W\}$. Определим операции сложения $(u, w) + (u’, w’) = (u + u’, w + w’)$ и умножения на числа из $F \,\,\,\, \lambda (u, w) = (\lambda u, \lambda w)$

. Относительно этих операций $V$ -- векторное пространство. $V$ -- *внешняя прямая сумма* $U$ и $W$. Обозначается $U \oplus W$.

Рассмотрим $\hat{U} = \{(u, 0): \,\,\,\, u \in U\}$ и $\hat{W} = \{(0, w): \,\,\,\, w \in W\}$.

$\hat{U}$ и $\hat{W}$ подпространства в $V$ и $V = \hat{U} \oplus_{in} \hat{W} = U \oplus_{out} W$

Отождествив $(u, 0)$ и $u$, $(0, w)$ и $w$, можно писать $u + w$ вместо $(u, w)$.

::::
